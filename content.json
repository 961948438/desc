{"meta":{"title":"f_x_y","subtitle":"cv Engineer","description":"熟练使用CTRL+C和CTRL+V","author":"xiangyou fu","url":"http://www.innerjquery.club","root":"/"},"pages":[{"title":"404","date":"2019-10-28T08:41:10.000Z","updated":"2021-03-14T03:36:11.439Z","comments":true,"path":"404.html","permalink":"http://www.innerjquery.club/404.html","excerpt":"","text":""},{"title":"about","date":"2020-12-30T10:28:44.000Z","updated":"2021-04-07T13:44:57.943Z","comments":true,"path":"about/index.html","permalink":"http://www.innerjquery.club/about/index.html","excerpt":"","text":"无业游民中，以打算毕业后直接务农， 妈了个巴子 11"},{"title":"categories","date":"2020-12-30T10:27:54.000Z","updated":"2020-12-30T10:36:59.008Z","comments":true,"path":"categories/index.html","permalink":"http://www.innerjquery.club/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2020-12-30T10:29:15.000Z","updated":"2020-12-30T10:29:24.857Z","comments":true,"path":"contact/index.html","permalink":"http://www.innerjquery.club/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-02-26T08:36:55.000Z","updated":"2021-04-07T12:57:43.728Z","comments":true,"path":"tags/index.html","permalink":"http://www.innerjquery.club/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2020-12-30T10:29:45.000Z","updated":"2020-12-30T10:30:02.255Z","comments":true,"path":"friends/index.html","permalink":"http://www.innerjquery.club/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"关于vue组件通信","slug":"关于vue组件通讯","date":"2021-04-07T11:17:20.536Z","updated":"2021-04-05T10:17:24.627Z","comments":true,"path":"2021/04/07/关于vue组件通讯/","link":"","permalink":"http://www.innerjquery.club/2021/04/07/%E5%85%B3%E4%BA%8Evue%E7%BB%84%E4%BB%B6%E9%80%9A%E8%AE%AF/","excerpt":"","text":"vue子父兄弟组件之间实现数据传递的方式(区分标签内容传递和data数据传递的区别) 兄弟组件之间实现数据传递1alert('Hello World!'); 1） val hub=new Vue()实例化一个vue对象用做事件中心管理组件；2） hub.$emit(‘tom-event’, 1); 再子组件的methods的方法中，通过$emit(事件名，data)方法触发事件管理中心下的指定事件3） hub.$on(‘jerry-event’,fn）再mounted声明周期钩子函数中给中心管理组件绑定事件和业务处理逻辑4） hub.$off(‘tom-event’); 可以再任意一个组件中销毁事件中心管理组件的绑定事件； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;div id=\"app\"&gt; &lt;div&gt;父组件&lt;/div&gt; &lt;div&gt; &lt;button v-on:click='handle'&gt;销毁事件&lt;/button&gt; &lt;/div&gt; &lt;test-tom&gt;&lt;/test-tom&gt; &lt;test-jerry&gt;&lt;/test-jerry&gt;&lt;/div&gt;var hub = new Vue(); Vue.component('test-tom', { data: function(){ return { num: 0 } }, template: \"&lt;div&gt; &lt;div&gt;TOM:{ {num} }&lt;/div&gt; &lt;div&gt; &lt;button v-on:click='handle'&gt;点击&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; \" , methods: { handle: function(){ hub.$emit('jerry-event', 2); } }, mounted: function() { // 监听事件 hub.$on('tom-event', (val) =&gt; { this.num += val; }); } }); Vue.component('test-jerry', { data: function(){ return { num: 0 } }, template: ` &lt;div&gt; &lt;div&gt;JERRY:{ {num} }&lt;/div&gt; &lt;div&gt; &lt;!-- &lt;button v-on:click='handle'&gt;点击&lt;/button&gt; --&gt; &lt;/div&gt; &lt;/div&gt; `, methods: { handle: function(){ // 触发兄弟组件的事件 hub.$emit('tom-event', 1); } }, mounted: function() { // 监听事件 hub.$on('jerry-event', (val) =&gt; { this.num += val; }); } }); var vm = new Vue({ el: '#app', data: { }, methods: { handle: function(){ hub.$off('tom-event'); hub.$off('jerry-event'); } } }); 父组件向子组件传递数据的方式；1）title=”我是父元素传递过来的值” 父组件通过添加属性的方式向子组件传递一个值；2）props: [‘title’, ‘content’], 子组件利用配置参数对象下的props属性接受传递过来的值并存储以便使用/*****以下以局部组件为例子，全局组件方法为vue。components（组件名，配置参数） 1234567891011121314151617components: { 'hello-p': { props: ['title', 'content'], data: function() { return { msg: 'hello - p' } }, template: `&lt;div v-on:click=\"$emit('enlarge-text',5)\"&gt; { {msg+\"-- -- -- -- --\"+title} }&lt;/div&gt;`, methods: { fn: function(event) { console.log(event) } } }} 子组件向父组件传递数据的方式 { {pmsg} } 1）父组件给子组件绑定一个自定义事件v-on:事件名：v-on:enlarge-text=\"handle($event)\" 1）子组件通过$emit('触发事件名'，携带data)方法触发一个自定义事件 1234567891011121314151617181920212223242526Vue.component('menu-item', { props: ['parr'], template: ` &lt;div&gt; &lt;ul&gt; &lt;li :key='index' v-for='(item,index) in parr'&gt;{ {item} }&lt;/li&gt; &lt;/ul&gt; &lt;button v-on:click='$emit(\"enlarge-text\", 5)'&gt;扩大父组件中字体大小&lt;/button&gt; &lt;button v-on:click='$emit(\"enlarge-text\", 10)'&gt;扩大父组件中字体大小&lt;/button&gt; &lt;/div&gt; ` }); var vm = new Vue({ el: '#app', data: { pmsg: '父组件中内容', parr: ['apple', 'orange', 'banana'], fontSize: 10 }, methods: { handle: function(val) { // 扩大字体大小 this.fontSize += val; } }});","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.innerjquery.club/tags/vue/"}]},{"title":"spider爬取所有基金","slug":"spider爬取所有基金","date":"2021-03-28T10:09:18.000Z","updated":"2021-03-28T10:13:57.123Z","comments":true,"path":"2021/03/28/spider爬取所有基金/","link":"","permalink":"http://www.innerjquery.club/2021/03/28/spider%E7%88%AC%E5%8F%96%E6%89%80%E6%9C%89%E5%9F%BA%E9%87%91/","excerpt":"","text":"requests模块爬取所有基金123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116from urllib import requestfrom bs4 import BeautifulSoupimport reimport pymysqlimport timefundSharesList = []db =pymysql.connect( host = '127.0.0.1', port =3306, user = 'root', password = '961948438', db = 'gupiao_info', charset = 'utf8' )head={ \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\"}find = { 1:re.compile(r'html\"&gt;(.*?)&lt;/a&gt;&lt;/td&gt;'), 2:re.compile(r'html\"&gt;(.*?)&lt;/a&gt;&lt;/td&gt;'), 6:re.compile(r'\"&gt;(.*?)&lt;/td&gt;'), 7:re.compile(r'\"&gt;(.*?)&lt;/td&gt;'), 8:re.compile(r'\"&gt;(.*?)&lt;/td&gt;')}def handle (a): flag = False for i in range(0,len(fundSharesList)): if a[0] == fundSharesList[i][0]: fundSharesList[i][2] = round(float(fundSharesList[i][2]) + float(a[4]),2) flag =True break if not flag: new = [a[0],a[1],a[4]] fundSharesList.append(new)if __name__==\"__main__\": funds = [] fundNum = 0 errorNum = 0 send = request.Request(\"http://fund.eastmoney.com/js/fundcode_search.js\",headers = head) response = request.urlopen(send) js = response.read().decode('utf-8') js = js[11:len(js)-3].split(\"],[\") for i in range(0,len(js)): fund = str(js[i]).replace('\"','') fund = fund.split(\",\") funds.append(fund) print(funds) while fundNum &lt; 5: fund_id = funds[fundNum][0] print(fund_id + \" \" + funds[fundNum][2]) print(fundSharesList) try: url = \"http://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&amp;code=\" + str(fund_id) + \"&amp;topline=10&amp;year=2020&amp;month=&amp;rt=0.21822537857648627\" send = request.Request(url,headers = head) response = request.urlopen(send, timeout=10) html = response.read().decode('utf-8') bs =BeautifulSoup(html,\"html.parser\") find_list = bs.find_all(\"tbody\") tr = find_list[0].find_all(\"tr\") for i in tr: td = i.find_all(\"td\") fundShares = [] for j in range(0,len(td)): if j in [1,2,6,7,8]: a = re.findall(find[j],str(td[j]))[0] if j ==8 : a = str(a).replace(\",\",\"\") if(len(a)&gt;8): time.sleep(6) fundShares.append(a) handle(fundShares) print() errorNum = 0 except Exception as e: print(fund_id + \" 获取失败\") print(e) if str(e) ==\"timed out\" and errorNum &lt;= 3: print(\"第\" + str(errorNum) + \"次超时，重试\") errorNum = errorNum + 1 fundNum = fundNum - 1 print() fundNum = fundNum + 1 # if fundNum == 1000: # break # 使用 cursor() 方法创建一个游标对象 cursor # cursor = db.cursor() # try: # for insert in fundSharesList: # sql = \"INSERT INTO jjinfo VALUES ('\"+ str(insert[0]) +\"', '\" + str(insert[1]) +\"', \" + str(insert[2]) + \");\" # print(sql) # # 执行sql语句 # cursor.execute(sql) # # 提交到数据库执行 # db.commit() # except Exception as e: # # 回滚 # db.rollback() # raise Exception(\"插入数据库错误！\", e) # # 关闭数据库连接 # db.close() for insert in fundSharesList: print(insert)","categories":[{"name":"spider","slug":"spider","permalink":"http://www.innerjquery.club/categories/spider/"}],"tags":[{"name":"python 爬虫","slug":"python-爬虫","permalink":"http://www.innerjquery.club/tags/python-%E7%88%AC%E8%99%AB/"}]},{"title":"spider爬取所有股票","slug":"spider爬取所有股票","date":"2021-03-28T10:09:05.000Z","updated":"2021-03-28T10:11:16.515Z","comments":true,"path":"2021/03/28/spider爬取所有股票/","link":"","permalink":"http://www.innerjquery.club/2021/03/28/spider%E7%88%AC%E5%8F%96%E6%89%80%E6%9C%89%E8%82%A1%E7%A5%A8/","excerpt":"","text":"爬取所有股票 工具selenium 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from logging import exceptionfrom selenium import webdriverimport timeimport io,syssys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='gb18030')class Domain(object): def __init__(self): self.chrome_driver = 'C:\\\\Users\\\\dd\\Desktop\\\\chromedriver.exe' self.driver = webdriver.Chrome(self.chrome_driver) @staticmethod def sleep_time(num): time.sleep(num) def login(self): self.driver.set_window_size(1920,1680) self.driver.get('http://vip.stock.finance.sina.com.cn/mkt/#stock_hs_up') time.sleep(0.5) self.totalpate = self.driver.find_element_by_xpath('//div[@id=\"list_pages_top2\"]/a[last()-1]') headtr =self.driver.find_element_by_xpath('//*[@id=\"tbl_wrap\"]//thead//tr') headcontent = [] headcontent.append(headtr.find_element_by_xpath('.//th[1]/a').text) headcontent.append(headtr.find_element_by_xpath('.//th[2]').text) tdalist = headtr.find_elements_by_xpath('.//td/a') for tda in tdalist: headcontent.append(tda.text) headcontent.append('\\n') with open(\"ggupiao.csv\",mode='a',encoding='utf-8') as f: f.write(\",\".join(headcontent)) while True: alltrlist =self.driver.find_elements_by_xpath('//*[@id=\"tbl_wrap\"]//tbody//tr') for tr in alltrlist: print(f'to scrapy {alltrlist.index(tr)}') listcontent = [] try: listcontent.append(tr.find_element_by_xpath('.//th[1]/a').text) except Exception: listcontent.append('暂未获取到代码') tdalist = tr.find_elements_by_xpath('.//td') try: listcontent.append(tr.find_element_by_xpath('.//th[2]/a/a').text) except Exception: listcontent.append('暂未获取到名称') tdalist = tr.find_elements_by_xpath('.//td') for tda in tdalist: listcontent.append(tda.text) listcontent.append('\\n') with open(\"ggupiao.csv\",mode='a',encoding='utf-8') as f: f.write(\",\".join(listcontent)) try: self.driver.find_element_by_xpath('//div[@id=\"list_pages_top2\"]/a[text()=\"下一页\"]').click() except Exception: print('找不到元素') return def run(self): self.login()if __name__ == \"__main__\": browser = Domain() browser.run()","categories":[{"name":"spider","slug":"spider","permalink":"http://www.innerjquery.club/categories/spider/"}],"tags":[{"name":"python 爬虫","slug":"python-爬虫","permalink":"http://www.innerjquery.club/tags/python-%E7%88%AC%E8%99%AB/"}]},{"title":"react-virtualized高性能长列表组件使用","slug":"react-virtualized高性能长列表组件使用","date":"2021-03-28T09:52:33.000Z","updated":"2021-03-28T10:05:39.605Z","comments":true,"path":"2021/03/28/react-virtualized高性能长列表组件使用/","link":"","permalink":"http://www.innerjquery.club/2021/03/28/react-virtualized%E9%AB%98%E6%80%A7%E8%83%BD%E9%95%BF%E5%88%97%E8%A1%A8%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8/","excerpt":"","text":"react长列表优化方案: react-virtualized常见问题： 当一个学生组件为如下时： 123function Student({student}) { return &lt;div&gt;{student.name}&lt;/div&gt;} 当有五千个学生时会生成五千个组件，消耗很大性能，特别是在dom进行重绘重排的时候； DOM结构如果过大, 网页就会出现用户操作体验上的问题, 比如滚动, 点击等常用操作. 同时, 对react的虚拟DOM计算以及虚拟DOM反映到真实DOM的压力也会很大. 当用户点击切换教室时, 就会出现秒级的卡顿 使用react-virtualized优化 在react生态中, react-virtualized作为长列表优化的存在已久, 社区一直在更新维护, 讨论不断, 同时也意味着这是一个长期存在的棘手问题!？ 解决以上问题的核心思想就是: 只加载可见区域的组件 react-virtualized将我们的滚动场景区分为了viewport内的局部滚动, 和基于viewport的滚动, 前者相当于在页面中开辟了一个独立的滚动区域，属于内部滚动, 这跟和iscroll的滚动很类似, 而后者则把滚动作为了window滚动的一部分(对于移动端而言，这种更为常见). 基于此计算出当前所需要显示的组件. 通过该第三方组件我们将进行如下实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 function Student({student, style, ...rest}) { return ( &lt;div style={style}&gt; ... &lt;div&gt;{student.name} ....&lt;/div&gt; ... &lt;/div&gt; ) } import React from 'react'import { AutoSizer } from 'react-virtualized/dist/commonjs/AutoSizer'import { List as VList } from 'react-virtualized/dist/commonjs/List'class StudentList extends React.Component { constructor(props) { super(props) this.state = { list: [] } } getList = () =&gt; { api.getList.then(res =&gt; { this.setState({ list: res }) }) } componentDidMount() { this.getList() } render() { const { list } = this.state const renderItem = ({ index, key, style }) =&gt; { return &lt;Student key={key} student={list[index]} style{style} /&gt; } return ( &lt;div style={{height: 1000}}&gt; &lt;AutoSizer&gt; {({ width, height }) =&gt; ( &lt;VList width={width} height={height} overscanRowCount={10} rowCount={list.length} rowHeight={100} rowRenderer={renderItem} /&gt; )} &lt;/AutoSizer&gt; &lt;/div&gt; ) } } 外层div样式中的高度不是必须的, 比如你的网页是flex布局, 你可以用flex: 1来让react-virtualized计算出这个高度)这个时候, 如果每个Student的高度相同的话, 问题基本上就解决啦!可是, 问题又来了, 有时候我们的Student会是不确定高度的, 可以有两种方法解决问题, 推荐react-virtualized的CellMeasurer组件解决方案 解决方法一： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import React from 'react'import { AutoSizer } from 'react-virtualized/dist/commonjs/AutoSizer'import { List as VList } from 'react-virtualized/dist/commonjs/List'import { CellMeasurerCache, CellMeasurer } from 'react-virtualized/dist/commonjs/CellMeasurer'class StudentList extends React.Component { constructor(props) { super(props) this.state = { list: [] } } measureCache = new CellMeasurerCache({ fixedWidth: true, minHeight: 58 }) getList = () =&gt; { api.getList.then(res =&gt; { this.setState({ list: res }) }) } componentDidMount() { this.getList() } render() { const { list } = this.state const renderItem = ({ index, key, parent, style }) =&gt; { return ( &lt;CellMeasurer cache={this.measureCache} columnIndex={0} key={key} parent={parent} rowIndex={index}&gt; &lt;Student key={key} student={list[index]} /&gt; &lt;/CellMeasurer&gt; ) } return ( &lt;div style={{height: 1000}}&gt; &lt;AutoSizer&gt; {({ width, height }) =&gt; ( &lt;VList ref={ref =&gt; this.VList = ref} width={width} height={height} overscanRowCount={10} rowCount={list.length} rowHeight={this.getRowHeight} rowRenderer={renderItem} deferredMeasurementCache={this.measureCache} rowHeight={this.measureCache.rowHeight} /&gt; )} &lt;/AutoSizer&gt; &lt;/div&gt; ) }} 解决方法二：过react-height或者issue中提到的通过计算回调的方法解决, 以使用react-height为例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576 import React from 'react'import { AutoSizer } from 'react-virtualized/dist/commonjs/AutoSizer'import { List as VList } from 'react-virtualized/dist/commonjs/List'import ReactHeight from 'react-height'class StudentList extends React.Component { constructor(props) { super(props) this.state = { list: [] heights = [] } } getList = () =&gt; { api.getList.then(res =&gt; { this.setState({ list: res }) }) } componentDidMount() { this.getList() } handleHeightReady = (height, index) =&gt; { const heights = [...this.state.heights] heights.push({ index, height }) this.setState({ heights }, this.vList.recomputeRowHeights(index)) } getRowHeight = ({ index }) =&gt; { const row = this.heights.find(item =&gt; item.index === index) return row ? row.height : 100 } render() { const { list } = this.state const renderItem = ({ index, key, style }) =&gt; { if (this.heights.find(item =&gt; item.index === index)) { return &lt;Student key={key} student={list[index]} style{style} /&gt; } return ( &lt;div key={key} style={style}&gt; &lt;ReactHeight onHeightReady={height =&gt; { this.handleHeightReady(height, index) }} &gt; &lt;Student key={key} student={list[index]} /&gt; &lt;/ReactHeight&gt; &lt;/div&gt; ) } return ( &lt;div style={{height: 1000}}&gt; &lt;AutoSizer&gt; {({ width, height }) =&gt; ( &lt;VList ref={ref =&gt; this.VList = ref} width={width} height={height} overscanRowCount={10} rowCount={list.length} rowHeight={this.getRowHeight} rowRenderer={renderItem} /&gt; )} &lt;/AutoSizer&gt; &lt;/div&gt; ) }}","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"react-virtualized_component","slug":"react-virtualized-component","permalink":"http://www.innerjquery.club/tags/react-virtualized-component/"}]},{"title":"spider爬取教务网成绩","slug":"爬虫小案例","date":"2021-03-24T12:24:06.000Z","updated":"2021-03-24T12:32:14.951Z","comments":true,"path":"2021/03/24/爬虫小案例/","link":"","permalink":"http://www.innerjquery.club/2021/03/24/%E7%88%AC%E8%99%AB%E5%B0%8F%E6%A1%88%E4%BE%8B/","excerpt":"","text":"快捷打开教务网成绩爬取12345678910111213141516171819202122232425262728293031323334353637383940from selenium import webdriverimport timechrome_driver = 'C:\\\\Users\\\\dd\\Desktop\\\\chromedriver.exe'driver = webdriver.Chrome(chrome_driver)driver.set_window_size(1920,1680)driver.get('http://kdjw.hnust.edu.cn/')# time.sleep(1)# print('正在获取到元素')# try:# ele = driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/ul[1]/li[2]\")# print(ele)# ele.click()# except Exception as f:# print(f)# print('获取失败')driver.find_element_by_id('userAccount').send_keys(\"1715110210\")driver.find_element_by_id('userPassword').send_keys(\"961948438fxy\")# time.sleep(1)driver.find_elements_by_id(\"btn-login\")[0].click()time.sleep(1)driver.find_element_by_xpath('//*[@id=\"accordion\"]/li[3]/div').click()# //*[@id=\"accordion\"]/li[3]/ul/li[3]/divtime.sleep(0.5)driver.find_element_by_xpath('//*[@id=\"accordion\"]/li[3]/ul/li[3]/div').click()time.sleep(0.5)driver.find_element_by_xpath('//*[@id=\"NEW_XSD_XJCJ_WDCJ_KCCJCX\"]').click()time.sleep(0.5)driver.switch_to.frame('Frame1')driver.switch_to.frame('cjcx_query_frm')driver.find_elements_by_id('btn_query')[2].click()cookies = { i[\"name\"]:i[\"value\"] for i in driver.get_cookies()}# 成绩打印print(cookies)time.sleep(300)driver.quit()","categories":[{"name":"spider","slug":"spider","permalink":"http://www.innerjquery.club/categories/spider/"}],"tags":[{"name":"python 爬虫","slug":"python-爬虫","permalink":"http://www.innerjquery.club/tags/python-%E7%88%AC%E8%99%AB/"}]},{"title":"3月中学习问题收集","slug":"01 3月学习","date":"2021-03-21T06:14:32.000Z","updated":"2021-04-07T13:02:36.818Z","comments":true,"path":"2021/03/21/01 3月学习/","link":"","permalink":"http://www.innerjquery.club/2021/03/21/01%203%E6%9C%88%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"关于vue中.sync修饰符的用法具名插槽slot的用法，作用域插槽的用法使用keepalive组件将失活的组件缓存起来什么是异步组件，定义组件的第二个参数为一个工厂函数异步组件配合加载状态依赖注入进行组件间数据交互provid，inject、inner-template和x-templatevue.extend()方法创建一个vue的子类，vue的异步更新队列：vue的全局配置属性confignextjs项目搭建oauth原理深度解析nexjs集成reduxnextjs作为koa中间件使用nextjs中的pages文件夹下的一个文件就对应一个页面区分next的静态渲染和服务端渲染getstaticprops、getstaticpaths、getserversideprops的用法next默认只支持css，可自行配置和less的支持next内置了一些常规组件如image再next.config.js配置文件夹中对外部网站托管的图片进行优化next支持静态文件的存放至于public目录下，对外访问路径以 (/) 作为起始路径。组件中的css-in-js的用法{h1&#123;color:blue&#125;}next根组件中的component就是我们每次渲染的模块里面的组件next的lazyloading模块懒加载hook中的useState和useReducer的相同之处不同用法uselayouteffect和useeffect的区别，前者只是形成虚拟dom是调用，后者已经形成真实domusecontext钩子useref钩子的使用优化组件的两个渲染useMemo,useCollback钩子使用useMemo（回调，依赖的状态）用来记忆属性优化组件渲染使用useCollback（回调，依赖的状态）用来记忆方法，优化组件渲染react闭包陷阱使得访问到的count可能是之前闭包下的状态redux中的combinereducer方法接受一个对象或者数组，对象中键或者数组下标被作为reudcernameredux的middleware中间件用第三方工具扩展我们的reduxredux-thunk模块的作用： 1.从redux中导出applyMiddleWare,从redux-thunk中导入redxu-thunk 2.export const store = createStore(allreducer,applyMiddleware(ReduxThunk)) 3.定义一个异步action，该异步actions必须返回一个回调函数，回来回调会被传入dispatch，可以通过diapatch发布同步actions 4.调用disptch即可 react-redux的配合使用： 再根组件中从react-redux模块中引入proider容器组件 利用provider容器组件将我们的store通过属性传给给所有的容器组件 导入connect方法从react-reduc中，以创建一个容器组件 123456789101112131415export default connect((state)=&gt;{ return { counter:state.countreducer, number:state.numberreducer }},(dispatch)=&gt;{ return{ add:()=&gt;dispatch(countaction('countadd',100000)), dec:()=&gt;dispatch(numberaction('numberadd',100000)) }})(Thook) 映射出来我们的状态和修改状态的方法到组件的props属性中，其内部做了处理，不用再store.subscribt()监听然后手动渲染了 然后再我们的ui组件中就可以随意通过属性获取我们的共有数据了， 使用redux-devtool-extensions开发者工具 import { composeWithDevTools } from ‘redux-devtools-extension’ composeWithDevTools(applyMiddleware(ReduxThunk)) nextjs的hoc模式：高阶组件，接受组件作为参数然后返回一个新的组件nextjs集成redux：服务端如何写入数据到store、如何同步服务端的数据到客户端授权登录OA：请求对象下的session，响应对象下的COOKIES(请求可拿到cookies)注意当CORS_ORIGIN_ALLOW_ALL = True是django是不能设置cookies的ajax跨域请求无法带上cookie的情况关于数据的变形和变异方法一定要了解，一个改变原数据，一个不改变原数据返回一个新数据；多使用promise将我们深层的回调无法传递出去的数据resove（）出去所谓长列表性能优化的常用方法，懒加载数据、可视区域渲染： 只渲染我们可见区域的数据，不可见的数据不进行渲染；只渲染可视区域的数据 可视区域渲染适用于一次性展示大量的数据；每次只渲染少量的dom， 可视区域渲染方案较好的第三方库文件有react-virtualized react-virtualized是一个第三方的高效渲染大型列表和表格的数据； react-virtualized组件的使用react中将来和组件没有关系的方法可以封装在组件外面实现百度api实现props的默认值设定和类型校验；一个组件只要被导入了。那么组件里的代码就会执行，对应的样式文件也会生效css-in-js是解决组件间样式所谓css-in-js就是使用javascript编写css，主要实现方法有： css-modules：这个方案已经被react脚手架集成，上手就可以使用 styled-component：是一个全新的写组件的方法 cssmodules是通过对css类型进行重命名，保证每个类名的唯一性 解决样式冲突问题，使得样式只能对当前组件作用古生效了，只在当前组件内部生效 css-modules的实现依赖于css-loader插件进行处理 将来我们的类型会被渲染为BEM（block块，element元素，modifier修改）命名规范的类型： 但是在react中进行了进一步的处理：在react中演化成了文件名+类名+随机hash值： 使用方式就是模块化导入我们的样式，并通过模块名下的名给我们组件添加样式； 我们可以打印以下导入的模块名，前提是我们样式文件是.modules.css结尾； 在模块化css中通过:global(.title)的方式声明我们的全局样式；（冒号家global包裹我们的类名）其不会对该类型进行BEM处理；而是保留原类名 axios的default属性可以访问到全局配置对象； 还可以通过axios.create方法创建一个axios对象，我们可以通过axios对象去发起请求 接口域名和图片分为开发环境和生产环境，直接写在代码中，项目发布时很难替换； 相关的解决方法： 创建一个开发环境变量文件和生产环境变量文件： 分别配置REACT_APP_URL = http://localhost:8000/ (生产环境) 配置REACT_APP_URL = 线上接口地址 将来我们可以同过process.env属性可以拿到我们配置的REACT_APP_URL属性； axios的all方法可以发起多请求，它接受一个数组作为参数： 数组中的每个元素都是将来发起的请求对象返回的promise对象：将来所有的promise对象都有了返回结果之后会调用then方法里的spread函数捕获结果 12345678910mounted(){ var me = this; this.$axios.all([me.getAllTask(),me.getAllCity()]).then( me.$axios.spread(function(allTask, allCity){ console.log('所有请求完成') console.log('请求1结果',allTask) console.log('请求2结果',allCity) }) ) 然后我们可以通过axios对象下的spread方法里的回调去捕获结果，它接受和我们all方法的数组参数的promise请求相对应的结果， 对象中的键默认是字符串，我们可以在键的旁边加上一个中括号表示这是一个变量 123{ [id]:'1'} 给我们的组件添加一个不同的key值，当我们切换该组件时可重新渲染该组件 以便拿到最新的value值；这就是react内部的处理：react内部认为只要key值不同就会重新渲染组件，初始化状态等操作； 实现清除按钮和确认按钮的封装：indexof方法的使用 Object对象下提供的属性和方法；接受父组件传递过来得值，-。——–组件化开发得一个重要原则，数据在哪个组件上，修改数据得方法也必须在该组件上当前菜单得高亮逻辑处理 对象处理逻辑根据筛选体条件获取房屋数据；监听scroll事件一定要找到我们监听的元素才行；前端性能优化域名解析规则，比如www.baidu.com 注意：域名的解析规则是从右到左的，实际上先解析.com后面的.（不是前面的）这个隐藏的点表示公网的意思； 本地浏览器和本地服务器之间； 前端页面渲染流程： html请求：html文档下载，html文档解析，解析生成dom树，解析生成render树（所有的元素是可见的） 逐级遍历解析dom树，这个逐级遍历解析dom树过程可优化以下方案： link-css尽量减少页面的reflow回流， javascript，js绘制dom节点会阻塞其他标签解析，甚至下载， 浏览器的js引擎； http://localhost:80; 原始状态码：301，302 304，分别表示永久跳转，临时跳转， export 不仅可以通过本文件导出，还可以通过其他文件导出electron + react + 七牛云构建跨平台的应用electron是一个基于chromiun和nodejs的让你构建html，css，ja构建的应用； 熟悉react的各种hook，和自定义hooknvm是一个快速切换node版本的工具；electron是基于多进程的，（注意多进程和多线程的区别）electron 有主进程和渲染进程，，主进程主要和系统对接的api，创建菜单；上传全面支持nodejs和domapi，还可以使用一部分electron的api，主进程和渲染进程的api的区别 nodemon第三方模块的简单用法就是：1.下载npm i nodemon 2. 然后让我们运行的脚本改为nodemon –wach main.js –exec electron .注意：–exec后面就是我们监控的文件发生变化之后运行的脚本； electron使用ipc在进程之间同xu安装electron官方的插件：devtrronreact源码学习；flow是用来静态类型检查的；实际上组件不能小写的原因：将来babel在转换jsx的时候就是遇到小写就把createElement方法第一个参数视为字符串，否则视作变量；reactElement元素：suspense内置组件的用法：当子组件返回的promise对象没有结果之前渲染suspense组件提供的fallback属性值；suspense通常配合lazy一起使用：其实lazy方法的返回值就是一个promise对象；注意当我们suspense组件有多个子组件的时候等到所有组件的promise都有返回值了之后suspense组件才会去掉fallback内容显示组件内容；简单理解：suspense组件用于异步渲染组件时显示的默认fallback内容；通常配合异步加载组件的lazy方法一起使用；hook 对usecallback钩子的理解：该钩子接受一个回调函数和一个依赖项数组作为参数，并且返回一个方法，将来如果依赖项数组发生了改变的时候我们调用了返回的方法就会触发里面的回调，否则不会触发里面的回调函数； 对useMemo钩子的理解：该钩子接受一个回调函数和一个依赖项数组作为参数，当依赖项数组发生改变之后就会返回该回调函数的调用： 使用effect钩子的时候如果传入一个空的依赖项数组，该钩子函数只会执行一次，并且组件卸载的时候返回的函数也只会执行一次；如果不传入依赖项数组默认会监控所有的状态，然后执行回调钩子和返回的函数； 通常情况下我们使用props。children就可以拿到我们的children属性的值，但是当我们想要操作children的时候我们就必须使用react、children属性下提供的map，foreach，count等方法：React.children.map(props.children,(item) =&gt; [item,item])children下面的map方法接受两个参数，一个是外界传递的props的children属性，还有一个通常是遍历children的方法；并且我们map返回的数组将来都会装换为一个一维数组；React.children对象下提供的onlychild方法用来判断是否是一个单独的节点； fragment本质上就是一个symbolreact对象下还提供了一个strictMode组件，也不渲染任何元素，当我们使用strictmode，可以给我们很好的api提示，（是否过期等等） suspense本质也就是一个symbol，createFactory（react对象下的一个属性）它接受一个elementtype作为参数，返回一个该elementType的工厂函数； reactDom.render函数的使用；创建更新额三种方式：1.reactDOM.render / hydrate（用于初次渲染）2.setState()3.force 将来我们的reactelement节点会对应一个fiber节点fiber是我们将来所有节点的根节点 当我们调用reactDom对象下提供的render函数的时候，其做了什么事情：1.创建一个reactroot，2.创建一个fiberroot和rootfiber3.创建一个更新进入调度， 重点：fiber对象：每一个reactElement对应着一个filber对象；记录着节点的各种状态；串联整个应用的状态；","categories":[{"name":"web 前端杂项","slug":"web-前端杂项","permalink":"http://www.innerjquery.club/categories/web-%E5%89%8D%E7%AB%AF%E6%9D%82%E9%A1%B9/"}],"tags":[{"name":"issue","slug":"issue","permalink":"http://www.innerjquery.club/tags/issue/"}]},{"title":"img的上传、预览和FileReader类","slug":"img的上传、预览和FileReader类","date":"2021-03-17T04:59:56.000Z","updated":"2021-03-17T05:16:04.334Z","comments":true,"path":"2021/03/17/img的上传、预览和FileReader类/","link":"","permalink":"http://www.innerjquery.club/2021/03/17/img%E7%9A%84%E4%B8%8A%E4%BC%A0%E3%80%81%E9%A2%84%E8%A7%88%E5%92%8CFileReader%E7%B1%BB/","excerpt":"","text":"原生js实现图片上传预览 先简单看一下图片的上传和预览的方式 1234567891011121314&lt;label for=\"file\"&gt;上传图片&lt;/label&gt;&lt;input id=\"file\" type=\"file\" name=\"file\" onchange=\"changepic()\"&gt;&lt;/input&gt;&lt;img src=\"\" id=\"show\" width=\"200\"&gt;&lt;script&gt; function changepic() { const reads = new FileReader(); const f = document.querySelector('#file').files[0]; reads.readAsDataURL(f); reads.onload = function (e) { document.getElementById('show').src = this.result; }; }&lt;/script&gt; js中FileReader()用法 HTML5定义了FileReader作为文件API的重要成员用于读取文件，根据W3C的定义，FileReader接口提供了读取文件的方法和包含读取结果的事件模型。 FileReader的使用方式非常简单，可以按照如下步骤创建FileReader对象并调用其方法： 1. 检测浏览器对FileReader的支持 1234567if(window.FileReader) {var fr = new FileReader();// add your code here}else { alert(\"Not supported by your browser!\");} 2. 调用FileReader对象的方法 FileReader 的实例拥有 4 个方法，其中 3 个用以读取文件，另一个用来中断读取。下面的表格列出了这些方法以及他们的参数和功能，需要注意的是 ，无论读取成功或失败，方法并不会返回读取结果，这一结果存储在 result属性中。 + abort() :中断读取 + readAsBinaryString(fileobj) :将文件读取为二进制码 + readAsDataURL(fileobj) :将文件读取为 DataURL + readAsText(fileobj,[encoding]) :将文件读取为文本 readAsText ：该方法有两个参数，其中第二个参数是文本的编码方式，默认值为 UTF-8。这个方法非常容易理解，将文件以文本方式读取，读取的结果即是这个文本文件中的内容。 readAsBinaryString ：该方法将文件读取为二进制字符串，通常我们将它传送到后端，后端可以通过这段字符串存储文件。 readAsDataURL ：这是例子程序中用到的方法，该方法将文件读取为一段以 data: 开头的字符串，这段字符串的实质就是 Data URL，Data URL是一种将小文件直接嵌入文档的方案。这里的小文件通常是指图像与 html 等格式的文件。 3. 处理事件 FileReader 包含了一套完整的事件模型，用于捕获读取文件时的状态，下面这个表格归纳了这些事件。 + onabort 中断时触发 + onerror 出错时触发 + onload 文件读取成功完成时触发 + onloadend 读取完成触发，无论成功或失败 + onloadstart 读取开始时触发 + onprogress 读取中 文件一旦开始读取，无论成功或失败，实例的 result 属性都会被填充。如果读取失败，则 result 的值为 null ，否则即是读取的结果，绝大多数的程序都会在成功读取文件的时候，抓取这个值。 123fr.onload = function() { this.result;} 4. 下面通过一个上传图片预览和带进度条上传来展示FileReader的使用。 123456789101112131415&lt;script type=\"text/javascript\"&gt; function showPreview(source) { var file = source.files[0]; if(window.FileReader) { var fr = new FileReader(); fr.onloadend = function(e) { document.getElementById(\"portrait\").src = e.target.result; }; fr.readAsDataURL(file); } }&lt;/script&gt;&lt;input type=\"file\" name=\"file\" onchange=\"showPreview(this)\" /&gt;&lt;img id=\"portrait\" src=\"\" width=\"70\" height=\"75\"&gt; 如果要限定上传文件的类型，可以通过文件选择器获取文件对象并通过type属性来检查文件类型 1234if(!/image\\/\\w+/.test(file.type)){ alert(\"请确保文件为图像类型\"); return false;} 不难发现这个检测是基于正则表达式的，因此可以进行各种复杂的匹配，非常有用。 如果要增加一个进度条，可以使用HTML 5的progress标签，通过下面的代码实现。 1234567891011&lt;form&gt; &lt;fieldset&gt; &lt;legend&gt;分度读取文件：&lt;/legend&gt; &lt;input type=\"file\" id=\"File\" /&gt; &lt;input type=\"button\" value=\"中断\" id=\"Abort\" /&gt; &lt;p&gt; &lt;label&gt;读取进度：&lt;/label&gt;&lt;progress id=\"Progress\" value=\"0\" max=\"100\"&gt;&lt;/progress&gt; &lt;/p&gt; &lt;p id=\"Status\"&gt;&lt;/p&gt; &lt;/fieldset&gt;&lt;/form&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192var h = {init: function() { var me = this; document.getElementById('File').onchange = me.fileHandler; document.getElementById('Abort').onclick = me.abortHandler; me.status = document.getElementById('Status'); me.progress = document.getElementById('Progress'); me.percent = document.getElementById('Percent'); me.loaded = 0; //每次读取1M me.step = 1024 * 1024; me.times = 0; }, fileHandler: function(e) { var me = h; var file = me.file = this.files[0]; var reader = me.reader = new FileReader(); // me.total = file.size; reader.onloadstart = me.onLoadStart; reader.onprogress = me.onProgress; reader.onabort = me.onAbort; reader.onerror = me.onerror; reader.onload = me.onLoad; reader.onloadend = me.onLoadEnd; //读取第一块 me.readBlob(file, 0); }, onLoadStart: function() { var me = h; }, onProgress: function(e) { var me = h; me.loaded += e.loaded; //更新进度条 me.progress.value = (me.loaded / me.total) * 100; }, onAbort: function() { var me = h; }, onError: function() { var me = h; }, onLoad: function() { var me = h; if(me.loaded &lt; me.total) { me.readBlob(me.loaded); } else { me.loaded = me.total; } }, onLoadEnd: function() { var me = h; }, readBlob: function(start) { var me = h; var blob, file = me.file; me.times += 1; if(file.webkitSlice) { blob = file.webkitSlice(start, start + me.step + 1); } else if(file.mozSlice) { blob = file.mozSlice(start, start + me.step + 1); } me.reader.readAsText(blob); }, abortHandler: function() { var me = h; if(me.reader) { me.reader.abort(); } }};h.init();","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"js 原生","slug":"js-原生","permalink":"http://www.innerjquery.club/tags/js-%E5%8E%9F%E7%94%9F/"}]},{"title":"web前端面试题","slug":"web前端面试题","date":"2021-03-14T13:01:12.000Z","updated":"2021-03-24T12:36:43.658Z","comments":true,"path":"2021/03/14/web前端面试题/","link":"","permalink":"http://www.innerjquery.club/2021/03/14/web%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"一、原生js和Jquery1.面向对象和面向过程的区别 js是面向过程还是面向过程？一直以来，顶级大师各有各的说法，这里不敢妄加评论。面向过程就是函数式编程，按照传统流程编写一个又一个的函数来解决需求的方式。面向过程适合一个人的项目，如果是团队合作，别人想修改你的代码就不利于维护了。所以下面着重聊聊面向对象。 面向对象就是讲你的需求抽象成一个对象，然后针对这个对象分析其属性和方法。面向对象的主要特点就是封装，继承，多态。 2. this指向 指向this所在的函数或者方法的调用者/拥有者; 3. eval函数的用法 将eval中的字符串作为表达式去使用；使用场景多在模块化规范中比如老版本的requirejs require将加载到的内容eval(content)去执行， 计时器也支持eval，他会将其内容作为表达式去使用； window.setTimeout(“alert(0)”,5000) 计时器也支持eval，他会将其内容作为表达式去使用； 在严格模式(“use strict”)下：eval(“var a=1;alert(a+=111)”) eval有自己的作用域即当前字符串内 4. 算法：函数防抖 函数的防抖就是固定的时间内反复触发事件只执行下一个（即删除前一个事件）， 函数的防抖就是限制函数执行的速度/次数，比如滚动滚动条事件触发的次数非常多，但是我们并不想频繁执行 事件处理函数，处理方式通常由： 设置时间间隔，延迟指定时间执行，指定时间内执行我们return取消掉； 每一次时间触发的时候我们把上一次事件取消掉； 利用延迟器 5. 算法：函数的节流 函数的节流就是限制函数执行的频率，即单位时间内执行的频率固定（即不执行下一个事件）； 处理逻辑就是让短时间内只执行指定次数的函数； 6. 函数的柯里化 函数的柯里化：函数的多参变成单参 比如 1234567function f(a) {return function(b){ return function(c){ a+b+c }}} 把f(1,2,3) = 6 变成 f(1)(2)(3) 7. 作用域链 js中万物接对象，是对象就有一定的属性和方法； 如下中的func方法是全局变量是保存在window下的，那局部变量num和ff是保存在哪里呢就是保存在哪个作用域对象下的，实际上是作用域对象.ff()调用了我们的ff方法 所谓产生一个作用域就是创建了一个作用域对象，将来作用对象里的变量将保存在其作用域对象下： 每一个产生作用域就会创建一个作用域对象； 当我们需要访问我们变量的时候，就会在我们当前作用域对象下去找我们的变量，如果没有就会找上一级的作用域对象上去找我们的变量，直到找到顶层作用域对象window上，这个变量的查找链就是我们的作用域链； 12345678function func(){ var mum = 1 function ff(){ console.log(mum) } ff()}func() 8. 原型链的继承机制 默认的继承机制是prototype JavaScript 中没有类的概念的，主要通过原型链来实现继承。通常情况下，继承意味着复制操作，然而 JavaScript默认并不会复制对象的属性，相反，JavaScript只是在两个对象之间创建一个关联（原型对象指针），这样，一个对象就可以通过委托访问另一个对象的属性和函数，所以与其叫继承，委托的说法反而更准确些 当我们 new 了一个新的对象实例，明明什么都没有做，就直接可以访问 toString 、valueOf 等原生方法。那么这些方法是从哪里来的呢？答案就是原型 在控制台打印一个空对象时，我们可以看到，有很多方法，已经“初始化”挂载在内置的 proto 对象上了。这个内置的 proto 是一个指向原型对象的指针，它会在创建一个新的引用类型对象时（显示或者隐式）自动创建，并挂载到新实例上。当我们尝试访问实例对象上的某一属性 / 方法时，如果实例对象上有该属性 / 方法时，就返回实例属性 / 方法，如果没有，就去 proto 指向的原型对象上查找对应的属性 / 方法。这就是为什么我们尝试访问空对象的 toString 和 valueOf 等方法依旧能访问到的原因，JavaScript 正式以这种方式为基础来实现继承的。 构造函数: 如果说实例的 proto 只是一个指向原型对象的指针，那就说明在此之前原型对象就已经创建了，那么原型对象是什么时候被创建的呢？这就要引入构造函数的概念。其实构造函数也就只是一个普通的函数而已，如果这个函数可以使用 new 关键字来创建它的实例对象，那么我们就把这种函数称为 构造函数。 原型对象正是在构造函数被声明时一同创建的。构造函数被申明时，原型对象也一同完成创建，然后挂载到构造函数的 prototype 属性上：原型对象被创建时，会自动生成一个 constructor 属性，指向创建它的构造函数。这样它俩的关系就被紧密地关联起来了。细心的话，你可能会发现，原型对象也有自己的 proto ，这也不奇怪，毕竟万物皆对象嘛。原型对象的 proto 指向的是 Object.prototype。那么 Object.prototype.proto 存不存在呢？其实是不存在的，打印的话会发现是 null 。这也证明了 Object 是 JavaScript 中数据类型的起源 原型及构造函数的大概关系了，我们可以用一张图来表示这个关系 原型链 说完了原型，就可以来说说原型链了，如果理解了原型机制，原型链就很好解释了。其实上面一张图上，那条被 proto 链接起来的链式关系，就称为原型链。原型链的作用：原型链如此的重要的原因就在于它决定了 JavaScript 中继承的实现方式。当我们访问一个属性时，查找机制如下： 访问对象实例属性，有则返回，没有就通过 proto 去它的原型对象查找。 原型对象找到即返回，找不到，继续通过原型对象的 proto 查找。 一层一层一直找到 Object.prototype ，如果找到目标属性即返回，找不到就返回 undefined，不会再往下找，因为在往下找 proto 就是 null 了。 通过上面的解释，对于构造函数生成的实例，我们应该能了解它的原型对象了。JavaScript 中万物皆对象，那么构造函数肯定也是个对象，是对象就有 proto ，那么构造函数的 proto 是什么？ object 9. js的垃圾回收机制 js的垃圾回收器是定期扫描的； 即变量的回收 算法1就是引用计数法，给每个变量上做上标记，有人要用就标记加1，不停的加一当要用的人不用的时候标记就减一，js会不断扫描我们的内存检查我们的变量，缺点就是产生了很多碎片 算法2.就是复制整理法 10. 引起内存泄漏的常见方法 闭包， 计时器 dom操作比如 let btn = $(“#btn”) ; btn.remove();此时dom元素还是存在内存中的； 11. 展开运算符(…)12. promise对象 普通用法：来实现异步操作： 1234567console.log(eval(\"var a=10000;a\")) let pro = new Promise(function(res,rej){ res(1) }) pro.then(function(result){ console.log(result) }).catch(function(res){ 链式加载 all方法获取到所有的返回值,且方法里的三个异步组是并列开跑的，all方法是所有的跑完了才执行then而Promise.race(promise对象1,promise对象2，promise对象3).then(function(r){alert(r)})race()方法有个特点，只要有一个promise对象完成，就会调用我们的then，也就是说，then只会拿到第一个执行完成的结果； 12345678910function apromise(a=1){ return new Promise(function(res,rej){ res(a+1) })}console.log(eval(\"var a=1000110;a\"))Promise.all([apromise(1),apromise(2),apromise(3)]).then(function(list){ console.log(list)}) 13. 数组的方法：map，flatmap，reduce方法 map用于处理我们数组返回一个新数组,返回的数组长度和原长度一样， 但是flatmap方法会将返回的对象比如元组扁平化，原返回[[1,2,3],[1,2,3],3]会将扁平化为[1,2,3,1,2,3,3] 12345let arr = [1,2,3] new_arr = arr.map(function(r,b,c){ console.log(r,b,c) return [r,r**r,r**r*r]}) reduce函数常用于累积计算注意它会遍历数组length(all) -1次，因为第一次会拿到两个数组中的值，后面遍历将会只拿一个参数，其回调函数的第一个参数是上一次返回的值 123456let arr = [1,2,3,4,5,6,7] nall = arr.reduce(function(a,b,c){ console.log(a,b,c) return a+b }) console.log(nall) 14. 浅拷贝和深拷贝 浅拷贝，只拷贝对象的第一层，深层次的对象的属性和方法拷贝其引用 方法： 遍历、 12345678910111213141516var obj = {a:1,b:2,c:{d:10,e:30}} var obj1 = {} var obj2 = {} for (var item in obj){ obj1[item] = obj[item] } Object.assign(obj2,obj) obj.a = 2 obj.c.d=11111 console.log(obj) console.log(obj1) console.log(obj2) 浅拷贝、深拷贝的方法 使用json序列化对象处理我们的对象获取一个新完全的对象(深拷贝) 但是这样存在一些问题，比如一些set,get等方法，或者后面动态添加的方法丢失，也不是完全的拷贝 1234567var obj = {a:1,b:2,c:{d:10,e:30}}var obj1 = {}var obj2 = {}var obj3 = JSON.parse(JSON.stringify(obj)) 深拷贝的一些方法 123456789101112131415161718192021222324252627282930313233function clone(target,source){ // 获取对象的所有的属性，包括不可遍历的属性 var names = Object.getOwnPropertyNames(source); for (var i=0;i&lt;names.length;i++ ){ var desc = Object.getOwnPropertyDescriptor(source,names[i]) if(typeof(desc.value) == \"object\" &amp; desc.value != null){ var obj; if (Array.isArray(desc.value)) { obj = [] } else { obj = {} } Object.defineProperty(target.names[i],{ configurable:desc.configurable, enumerable:desc.enumerable, value:obj.value, writable:desc.writable }); clone(obj,desc.value) } else { Object.defineProperty(target.names[i],{ // configurable 属性表示不可删除、 configurable:desc.configurable, // enumerable 表示是否可以遍历 enumerable:desc.enumerable, // 值 value:desc.value, // 是否可写 writable:desc.writable }); } }} 15. 了解一下es6的代理Proxy 代理使得一个对象拥有了相关的属性和方法： 用法：var p = new Proxy(obj,handler)使得我们的obj对象拥有了handler的一些属性和方法； 简单来说 代理就是给我们的被代理对象添加一些属性和方法，但是是作用在代理实例化对象上，而不是原被代理对象上 123456789101112131415161718let obj = {a:1,b:2}let handler = { set:function(target,key,value){ target[key] = value }, get:function(target,key){ return target[key] }, has:function(target,key){ return key in target; }}var p = new Proxy(obj,handler)p.a = 20;console.log(obj.p) 16. 两个加载完成事件的区别 $(window).load()和$(window).ready()两个加载完成事件的区别 document文档加载的顺序： html结构加载 加载外部样式表和执行文件 加载并解析执行脚本代码 构造dom模型（样式应用）此时ready事件触发 加载图片文件等等资源 再页面加载完成 此时load事件触发 ready不必等图片媒体进来之前就可以运行代码了，否则load需要等到全部完成后执行； 17. 事件循环Eventloop js任务分为同步任务和异步任务，异步任务主要有宏任务，微任务 js 二、nodejs和项目工程化1. 使用nodejs编写代码实现遍历文件夹及所有文件名2. node如何做版本的升级？为什么要做nvm3. 模块化差异，AMD,CMD,Commonjs,Esmodule,4. 图片上传到服务器的过程(filereader，readAsDataURL)5. token如何存在localstorage里面，过期怎么处理6. node框架中的mvc7. mongodb和mysql的优势8. less(js) ,sass(ruby),stylus,css,命名空间与css module9. 工程化上的按需加载10. git上的冲突怎么解决11. 设计模式12. node中的npm版本管理，package.lock和yarn.lock13. Webpack14. 后端的环境的搭建15. typescript二、Vue相关axios是什么，如何实现登录功能的 通过axios的请求拦截器interceptors完成request、response拦截 vuex统一状态管理","categories":[{"name":"web 前端杂项","slug":"web-前端杂项","permalink":"http://www.innerjquery.club/categories/web-%E5%89%8D%E7%AB%AF%E6%9D%82%E9%A1%B9/"}],"tags":[{"name":"vue 前端面试题","slug":"vue-前端面试题","permalink":"http://www.innerjquery.club/tags/vue-%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"第三方模块引用","slug":"第三方模块引用","date":"2021-03-13T07:08:50.000Z","updated":"2021-03-15T13:48:37.430Z","comments":true,"path":"2021/03/13/第三方模块引用/","link":"","permalink":"http://www.innerjquery.club/2021/03/13/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97%E5%BC%95%E7%94%A8/","excerpt":"","text":"struct 模块1. struct模块来解决bytes和其他二进制数据类型的转换。 相关博客链接 https://blog.csdn.net/weixin_44621343/article/details/112793520 相关博客链接 https://blog.csdn.net/weixin_44621343/article/details/112793520 2. struct模块来解决bytes和其他二进制数据类型的转换。 相关博客链接 https://blog.csdn.net/weixin_44621343/article/details/112793520 相关博客链接 https://blog.csdn.net/weixin_44621343/article/details/112793520 3. python web框架的本质及自定义web框架 https://www.cnblogs.com/clschao/articles/10391859.html","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_其他第三方模块","slug":"python-其他第三方模块","permalink":"http://www.innerjquery.club/tags/python-%E5%85%B6%E4%BB%96%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97/"}]},{"title":"reacc中通过context传递数据","slug":"reacc中通过context传递数据0","date":"2021-01-22T06:13:49.000Z","updated":"2021-03-13T03:32:52.063Z","comments":true,"path":"2021/01/22/reacc中通过context传递数据0/","link":"","permalink":"http://www.innerjquery.club/2021/01/22/reacc%E4%B8%AD%E9%80%9A%E8%BF%87context%E4%BC%A0%E9%80%92%E6%95%B0%E6%8D%AE0/","excerpt":"","text":"Context 传递数据Context提供了一种在组件之间共享值的方式，而不必显式地通过组件树的逐层传递 props。 1. 创建一个Context对象const ThemeContext = React.createContext(); 2.Provider（订阅者）：Provider 接收一个 value 属性，传递给消费者组件。注意：这个value名字是固定的，不能改变，否则后面的消费者组件中获取不到属性值 1&lt;ThemeContext.Provider value={this.state}&gt; 3.Consumer（消费者）：这里，React 组件也可以订阅到 context 变更12345&lt;ThemeContext.Consumer&gt; { value =&gt; &lt;div&gt;{value.name}&lt;/div&gt; }&lt;/ThemeContext.Consumer&gt; 4.Context 完整使用代码：1234567891011121314151617181920212223242526272829303132333435import React, { Component } from 'react';// 创建一个Context对象const ThemeContext = React.createContext();function ThemeBtn(props) { return ( &lt;ThemeContext.Consumer&gt; { value =&gt; &lt;div&gt;{value.name}&lt;/div&gt; } &lt;/ThemeContext.Consumer&gt; )}function ToolBar(props) { return &lt;ThemeBtn&gt;&lt;/ThemeBtn&gt;}class ContextSimple extends Component { constructor(props) { super(props); this.state = { name: '按钮' }; } render() { return ( &lt;ThemeContext.Provider value={this.state}&gt; &lt;ToolBar&gt;&lt;/ToolBar&gt; &lt;/ThemeContext.Provider&gt; ); }}export default ContextSimple;","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"react_context","slug":"react-context","permalink":"http://www.innerjquery.club/tags/react-context/"}]},{"title":"vue-router源码解析","slug":"vue-router源码解析","date":"2021-01-07T04:29:44.000Z","updated":"2021-03-13T03:31:54.459Z","comments":true,"path":"2021/01/07/vue-router源码解析/","link":"","permalink":"http://www.innerjquery.club/2021/01/07/vue-router%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","excerpt":"","text":"手写vue-router插件1.作为一个插件存在，实现VueRouter类和install方法2.定义两个全局组件router-link,和router-view3.监控url变化4.创建响应式的current属性5.路由映射表的创建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 1.作为一个插件存在，实现VueRouter类和install方法let Vue;class XXXVueRouter { constructor(options) { this.$options = options //4.创建响应式的current属性 （可以通过Vue.set()方法设置响应式数据，util设置也可以） Vue.util.defineReactive(this,'current','/') // Vue.set(this,'current','/') //3.此处可以监控url变化 window.addEventListener('hashchange', () =&gt; { console.log(this) this.onHashChange() } ) window.addEventListener('load', () =&gt; { console.log(this) this.onHashChange() } ) //5.路由映射表的创建 this.routeMap = {} options.routes.forEach(route =&gt; { this.routeMap[route.path] = route }) } onHashChange() { console.log(window.location.hash); this.current = window.location.hash.slice(1) }}XXXVueRouter.install = function (_Vue) { Vue = _Vue; Vue.mixin({ beforeCreate(){ if(this.$options.router) {//有router即根实例 Vue.prototype.$router = this.$options.router } } }) //2.定义两个全局组件router-link,和router-view Vue.component('router-link',{ props: { to: { type: String, required: true } }, render:function (h) { //此处不能使用我们的template去渲染元素，因为running-time-only运行时环境下没得编译器 return h('a',{attrs: {href: '#'+this.to}},this.$slots.default) } }) Vue.component('router-view',{ render:function (createElement) { const {routeMap,current} = this.$router const component = routeMap[current].component || null return createElement(component) } })}export default XXXVueRouter","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.innerjquery.club/tags/vue/"}]},{"title":"vue中组件开发中大量使用的dispatch和broadcast","slug":"vue中组件开发中大量使用的dispatch和broadcast","date":"2021-01-04T12:43:37.000Z","updated":"2021-03-13T03:31:47.815Z","comments":true,"path":"2021/01/04/vue中组件开发中大量使用的dispatch和broadcast/","link":"","permalink":"http://www.innerjquery.club/2021/01/04/vue%E4%B8%AD%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B8%AD%E5%A4%A7%E9%87%8F%E4%BD%BF%E7%94%A8%E7%9A%84dispatch%E5%92%8Cbroadcast/","excerpt":"","text":"1.在使用 Element 过程中组件通信大量使用 dispatch 和 broadcast 两个方法，之vue2 组件通信 也提到过 vue2 中取消了 $dispatch 和 $broadcast 两个重要的事件，而 Element 重新实现了这两个函数，通过下方可简单认识一下这两个方法 2. 1234567891011121314151617181920212223242526272829303132\"use strict\";exports.__esModule = true;function _broadcast(componentName, eventName, params) { this.$children.forEach(function (child) { var name = child.$options.componentName; if (name === componentName) { child.$emit.apply(child, [eventName].concat(params)); } else { _broadcast.apply(child, [componentName, eventName].concat([params])); } });}exports.default = { methods: { dispatch: function dispatch(componentName, eventName, params) { var parent = this.$parent || this.$root; var name = parent.$options.componentName; while (parent &amp;&amp; (!name || name !== componentName)) { parent = parent.$parent; if (parent) { name = parent.$options.componentName; } } if (parent) { parent.$emit.apply(parent, [eventName].concat(params)); } }, broadcast: function broadcast(componentName, eventName, params) { _broadcast.call(this, componentName, eventName, params); } }}; 3分析 1）dispatch 和 broadcast 方法都需要 3 个参数，componentName 组件名称， eventName 事件名称， params 传递的参数。 2）dispatch 方法会寻找所有的父组件，直到找到名称为 componentName 的组件，调用其 $emit()事件。broadcast 方法则是遍历当前组件的所有子组件，找到名称为 componentName 的子组件，然后调用其 $emit() 事件。4.vue 组件通信方式总结父组件向子组件传递信息使用 props down子组件向父组件传递信息使用 event up其它关系类型组件通信使用 global event bus大型 SPA 组件之间通信使用 Vuex 管理组件状态使用 Element 下 emitter.js 中的 dispatch 和 broadcast 做事件定向传播","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.innerjquery.club/tags/vue/"}]},{"title":"微信小程序环境下的js","slug":"微信小程序环境下的js","date":"2021-01-01T15:41:10.000Z","updated":"2021-03-13T03:33:40.261Z","comments":true,"path":"2021/01/01/微信小程序环境下的js/","link":"","permalink":"http://www.innerjquery.club/2021/01/01/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84js/","excerpt":"","text":"1.json文件里不能注释，非主页面json文件可以覆盖app.json文件 页面里的配置内容只可以设置window下的一些配置 tabbar标签条中只能有2-5个标签，2.微信小程序的开发语言是js但是不同于浏览器运行环境的javascript ==》首先没有bom和dom对象模型，所以没有对象window和document对象， ==》小程序运行环境的javascript拥有的额外的全局成员（方法）有： App() 方法用于定义应用程序对象； Page() 方法用于定义页面对象； getApp() 方法用于获取全局应用程序对象 getcurrentPages() 方法用于获取当前页面的调用栈 ==》微信小程序中js的顶级对象是wx，微信小程序端还提供了一些核心的对象； 微信小程序环境的js是支持commonjs规范的（和nodejs的模块开发相似），但是不支持直接export导出对象 在0.10版本之后默认使用 babel 将开发者 ES6 语法代码转换为三端都能很好支持的 ES5 的代3.语法知识： ==》支持插值表达式，且插值表达式可以放在我们的类中动态管理类class = “ into { {addclass} }”,可以用在任意值的位置 ==》在小程序运行环境下的复选框checked =“false”（不会被当成布尔类型，使得复选框被勾选，），可以以插值表达式 表示一个false，checked = “{ {false} }” ==》小程序中的循环语句为： 12345678910111213 todos: [ { name: 'java', completed: false }, { name: 'php', completed: true }, { name: 'vue', completed: false }, { name: 'javascript', completed: true , { name: 'phpstudy', completed: false }, { name: 'vuex', completed: false } ]&lt;view wx:for=\"{ { todos } }\" wx:key=\"item\"&gt; &lt;checkbox checked=\"{ { item.completed } }\" &gt;&lt;/checkbox&gt; &lt;text&gt;-------{ {item.name} }&lt;/text&gt;&lt;/view&gt; 注意：在当前循环作用域内如有全局对象index和item会冲突访问不到，当前作用域内的index和item 会被当做循环的当前对象和当前索引； 解决方法： 通过wx：for-item =”aaa“即为当前作用域遍历的对象起个别名为aaa，index也可以这样子起别名6.小程序里提供的事件和window对象下的事件的区别；（小程序端没有鼠标概念，只有tap触摸概念） 给元素添加触摸事件的方法：bindtap = “todo”//行内事件也不需要添加小括号，区别于pc端js 默认情况下，小程序的开发也会冒泡事件,但是阻止冒泡的方式是通过catchtap事件， 即bindtap会有事件冒泡机制，但是无法阻止，catchtap不会产生冒泡，7.事件传参的方法也显著区别于浏览器运行环境下的js 不能通过函数传参的方法传递参数，语法不允许，实际上bindtap=”type()”中的type()会被当做一个整体函数名 有点莫名奇妙，但是不得不接受官方， 同时也不可通过事件处理函数中的this指向调用该方法的对象即元素，因为在小程序的运行环境中，this会直接指向当前页面的pages对象， 可以通过dataset属性获取到我们自定义的属性值（dataset相似于浏览器运行环境中的data-开头的自定义数据的集合） 1234567 &lt;button bindtap=\"type\" data-name=\"张三\" data-id=\"zhansan\"&gt;456&lt;/button&gt;console.log(e.target.dataset){id: \"zhansan\", name: \"张三\"}id: \"zhansan\"name: \"张三\"__proto__: Object 小程序没有双向数据绑定，所有的数据都是单向的，当通过插值表达式从逻辑层拿到数据到界面时，不再监听数据的变化，（不会像vue那样监听数据） 只能再通知小程序这个框架去渲染数据 this.setData({ testmsg: e.target.value})","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"wx api","slug":"wx-api","permalink":"http://www.innerjquery.club/tags/wx-api/"}]},{"title":"vuex的使用","slug":"vuex的使用","date":"2020-12-31T14:24:30.000Z","updated":"2021-03-13T03:31:41.589Z","comments":true,"path":"2020/12/31/vuex的使用/","link":"","permalink":"http://www.innerjquery.club/2020/12/31/vuex%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"（两个指令的区别） vue add vuex:该方法添加插件会改变原有项目结构，即对新添加的插件进行初始化操作； npm install vuex 该方法只下载第三方插件或者模块，不做初始化资源的配置； 使用场景/好处：vuex集中管理共享的数据，易于开发和后期维护 能够高效的实现组件之间的数据共享，提高开发效率 储存再vuex中的数据都是响应式的，能够实时保持数据和页面的同步 组件之间需要共享的数据储存再我们的vuex中，组件私有数据储存在我们的data中即可 坏处：条条框框特别多，当页面应用程序组件树不大时还不如通过（组件树/事件总栈）进行数据访问 1.vuex是一个专门为vue.js应用程序开发的状态管理模式，它应用集中式储存管理应用的所有组件的状态，并以对应的规则保证状态以可预测的方式发生变化； 通过vuex可以很方便的实现组件之间的数据共享； 2.vue add vuex 下载我们的插件,默认会生成store文件夹； 3.import store from ‘./store/index.js’引入模块，该添加插件方法会默认配置 4.访问store仓库下state数据源的方法有以下两种： 1==》 1this.$store.state[数据名] 2==》 1234import {mapstate} from \"vuex\" //按需导入mapstate方法 computed: { ...mapstate([数据名1，数据名2]) //（...）是展开运算符 }//组件中即可直接使用数据名5.通过mutations属性下定义的方法修改，组件中不可直接修改共享状态state（可以但没必要，不方便管理数据）， 1==》 12345678910111213mutations: { login (state) { state.isLogin = true }, add: function (state) { state.count++ }, sub: function (state,step) { state.count -= step } },` 在组件中通过this.$store.commit(方法名，参数)通知mutations去修改数据 2==》 1234567import {mapMutation} from 'vuex' methods: { ...mapMutation(['subN'，'方法2']) //简单理解就是将vuex中的mutation里方法映射过来成为本身组件subcountt: function (msg) { this.subN(msg)//映射为组件本身的方法之后就可以向调用自有方法一样调用mutations里的方法 }` }6.mutation中不支持直接进行异步操作，在store里执行异步操作依赖于action（虽然action还是通过触发mutation间接变更数据） 1==》在store对象的actions属性下定义我们的异步任务： 1234567891011addAsync(context,接受携带的数据) { //context暂时理解为仓库store实例对象，具体不也不知 setTimeout(() =&gt; { context.commit('mutations里的方法') //此处不能直接访问state，通过提交mutation才行，vuex官方说的 },1000) }` 在我们的组件的mothods里定义好的方法中发起actions `methods： { handle: function(){ this.$store.dispatch('addAsync',携带的数据)//addAsync为action里的异步任务 } } 2==》从vuex按需导入我们的mapactions函数，再将指定的actions函数映射为组件自有的methods函数 123456789import {mapactions} from ‘vuex’methods： {...mapActions(['actions中异步任务1','actions中的异步任务2'])//将全局中的某些函数映射成为自身方法subAsyncto: function () { this.subAsync() //&lt;button @click=\"subAsyncto\"&gt;async-1&lt;/button&gt; //差点调用函数自身进入死循环了，此处应该和actions里的异步任务函数区别开来}` 7.store实例化对象中的getter方法用于对state中的数据进行加工输出，但是该方法并不会改变数据源，使用getter的方法有 12345678910getters: { teststring: function (state) { return '当前的数据('+state.msg+')已经加工过s了' } }this.$store.getters.teststringimport {mapGetters} from 'vuex'computed: { ...mapGetters(['testing']) }","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.innerjquery.club/tags/vue/"}]},{"title":"vs code插件合集[C","slug":"vs-code插件合集-C","date":"2020-12-30T11:12:42.000Z","updated":"2021-03-24T12:23:21.283Z","comments":true,"path":"2020/12/30/vs-code插件合集-C/","link":"","permalink":"http://www.innerjquery.club/2020/12/30/vs-code%E6%8F%92%E4%BB%B6%E5%90%88%E9%9B%86-C/","excerpt":"","text":"title: vs code 的几个实用性插件date: 2020-12-30 14:46:55tags: 1.Chinese (Simplified) Language Pack ==&gt; 中文语言包 2.Auto Close Tag ==&gt; 自动添加HTML / XML关闭标签 3.Auto Rename Tag ==&gt; 自动重命名配对的HTML / XML标签 4.Bracket Pair Colorizer ==&gt; 用不同颜色高亮显示匹配的括号,对配对的括号 进行着色，方便区分，未安装该插件之前括号统一都是白色的 5.Color Info ==&gt; 提供你在 CSS 中使用颜色的相关信息在颜色上悬停光标，就可以预览色块中色彩模型的（HEX、 RGB、HSL 和 CMYK）相关信息，点击还可以切换颜色模式 6.colorize ==&gt; 在设置下面直接显示颜色，更直观的知道你设置的是什么颜色，同时也支持Less、Sass的变量 7.vscode-fileheader ==&gt; 顶部注释模板，可定义作者、时间等信息，并会自动更新最后修改时间 快捷键: Ctrl+Alt+i 8.Highlight Matching Tag ==&gt; 高亮显示匹配标签,这个插件自动帮我们将选中的匹配标签高亮显示，再也不用费劲查找了。 9.TODO Highlight ==&gt; 高亮,如果我们在编写代码时想在某个地方做一个标记，后续再来完善或者修改里面的内容，可以利用此插件高亮显示，之后可以帮助我们快速定位到需要修改的代码行。 IntelliSense for CSS class names in HTML ==&gt; 在 HTML 中调用定义好的样式名时，有时需要经常在 HTML 与 CSS 文件之间切换，来回地查看你已定义好的 CSS 类名。而有了 IntelliSense for CSS class names in HTML 插件后，你可以在 HTML 中需要调用 CSS 类名的地方，此插件会智能地给你已定义 CSS 类名的提示。 11.Regex Previewer ==&gt; 这是一个用于实时测试正则表达式的实用工具。它可以将正则表达式模式应用在任何打开的文件上，并高亮所有的匹配项 12.Markdown Preview Enhanced ==&gt; 实时预览markdown，markdown使用者必备 markdownlint ==&gt; markdown语法纠错 14.Code Runner ==&gt; 非常强大的一款插件，能够运行多种语言的代码片段或代码文件：C，C ++，Java，JavaScript，PHP，Python，Perl，Ruby，Go等等安装完成后，右上角会出现：▶ 15.Debugger for Chrome ==&gt; 直接在vscode里面进行调试js文件，跟谷歌的控制台是一样的功能，下载了它就不用打开浏览器的控制台就能进行打断点。 16.Live Server 实时预览 ==&gt; 安装这个插件之后，我们在编辑器中修改代码，按Ctrl+S保存，修改效果就会实时同步，显示在浏览器中，再不用手动刷新。 17.Beautify ==&gt; 格式化代码 18.Prettier ==&gt; Prettier 是目前 Web 开发中最受欢迎的代码格式化程序。安装了这个插件，它就能够自动应用 Prettier，并将整个 JS 和 CSS 文档快速格式化为统一的代码样式 19.HTML Snippets ==&gt; 超级实用且初级的 H5代码片段以及提示 20.TML CSS Support ==&gt; 让 html 标签上写class 智能提示当前项目所支持的样式新版已经支持scss文件检索 21.HTMLHint ==&gt; HTML 代码格式检测 22.ESlint ==&gt; ESlint 接管原生 js 提示，可以自定制提示规则 23.JavaScript (ES6) code snippets ==&gt; es6代码片段 24.Code Spell Checker ==&gt; 我们在编写代码的时候经常会不小心拼写错误造成软件运行失败，安装这个插件后会自动帮我们识别单词拼写错误并且给出修改建议，大大帮我们减轻了排除bug的压力 25.jQuery Code Snippets ==&gt; jQuery代码智能提示 26.Path Intellisense ==&gt; 路径自动补全 27.SVG Viewer ==&gt; 此插件在 Visual Studio 代码中添加了许多实用的 SVG 程序，你无需离开编辑器，便可以打开 SVG 文件并查看它们。同时，它还包含了用于转换为 PNG 格式和生成数据 URI 模式的选项 28.Import Cost ==&gt; 引入包大小计算,对于项目打包后体积掌握很有帮助 29.Version Lens ==&gt; 工具包版本信息 30.Minify ==&gt; 这是一款用于压缩合并 JavaScript 和 CSS 文件的应用程序。它提供了大量自定义的设置，以及自动压缩保存并导出为.min文件的选项。它能够分别通过 uglify-js、clean-css 和 html-minifier，与 JavaScript、CSS 和 HTML 协同工作。 31.Git History ==&gt; 以图表的形式查看 git 日志 32.Easy LESS ==&gt; Less编译工具 33.Easy Sass ==&gt; Sass编译工具 34.vueHelper ==&gt; 可能是目前vscode最好的vue代码提示插件，不仅包括了vue2所有api，还含有vue-router2和vuex2的代码提示,同时它可以支持代码高亮，在vue文件中部分支持html/jade/pug的高亮，style部分支持css/scss/less/stylus的高亮，script部分支持js/ts的高亮 35.Vetur ==&gt; Vue多功能集成插件，包括：语法高亮，智能提示，emmet，错误提示，格式化，自动补全，debugger。vscode官方钦定Vue插件，Vue开发者必备。 36.vscode-icon ==&gt; 让 vscode 资源树目录加上图标，必备良品！","categories":[{"name":"web 前端杂项","slug":"web-前端杂项","permalink":"http://www.innerjquery.club/categories/web-%E5%89%8D%E7%AB%AF%E6%9D%82%E9%A1%B9/"}],"tags":[{"name":"vs code","slug":"vs-code","permalink":"http://www.innerjquery.club/tags/vs-code/"}]},{"title":"element ui 的理解","slug":"element-ui-的理解","date":"2020-11-03T15:39:46.000Z","updated":"2021-03-24T12:34:13.843Z","comments":true,"path":"2020/11/03/element-ui-的理解/","link":"","permalink":"http://www.innerjquery.club/2020/11/03/element-ui-%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"好处：对深入vue底层源码和ui组件库的开发有一定的帮助 1.通过自定事件总栈深入理解vue事件总栈 1234567891011121314151617class Buf { constructor () { this.callbacks = {} } $on(name,fn) { this.callbacks[name] = this.callbacks[name] || [] this.callbacks[name].push(fn) } $emit(name,args){ if(this.callbacks[name]) { this.callbacks[name].forEach(ele =&gt; { ele(args) }); } }}Vue.prototype.$buf = new Buf() //将buff的实例化对象挂载到vue的原型上 2.通过$parents和$children组件访问属性完成组件间交互 123456this.$parent.$emit('parentto-child2','我通过父元素找到了child2') //在当前组件内通过组件访问属性$parent获取父元素组件实例对象，分发一个prentto-child2事件并且传参this.$children[0].todo() //通过$children组件访问属性获取到子组件，即可使用子组件下定义的方法this.$children[0].$emit('link-child1','父元素给child1发的一些信息')//通过$children拿到的数组不保证顺序的，其不是按template模板结构的顺序排列的 3.$attrs和$listeners实现组件间交互//父组件通过属性绑定的方式添加给子组件，但是子组件并未通过props的方式接受数据被放置于$attrs对象下 123&lt;div&gt;{ {$attrs.msg} }&lt;/div&gt;&lt;h2 v-on=\"$listeners\"&gt;123&lt;/h2&gt;//通过$listeners可以监听给该组件绑定并触发事件的组件对象 4.通过provide/reject对象实现任意辈分组件间访问 123456789//通过provide可以向外界组件提供数据接口，通过inject注入数据//该方法也可实现任意组件之间的数据访问，在组件开发时经常使用provide:function () { return { fo: '0000ss', comp: this } },inject:['fo','comp'], 5.插槽的用法 123456789101112131415161718192021222324252627282930//template是slot组件的模版&lt;slot-com&gt; &lt;template v-slot:header&gt;sdafdsa&lt;/template&gt; &lt;template&gt;sdafdsafdsafdsafdsa&lt;/template&gt; &lt;template v-slot:footer=\"fc\"&gt;{ {fc.msg} }&lt;/template&gt;&lt;/slot-com&gt;&lt;template&gt; &lt;div&gt; &lt;div class=\"header\"&gt; &lt;slot name=\"header\"&gt;&lt;/slot&gt; &lt;/div&gt; &lt;div class=\"content\"&gt; &lt;slot &gt;&lt;/slot&gt; &lt;/div&gt; &lt;div class=\"footer\"&gt; &lt;!-- 通过作用域插槽，父元素可以拿到子元素的值 --&gt; &lt;slot name=\"footer\" v-bind:msg='msg'&gt;&lt;/slot&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default { data: function () { return { msg: '我是子组件想传递给父组件的数据' } } }&lt;/script&gt; 6熟悉以上用法就可以直接手撸element ui组件库了，深入element ui组件库源码；1）从简单的kinput组件开始封装 123456789101112131415161718192021222324252627282930313233343536&lt;template&gt; &lt;div&gt; &lt;input :type=\"type\" v-bind:value=\"value\" @input=\"oninput\"&gt; &lt;p&gt; { {value} } &lt;/p&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default { data: function () { return { } }, props: { value: { type: String, default: '' }, type: { type: String, default: 'text' } }, methods: { oninput: function (e) { this.$emit('input',e.target.value) } } }&lt;/script&gt;&lt;style lang=\"scss\" scoped&gt;&lt;/style&gt; 2）封装kinput组件的父组件kformitem 12345678910111213141516171819202122232425262728&lt;template&gt; &lt;div&gt; &lt;slot name=\"default\"&gt;&lt;/slot&gt; &lt;label v-if=\"label\"&gt;{ {label} }&lt;/label&gt; &lt;p v-if=\"error\"&gt;{ {error} }&lt;/p&gt; &lt;p&gt;{ {form.rules} }&lt;/p&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default { inject: ['form'], data:function () { return { error: '' } }, props:{ label: { type: String, default: '' } } }&lt;/script&gt;&lt;style lang=\"less\" scoped&gt;&lt;/style&gt; 3）封装kformitem的父元素表单元素 12345678910111213141516171819202122232425262728&lt;template&gt; &lt;div&gt; &lt;slot name=\"default\"&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default { provide: function () { return { form: this } }, props: { model: { type: Object, required: true }, rules: { type: Object } } }&lt;/script&gt;&lt;style lang=\"less\" scoped&gt;&lt;/style&gt; 4）这样一个简单的表单元素功能就封装好了；可以在我们组件中使用了 1234567891011121314151617181920212223242526272829303132333435363738&lt;template&gt; &lt;div class=\"content\"&gt; &lt;kform v-bind:model='userInfo' v-bind:rules='rules'&gt; &lt;kinputitem&gt; &lt;kinput v-model=\"userInfo.username\"&gt;&lt;/kinput&gt; &lt;/kinputitem&gt; &lt;/kform&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import kinput from '../components/kinput' import kinputitem from '../components/kformitem' import kform from '../components/kform' export default { components: { kinput,kinputitem,kform }, data: function () { return { userInfo: { username: 'todo', password: '', }, rules: { username: [{requried: true, message: '请输入用户名称'}], password: [{requried: true, message: '请输入密码'}] } } } }&lt;/script&gt;&lt;style lang=\"less\" scoped&gt;.content{ padding: 30px 50px;}&lt;/style&gt;","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"vue ui","slug":"vue-ui","permalink":"http://www.innerjquery.club/tags/vue-ui/"}]},{"title":"关于axios","slug":"My-New-Post","date":"2020-10-30T10:14:19.000Z","updated":"2021-03-13T03:33:21.925Z","comments":true,"path":"2020/10/30/My-New-Post/","link":"","permalink":"http://www.innerjquery.club/2020/10/30/My-New-Post/","excerpt":"","text":"参考来源===》》http://axios-js.com/zh-cn/docs/ 1.Axios 是一个基于 promise 的 HTTP 库，可以用在浏览器和 node.js 中。 特性===》》从浏览器中创建 XMLHttpRequests，从 node.js 创建 http 请求，支持 Promise API，拦截请求和响应转换请求数据和响应数据，取消请求，自动转换 JSON 数据，客户端支持防御 XSRF 3.使用：$ npm install axios（服务器安装axios模块api） （客户端使用cdn下载库文件） 4.//发送get请求 为给定 ID 的 user 创建请求axios.get('/user?ID=12345') .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); // 上面的请求也可以这样做axios.get('/user', { params: { ID: 12345 } }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); });* post===》发送post请求：****axios.post('/user', { firstName: 'Fred', lastName: 'Flintstone' }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); });*执行多个并发请求*****`function getUserAccount() { return axios.get(‘/user/12345’);} function getUserPermissions() { return axios.get(‘/user/12345/permissions’);} axios.all([getUserAccount(), getUserPermissions()]) .then(axios.spread(function (acct, perms) { // 两个请求现在都执行完成 }));` 5.相关请求方式（别名）有axios.request(config) axios.get(url[, config]) axios.delete(url[, config]) axios.head(url[, config]) axios.options(url[, config]) axios.post(url[, data[, config]]) axios.put(url[, data[, config]]) axios.patch(url[, data[, config]])在使用别名方法时， url、method、data 这些属性都不必在配置中指定。 6.相关配置{ // url 是用于请求的服务器 URL url: ‘/user’, // method 是创建请求时使用的方法 method: ‘get’, // default // baseURL 将自动加在 url 前面，除非 url 是一个绝对 URL。 // 它可以通过设置一个 baseURL 便于为 axios 实例的方法传递相对 URL baseURL: ‘https://some-domain.com/api/', // transformRequest 允许在向服务器发送前，修改请求数据 // 只能用在 ‘PUT’, ‘POST’ 和 ‘PATCH’ 这几个请求方法 // 后面数组中的函数必须返回一个字符串，或 ArrayBuffer，或 Stream transformRequest: [function (data, headers) { // 对 data 进行任意转换处理 return data; }], // transformResponse 在传递给 then/catch 前，允许修改响应数据 transformResponse: [function (data) { // 对 data 进行任意转换处理 return data; }], // headers 是即将被发送的自定义请求头 headers: {‘X-Requested-With’: ‘XMLHttpRequest’}, // params 是即将与请求一起发送的 URL 参数 // 必须是一个无格式对象(plain object)或 URLSearchParams 对象 params: { ID: 12345 }, // paramsSerializer 是一个负责 params 序列化的函数 // (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/) paramsSerializer: function(params) { return Qs.stringify(params, {arrayFormat: ‘brackets’}) }, // data 是作为请求主体被发送的数据 // 只适用于这些请求方法 ‘PUT’, ‘POST’, 和 ‘PATCH’ // 在没有设置 transformRequest 时，必须是以下类型之一： // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams // - 浏览器专属：FormData, File, Blob // - Node 专属： Stream data: { firstName: ‘Fred’ }, // timeout 指定请求超时的毫秒数(0 表示无超时时间) // 如果请求话费了超过 timeout 的时间，请求将被中断 timeout: 1000, // withCredentials 表示跨域请求时是否需要使用凭证 withCredentials: false, // default // adapter 允许自定义处理请求，以使测试更轻松 // 返回一个 promise 并应用一个有效的响应 (查阅 response docs). adapter: function (config) { /* … */ }, // auth 表示应该使用 HTTP 基础验证，并提供凭据 // 这将设置一个 Authorization 头，覆写掉现有的任意使用 headers 设置的自定义 Authorization头 auth: { username: ‘janedoe’, password: ‘s00pers3cret’ }, // responseType 表示服务器响应的数据类型，可以是 ‘arraybuffer’, ‘blob’, ‘document’, ‘json’, ‘text’, ‘stream’ responseType: ‘json’, // default // responseEncoding indicates encoding to use for decoding responses // Note: Ignored for responseType of ‘stream’ or client-side requests responseEncoding: ‘utf8’, // default // xsrfCookieName 是用作 xsrf token 的值的cookie的名称 xsrfCookieName: ‘XSRF-TOKEN’, // default // xsrfHeaderName is the name of the http header that carries the xsrf token value xsrfHeaderName: ‘X-XSRF-TOKEN’, // default // onUploadProgress 允许为上传处理进度事件 onUploadProgress: function (progressEvent) { // Do whatever you want with the native progress event }, // onDownloadProgress 允许为下载处理进度事件 onDownloadProgress: function (progressEvent) { // 对原生进度事件的处理 }, // maxContentLength 定义允许的响应内容的最大尺寸 maxContentLength: 2000, // validateStatus 定义对于给定的HTTP 响应状态码是 resolve 或 reject promise 。如果 validateStatus 返回 true (或者设置为 null 或 undefined)，promise 将被 resolve; 否则，promise 将被 rejecte validateStatus: function (status) { return status &gt;= 200 &amp;&amp; status &lt; 300; // default }, // maxRedirects 定义在 node.js 中 follow 的最大重定向数目 // 如果设置为0，将不会 follow 任何重定向 maxRedirects: 5, // default // socketPath defines a UNIX Socket to be used in node.js. // e.g. ‘/var/run/docker.sock’ to send requests to the docker daemon. // Only either socketPath or proxy can be specified. // If both are specified, socketPath is used. socketPath: null, // default // httpAgent 和 httpsAgent 分别在 node.js 中用于定义在执行 http 和 https 时使用的自定义代理。允许像这样配置选项： // keepAlive 默认没有启用 httpAgent: new http.Agent({ keepAlive: true }), httpsAgent: new https.Agent({ keepAlive: true }), // ‘proxy’ 定义代理服务器的主机名称和端口 // auth 表示 HTTP 基础验证应当用于连接代理，并提供凭据 // 这将会设置一个 Proxy-Authorization 头，覆写掉已有的通过使用 header 设置的自定义 Proxy-Authorization 头。 proxy: { host: ‘127.0.0.1’, port: 9000, auth: { username: ‘mikeymike’, password: ‘rapunz3l’ } }, // cancelToken 指定用于取消请求的 cancel token // （查看后面的 Cancellation 这节了解更多） cancelToken: new CancelToken(function (cancel) { })} 7.响应结构；{ // data 由服务器提供的响应 data: {}, // status 来自服务器响应的 HTTP 状态码 status: 200, // statusText 来自服务器响应的 HTTP 状态信息 statusText: ‘OK’, // headers 服务器响应的头 headers: {}, // config 是为请求提供的配置信息 config: {}, // ‘request’ // request is the request that generated this response // It is the last ClientRequest instance in node.js (in redirects) // and an XMLHttpRequest instance the browser request: {}} 8.以如下方式接受下面响应；axios.get('/user/12345') .then(function(response) { console.log(response.data); console.log(response.status); console.log(response.statusText); console.log(response.headers); console.log(response.config); }); 9.进行axios全局配置；axios.defaults.baseURL = 'https://api.example.com'; axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; 10.请求和响应的拦截器；// 添加请求拦截器axios.interceptors.request.use(function (config) { // 在发送请求之前做些什么 return config; }, function (error) { // 对请求错误做些什么 return Promise.reject(error); }); // 添加响应拦截器axios.interceptors.response.use(function (response) { // 对响应数据做点什么 return response; }, function (error) { // 对响应错误做点什么 return Promise.reject(error); });","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"js_axios","slug":"js-axios","permalink":"http://www.innerjquery.club/tags/js-axios/"}]},{"title":"mongodb和pymongo模块","slug":"mongodb和pymongo模块","date":"2020-10-13T03:42:45.000Z","updated":"2021-03-24T12:34:28.962Z","comments":true,"path":"2020/10/13/mongodb和pymongo模块/","link":"","permalink":"http://www.innerjquery.club/2020/10/13/mongodb%E5%92%8Cpymongo%E6%A8%A1%E5%9D%97/","excerpt":"","text":"nosql：mongodbmongodb说明 mongo的客户端是js运行环境的，我们可以写任意js代码； mongo里面的对象是js对象，且mongo里面是支持写任何js函数的， mongodb:查看帮助：mongod -help启动：sudo service mongod start停止: sudo service mongod stop重启：sudo service mongod restart查看是否启动成功： ps ajx|grep mondod查看配置文件： /etc/mongod.conf默认端口：27017日志 mongo是一个非关系的关系型数据库，非关系型数据库通常是以键值对的形式存在； mongo是一个扩展性强的数据库， 安装添加环境变量就可以了 以上我们只是开启了mongod服务器，我们可以mongo开启客户端就可以使用交互式命令了 mongo语法对数据库和集合的操作 show databases; use 数据库名： db.dropdatabase();删除数据库 注意：mongodb是没有表这个概念的，一般称作为一个集合： db.createCollection(name,options) 配置对象的capped属性true值表示设置上限size属6. 性表示10个字节，超过旧值被覆盖， db.集合名.drop()删除集合； 数据类型：string，boolean integer double浮点型 arrays数组 object用于嵌入式的文档，null timestamp时间错，注意：mongod 创建日期的语法如下：new date（xxxx-mm-dd）, 注意每一个文档都有一个属性，_id保证文档的唯一性，如果我们不提供，mongod内置提供，object id即是每个文档的唯一id， 其前四个字节为当前时间搓，下三个为机器id后两个为mongod服务进程id，最后三个为简单增量值； 插入数据的操作 利用数据库下的test100集合下的insertapi插入一个对象：db.test100.insert({“sda”:”sdafdsaf”})db.test100.insert({“name”:”xiaoming”}) db.test100.find()查找集合下的所有数据：所有的对象{ “_id” : ObjectId(“6043ab203f993b072f5e9500”), “name” : “xiaoming” }{ “_id” : ObjectId(“6043acfa3f993b072f5e9501”), “sda” : “sdafdsaf” } 每一个集合有多个文档，文档就是每次插入的唯一标识，它都带有一个唯一标识_id 11.db.test100.save({‘_id’:’sad’,’s’:’sa’})保存一个保存一个对象，注意如果此时id发生冲突将覆盖旧的且不会报错，但是insert插入一个对象可能会冲突报错： 更新数据的操作 db.集合名.update(条件，新值，配置参数)db.test100.update({name:’xiaoming’},{name:’xiaozhao’}) 注意：此时是 把第一个参数条件为name = xiaoming的对象值该为后面这个对象，如果原来还有键值对将丢失，即将满足条件的对象完全替换成后面的新对象 注意：db.test100.update({name:”ds”},{$set:{name:”dsafdsa”}}); 后面的更新的对象里面的$set字段键表示更新，某些字段，不能直接写新键值对对象； 注意：如果不指定update方法的第三个参数的multi属性为true是不会修改多条记录的，只会替换一条记录， 删除数据的操作 db.集合名.remove（条件，配置参数） 注意：默认请求下会删除集合中的满足条件的记录，如果有配置参数属性justone为true则只删除一条 数据的查询操作 额外：pretty()方法可以美化输出： db.test100.find({age:10}) 查找满足脚尖age的所有数据； db.test100.findOne({age:10}) 查找满足条件的一个数据 比较运算符：默认是等于：没有运算符：$gl,$lt $lte,$gte $ne: 分别表示大于、小于，大于等于，小于等于：用法：db.test100.find({age:{$gt:10}}) 表示查找所有年纪大于10的所有记录 $in 表示在什么范围、$nin表示不在什么范围 范围运算符运算符号：db.test100.find({age:{$in:[12,34,545]}) 多条件查询：db.test100.find({age:{$gt:50},index:”212”}) 查询多个条件的书 逻辑运算符：或逻辑查询：db.test100.find( { $or:[ {age:10},{age:221} ] ,name:”agsse” } )这是查找age是10或者221的且name值为agsse的数据没有逻辑且，直接写多个键值对作为条件即可，没有逻辑非，直接$ne表示不等于就行了 支持正则表达式：db.test100.find({index:/^abc/}) 查找键index的值以abc开头的所有记录： 支持限制和跳跃获取数据：limit(整形数字) 、skip（整形数字） 条约多少个 自定义查询条件，查询条件为js函数， 12345678910111213141516171819db.test100.find({ $where:function(){ return this.age&gt;30 }})&lt;!-- 注意：自定义的js函数必须要有返回值：$where表示自定义查询条件：10.通过第二个配置参数指明需要查看的字段，必须为键值对类型，需要查看则写1，不需要查看旧不写 --&gt;db.test100.find({},{asd:1})&lt;!-- 查看所有的记录但是只查看我们的asd字段，没有该字段的显示空记录， --&gt;{ \"_id\" : ObjectId(\"6043ab203f993b072f5e9500\") }{ \"_id\" : ObjectId(\"6043acfa3f993b072f5e9501\") }{ \"_id\" : ObjectId(\"6043b1bb5cd69f8fe4a00ee6\"), \"asd\" : \"sadf\" }{ \"_id\" : ObjectId(\"6043c1a75cd69f8fe4a00ee7\"), \"asd\" : \"sad\" }{ \"_id\" : ObjectId(\"6043c1cb5cd69f8fe4a00ee8\") }{ \"_id\" : ObjectId(\"6043c1e35cd69f8fe4a00ee9\") }{ \"_id\" : ObjectId(\"6043c1fa5cd69f8fe4a00eea\") } 排序：db.test100.find().sort({age:1}) 以age字段对记录进行排序值为1则是升序，值为-1为降序，如果没有该排序的字段，则显示在最前面：降序则相反，没有显示在最后面； find（）方法的第二个参数为配置选项，第一个参数为条件 count（）统计查询的个数：db.test100.find().count() 查找所有的记录然后统计个数，注意如果没有条件find（）方法可以省略db.test100.count()db.test100.find({age:{$ne:”s”}}).count(); .mongod的投影：返回结果的字典注意：在查询的字段里面_id默认会显示，我们可以通过_id:0这个配置属性来不显示它(其他字段不能这么设置为0不显示这是_id字段的都有写法)，db.test100.find({},{name:1,_id:0}) 消除重复：对某一字段进行去重，db.test100.distinct(“index”) 对index字段进行去重 db.test100.distinct(“index”)[ “sadfsa”, “sad”, “sdaf” ]他会返回不重复的值的列表：db.test100.distinct(“index”,{age:{$ne:”s”}}) 它的第二个参数是一个键值对的条件，返回值为去重的经过筛选的列表： mongodb中的表达式有： $sum$avg$min$max$push 将结果插入一个数组中$first根据查询到的数据获取到第一个$last根据查询到的数据获取到最后一个$$ 数据的聚合操作 聚合aggregate：通常用于进行分组或者过滤等等操作；注意：管道的作用就是将上一次的结果作为下一次命令的条件：在mongodb中文档处理完毕后，通过管道进行下一次的处理：常用的管道有： 分组： 通过某个字段进行分组（通过_id指定分组的依据字段，）， db.test.aggregate({$group:{_id:”$gender”}})他会返回分组的字段：{ “_id” : false }{ “_id” : 0 }{ “_id” : 1 }在分组的时候通过count进行统计，他会返回分组的我们这两个id：db.test.aggregate({$group:{_id:”$gender”,count:{$sum:1}}}){ “_id” : false, “count” : 1 }{ “_id” : 0, “count” : 2 }{ “_id” : 1, “count” : 3 }所以：$group分组命令中的字段，就是我们返回的分组中的字段，在分组的使用指定avg字段：然后取平均值{$avg:”$age”} 这里通过age这个字段进行求平均，注意必须使用$db.test.aggregate({$group:{_id:”$gender”,count:{$sum:1},avg_age:{$avg:”$age”}}})注意：我们通常指定分组的_id为null来统计集合中的所有记录：db.test.aggregate({$group:{_id:null,count:{$sum:1}}}){ “_id” : null, “count” : 6 }注意：聚合函数的第二个参数$project可以用来对数据进行一些重命名，或者控制显示的字段，{$avg:”$age”}}},{$project:{gender:”$_id”,count:”$count”,_id:0}}db.test.aggregate({$group:{_id:”$gender”,count:{$sum:1},avg_age:{$avg:”$age”}}},{$project:{gender:”$_id”,count:”$count”,_id:0}}){ “gender” : false, “count” : 1 }{ “gender” : 0, “count” : 2 }{ “gender” : 1, “count” : 3 }注意：在聚合函数中的project属性中，$_id表示取上一次的_id字段的值，相当于管道符的作用，其他字段加$符号也一样 聚合函数的$match用于过滤数据，输出符合条件的文档，match是管道命令，能将结果交给后一个管道，但是find不可以 db.test.aggregate({$match:{age:{$gt:12}}}){ “_id” : ObjectId(“604430205cd69f8fe4a00eed”), “name” : “wanger”, “age” : 21, “gender” : 0 }{ “_id” : ObjectId(“604430375cd69f8fe4a00eee”), “name” : “mazi”, “age” : 20, “gender” : 0 }{ “_id” : ObjectId(“604430535cd69f8fe4a00eef”), “name” : “sidsi”, “age” : 22, “gender” : 1 }{ “_id” : ObjectId(“604431415cd69f8fe4a00ef0”), “name” : “ss”, “age” : 21, “gender” : false }其后还可以接分组等操作，而find不可以：注意：去重不仅可以通过$group进行分组：分组通过所有的字段进行分组依据：{_id:{country:”$country”,age:”$age”}} 等操作就可以完成去重，通过分组的方式，当然了：这也可以通过多键进行分组：注意：聚合函数aggregate（操作1，操作2，操作3）的语法：且后面的操作会以前面操作的返回值的基础上进行操作：这些操作：可以是分组$group $match过滤 $project等等操作：所以：聚合函数的功能就是聚合一些操作，且后续操作是在前面操作的返回值的基础上进行的； $sort 用来对记录进行排序输出，$skip跳过操作，$limit进行取记录限制等等操作： db.test.aggregate({$sort:{age:1}}) 如下操作按照升序进行排序$sum值为1表示升序，-1表示降序，db.test.aggregate({$group:{_id:”$gender”,count:{$sum:1}}},{$sort:{count:1}}){ “_id” : false, “count” : 1 }{ “_id” : 0, “count” : 2 }{ “_id” : 1, “count” : 3 } $unwind等等操作：（它以字段作为值，） 将文档中的某个数组类型的字段拆分为多条，每条包含数组中的一个值，注意这样情况下其他记录没有列表类型的size值将会丢失为了防止这种情况（没有size，或者size属性值不是数组），建议如下操作：db.test1.aggregate({$unwind:”$size”}){ “_id” : 1, “item” : “t-shirt”, “size” : “s” }{ “_id” : 1, “item” : “t-shirt”, “size” : “m” }{ “_id” : 1, “item” : “t-shirt”, “size” : “l” }$unwind分隔字段的第二种用法通过preserveNulAndEmptyArrays:true设置为true防止值丢，db.test.aggregate({&nbsp;&nbsp;$unwind:{&nbsp;&nbsp;&nbsp;&nbsp; path:”$字段”,&nbsp;&nbsp;&nbsp;&nbsp; preserveNulAndEmptyArrays:true&nbsp;&nbsp;}}) 索引的建立操作： 索引的作用：用来提高查询的速度：db.test2.ensureIndex({name:1})通过ensureIndex()方法建立索引，并传入一个js对象db.test3.ensureIndex({name:1}){“createdCollectionAutomatically” : false,“numIndexesBefore” : 1,“numIndexesAfter” : 2,“ok” : 1}注意：索引需要以一个字段作为索引，字段值为1为升序，字段值为-1表示降序，以js对象的形式书写给一个集合建立索引，如果要删除集合建立索引的字段的索引，（注意是删除索引）db.test3.dropIndex({name:1})注意：如果建立的升序索引查看一个集合中的所有索引：db.test.getIndexes();[&nbsp;&nbsp; {&nbsp;&nbsp;&nbsp;&nbsp; “v” : 2,&nbsp;&nbsp;&nbsp;&nbsp; “key” : {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “_id” : 1&nbsp;&nbsp;&nbsp;&nbsp; },&nbsp;&nbsp;&nbsp;&nbsp; “name” : “id“,&nbsp;&nbsp;&nbsp;&nbsp; “ns” : “ddj.test3”&nbsp;&nbsp; }]注意：默认情况下索引字段的值并不是唯一的，值可以是相同的，但是我们可以通过配置参数unique属性为true建立唯一索引；db.test3.ensureIndex({name:1},{unique:true})建立联合索引的方法：db.test3.ensureIndex({name:1,age:1}) 建立namehe1age的联合注意：数据库的唯一索引也可以进行去重： 爬虫中使用pymongo 爬虫数据去重得主要思路（实现增量式爬虫；）： 使用url地址进行去重；比如帖子得url，一般是唯一得，其内容可能会发生变化；一本可以将url存放在redis中，拿到url地址，判断是否重复，如果存在，布隆过滤器：用非常小的思路 根据数据本身进行去重，使用加密算法； 数据备份 数据库的备份在python里面使用我们的mongodb数据库需要pymongo模块下载pymongo，并导入moongo客户端这个类， pymongo使用from pymongo import MongoClient调用一下类，创建一个实例化对象，并通过字典参数指明域名和端口client = MongoClient(host=’127.0.0.1’,port=27017)创建集合，client[‘数据库名’][‘集合名’]collection = client[‘test4’][‘ddj’]插入单条数据；collection.insert_one({“name”:”xiaoming”,”age”:1})相关的api还有insert_many,find()注意：findapi返回值是一个游标，每遍历一次取一次值，游标往前移动一位，update_one()update_many()注意：find方法返回的是一个邮编对象，可以通过遍历取到对象中的每一个记录值，&lt;pymongo.cursor.Cursor object at 0x000001E1304E1B50&gt;","categories":[{"name":"Database","slug":"Database","permalink":"http://www.innerjquery.club/categories/Database/"}],"tags":[{"name":"DB-mongo","slug":"DB-mongo","permalink":"http://www.innerjquery.club/tags/DB-mongo/"}]},{"title":"python中的hashlib模块详解","slug":"python中的hashlib模块详解","date":"2020-09-11T14:31:36.000Z","updated":"2021-03-24T12:35:50.560Z","comments":true,"path":"2020/09/11/python中的hashlib模块详解/","link":"","permalink":"http://www.innerjquery.club/2020/09/11/python%E4%B8%AD%E7%9A%84hashlib%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Python中hashlib模块详解文章目录 hashlib的简介 hashlib的使用 常用属性 常用方法 使用示例 hashlib的特点 代码实操 举例子 应用场景案例 一、hashlib的简介hashlib 是一个提供了一些流行的hash(摘要)算法的Python标准库．其中所包括的算法有 md5, sha1, sha224, sha256, sha384,sha512等什么是摘要算法呢？摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。更多请看：hashlib — 安全哈希与消息摘要 二、hashlib的使用本文以hashlib中MD5算法为例，其他的sha224、sha256算法用法和MD5基本一致。如果想看其他案例可以参考我的博文：用python实现MD5、sha256、sha384、sha512、base64加密 1、常用属性12345678hashlib.algorithms#列出所有加密算法h.digest_size#产生的散列字节大小。h.block_size#哈希内部块的大小 2、常用方法123456789hash.new([arg]) # 创建指定加密模式的hash对象hash.update(arg) # 更新哈希对象以字符串参数。如果同一个hash对象重复调用该方法，m.update(a); m.update(b) 等价于 m.update(a+b)hash.digest() # 返回摘要，作为二进制数据字符串值。hash.hexdigest() # 返回摘要，作为十六进制数据字符串值hash.copy() # 复制 3、使用示例12345678910import hashlib # MD5 的使用def jm_md5(password): m = hashlib.md5() # 构建MD5对象 m.update(password.encode(encoding='utf-8')) #设置编码格式 并将字符串添加到MD5对象中 password_md5 = m.hexdigest() # hexdigest()将加密字符串 生成十六进制数据字符串值 return password, password_md5 g = jm_md5('123456')print(g) 三、hashlib的特点 1、摘要算法在很多地方都有广泛的应用。 2、要注意摘要算法不是加密算法，不能用于加密（因为无法通过摘要反推明文），只能用于防篡改。 3、它的单向计算特性决定了可以在不存储明文口令的情况下验证用户口令。 注意：一个优秀的 hash 算法，将能实现：正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突）。即对于任意两个不同的数据块，其hash值相同的可能性极小；对于一个给定的数据块，找到和它hash值相同的数据块极为困难 四、代码实操可以找找其他篇博文：用python实现MD5、sha256、sha384、sha512、base64加密 1.举例子123456789101112131415161718192021import hashlib\"\"\"一、在构建对象直接插入加密字符串\"\"\"m1 = hashlib.md5('hello python'.encode(encoding='utf-8')) # 构建MD5对象print(m1.hexdigest()) # 结果为： e53024684c9be1dd3f6114ecc8bbdddc\"\"\"二、通过update方法 往MD5对象中增加字符串参数\"\"\"m2 = hashlib.md5() # 构建MD5对象m2.update('hello python'.encode(encoding='utf-8')) # 设置编码格式 并将字符串添加到MD5对象中password_md5 = m2.hexdigest()print(m2.hexdigest()) # 结果为 e53024684c9be1dd3f6114ecc8bbdddc\"\"\"三、当数据量过过大时，可以分块摘要，例如：\"\"\"m3 = hashlib.md5()m3.update(\"hello \".encode(\"utf-8\")) # 注意：分块是空格也要保持一致m3.update(\"python\".encode(\"utf-8\"))print(m3.hexdigest()) # 结果为：e53024684c9be1dd3f6114ecc8bbdddc\"\"\"MD5是最常见的摘要算法，速度很快，生成结果是固定的128 bit字节，通常用一个32位的16进制字符串表示。\"\"\" 三种方式，往构造的MD5对象中传参，只要传参的字符串一致，最后生成的结果是一样的。这说明hash算法就像一座工厂，工厂接收你送来的原材料（可以用m.update()为工厂运送原材料），经过加工返回的产品就是hash值。这也是摘要算法的一个特点，它不是加密算法，不能用于加密（因为无法通过摘要反推明文），只能用于防篡改 2、应用场景案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import hashlibUSER_LIST = []def pwd_Md5(password): password = password+'hello python' # 字符串混淆加盐，可以设置更复杂一点 return hashlib.md5(password.encode(\"utf-8\")).hexdigest()def register(): print('**************用户注册**************') while True: user = input('请输入用户名:') if user.isalpha(): break while True: password1 = input('请输入密码&gt;&gt;&gt;:').strip() passwprd2 = input('请重复密码&gt;&gt;&gt;：').strip() if password1 == passwprd2: password = pwd_Md5(password1) # 将密码进行Md5加密 break else: print('密码不正确，重新输入！') temp = {'username':user,'password':password} USER_LIST.append(temp)def login(): print('**************用户登陆**************') user = input('请输入用户名:') pwd = input('请输入密码:') for item in USER_LIST: if item['username'] == user and item['password'] == pwd_Md5(pwd): return Trueif __name__=='__main__': register() if login(): print('登陆成功') else: print('登陆失败')结果：**************用户注册**************请输入用户名:wuhan请输入密码:123456**************用户登陆**************请输入用户名:小马过河请输入密码:123456登陆成功 代码分析：1、用户登录需要使用密码，密码一定要加密，保证用户的信息安全。 1）加密可以使用hashlib模块进行加密。 2）加密可以写成加密函数，方便多处调用 3）提高密码解密的复杂性，代码中多加字符串。（加密算法虽然依然非常厉害，但是也存在缺陷，即：通过撞库可以反解。所以，有必要对加密密码进行加盐。）","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_hashlib模块","slug":"python-hashlib模块","permalink":"http://www.innerjquery.club/tags/python-hashlib%E6%A8%A1%E5%9D%97/"}]},{"title":"mysql和pymysql","slug":"mysql和pymysql","date":"2020-08-13T03:41:06.000Z","updated":"2021-03-24T12:34:56.368Z","comments":true,"path":"2020/08/13/mysql和pymysql/","link":"","permalink":"http://www.innerjquery.club/2020/08/13/mysql%E5%92%8Cpymysql/","excerpt":"","text":"mysql的使用sql的基本语法1.说明 行：记录 列：字段 唯一标识每一个行/记录的字段叫做主键： RDBMS关系型数据库： redis适合做缓存数据库、mysql适合做网站、magoose适合做爬虫： rdbms客户端与服务器端通过sql语句进行通讯，sql是一种结构化查询语言：sql语句可以应用在很多的数据库软件上： DQL是数据查询语言，DML是数据操控语言：sql数据库语言是不区分大小写的： ubuntu系统中使用如下命令安装数据库服务端和客户端$ sudo apt-get install mysql-client-core-5.6$ sudo apt-get install mariadb-client-core-10.0然后利用mysql -uroot -p进入数据库eixt/quit/ctrl+d退出数据库 为表定义字段的类型和约束可以规范表的完整性 2.类型 字段中常用的数据类型如下： 整形：int bit 小数：decimal ：表示浮点数，如decimal（4，2）表示共存四位数，小数占2为 字符串：varchar、char ：varchar表示可变字符串长度度，多了会丢弃、char表示固定字符串长度多了会丢弃少了会补空格 字符串text表示存储大文本，当字符大于4000时使用 日期时间：data、time、datetime 枚举类型：enum对于图片音视频文件不存储在数据库中，而是上传到某个服务器然后在表中存储这些文件的保存路径： 3.约束 主键primary key：物理上存储的顺序 非空not null：此字段不允许为空 唯一unique：此字段的值不允许重复 默认default：不填写此值时会使用默认值，如果填写时以填写为准 外键foreign key： 对关系字段进行约束当为关系字段填写值时会关联到表中查询此值是否存6. 在，如果存在贼填写成功 如果不存在就填写不成功：（通常来说外键就是其他表的主键，存储其他表的主键的字段就是外键） 4.常用操作 常用的数据库操作（注意语句要以分号的形式写，如果不写分号其会认为语句未完，sql是不区分大小写的：） show databases；显示连接的所有数据库 select now();显示当前时间 select version(); create database 数据库名 charset=’utf8’;(注意指定编码字符未utf-8) show create database 数据库名；（用于显示数据库的创建细节） drop database 数据库名；删除数据库 数据库名不支持-中横线，要想认为是一个整齐必须使用类似模板字符串的标识符``即反引号 select database();显示当前使用或者选择的数据库 use 数据库名；表示使用或者切换该数据库； show tables 选择当前选择的数据库里面的所有表 create table yyyy(id int primary key not null auto_increment,name varchar(25))用于创建一个表；方法中的每一个字段用逗号隔开，每个字段名后面空隔加上修饰符进行字段修饰； desc 表名；用于表格形式显示所有的表的字段； 创建多个字段的表的方法：create table stuednts(id int unsigned primary key not null auto_increment,name varchar(25),age tinyint(3) unsigned,high decimal(5,2),gender enum(“男”,”女”,”保密”) default “保密”,cls_id int unsigned) 向表中插入值得方法（一定表得字段得顺序去插入）insert into stuednts values(0,’老王’,19,190.00,’男’,1606); select * from stuednts （向指定表中查询所有得信息） sql得命令行中得注释为–； 增加删除修改表字段得方法为：alter table stuednts add birthday datetime;alter table 表名 add 字段名 字段类型描述（向表中添加字段） alter table 表明 modify 字段名 字段类型 字段描述；（修改表中字段不重命名版） alter table 表名 change 原字段名 新字段名 字段类型 字段描述；（修改表中字段重命名版） alter table 表名 drop 字段名； （字段删除后字段所在得数据也删除了） drop table 表名；用于删除数据表 show create table 表名 一般在sql语句中带有名字得比如表名、数据库名、字段名通常带反引号以放出错； 5.表的简单增删改查 插入数据(xxx是表名，插入了一个记录有两个字段值)insert into xxx value(1,’121’) 注意：此时插入数据得字段值可以为null或者default，只要约束允许；注意：枚举类型值可以设定得时候用指定得值，也可以用枚举得下标表示枚举得值； 部分插入：insert into xxx(字段名) value(字段值)插入单个字段值； 多行插入：value后面可以接多个记录使得可以一行插入多个；insert into xxx value(21,’safsafds’),(31,’asdfsafdsa’),(41,’sdafsdafdsa’) update 表名 set 字段=值 where 字段 = 值 注意：根据唯一字段作为条件去修改字段值，否则将修改整个字段列得值； 条件查询通过where：select * from xxx where name = ‘222’;select * from xxx where id&gt;7; 条件查询指定列（记得用逗号分隔）：select id,name from where name = ‘222’ 条件查询指定列并起别名(通过)：select id as ID,name as 姓名 from where name = ‘222’ 物理删除在数据库中真删除和逻辑删除在表中标记删除,即通过特定的字段标记有没有删除：物理删除：delete from xxx where name = ‘222’逻辑删除：update xxx set is_delete = 1 where id=11 数据库增删改查专题1.查询相关 模糊查询的查询条件要使用引号，可以是单引号也可以是双引号，但是不能是反引号； 去重查询(从students表中去重复查询gender)；select distinct gender from stuednts; 条件查询里面有的运算符有：比较运算符&gt; &lt; &gt;= &lt;= = != &lt;&gt;条件运算符and or not注意：select * from xxx where id &gt;= 8 and id&lt;=10;and运算符左边和右边都是一个整体而不是值；注意：select * from xxx where not id &gt;= 8 and gender = 2;not的用法，用在整体的条件的前面； 模糊查询为查询条件：可以使用like，用%替换0个或者多个字符，用_表示一个字符，select * from xxx where name like “_明%”可以使用rlike后接正则作为查询条件， 使用范围查询作为条件 字段 in (范围) ：注意in前面还可以加notselect * from xxx where age in (11,14)可以使用between and 作为范围查询条件：注意between前面可以加not取反，且between和and是一个整体select * from xxx where age between 16 and 19 是否非空作为条件查询（is null / is not null）：select * from xxx where name is not null 在使用了数据库的情况下 通过source 数据库文件名导入数据库 注意：有时查询条件混淆的时候建议使用小括号明晰一下 2.排序相关 按照指定条件之后从小到大排序（asc表示从小到大、desc表示从大到小排）：此时如果我们排序的那个字段比如age相同的时候系统会按照主键再去排；但是我们可以在by后面接多个字段 表示当前面字段相同时再按后面的字段排；而不是系统的字段排（多个字段之间使用逗号，）elect * from xxx where (age between 15 and 25) and gender = 1 order by age ascselect * from xxx where (age between 15 and 25) and gender = 1 order by age desc,cls_id desc; 3.聚合、分组（select查询的位置可以放置任何函数或者表达式子） 聚合函数的用法： count() :查询条件查询后的记录总数： select count() as 人数 from xxx where id = 8; max(age)：max函数用于查询指定字段的列的最大值： select max(age) from xxx; sum():函数的用法用于查询指定列的总数； select sum(age) from xxx; agv（）：函数用于返回指定列的平均值： select avg(age) from xxx; round（值，小数点位数）函数用于四舍五入保留指定小数点位数； select round(avg(age),1) from xxx; 注意：聚合函数不能直接和其他字段列一起查找：可能会报错；但是不一定报错，注意场景 分组====》group by 字段名 实际上按照某一字段进行分组就是将每一组折叠起来只显示每一组中的第一个记录； 分组的意义在于以和聚合函数一起配合使用； 表示：只查询gender字段，并且按其将其分组； select gender,count() from xxx group by gender; 次数的聚合函数count是对分组的每个组进行求值 +——–+———-+ | gender | count() | +——–+———-+ | 女 | 7 | | 男 | 6 | +——–+———-+ 2 rows in set (0.00 sec) 注意：和分组配合使用的聚合函数group_concat(name)的作用显示分组的每一组该字段的值 select gender,group_concat(name，age,cls_id) from xxx group by gender +——–+———————————————————————————–+ | gender | group_concat(name,’:’, age,’:’) | +——–+———————————————————————————–+ | 男 | 小明4:16:,小s:19:,小明dsafsda:11:,小明sadf:64:,小明sdafs:68:,小明sss:78: | | 女 | 小明:11:,小明1:14:,小明2:17:,小明3:19:,小明5:13:,小明sdaf:10:,小明sdafdsafdsa:28: | +——–+———————————————————————————–+ 2 rows in set (0.00 sec) 3.having的用法，having作为分组的一个条件使用：having是对查出来的结果进行条件判断，而 where是对原表进行判断； 4.分页limit start,count：注意 select * from xxx limit 3; 注意只有一个参数表示查询的个数 select * from xxx limit 2,2; 注意如果有两个参数表示查询的开始个数和查询的总个数，注意不能省略逗号； 注意：limit 语句只能放在一个sql语句的最后 5.链接查询、多表查询 链接查询：（链接多个表，取多个表的共有值） 内连接：取多个表的交集：其实际上的处理过程为，从当前表中的每个记录的指定字段去找其他表对应的记录合并成为一行记录的过程；如果两个表都有该字段则合并显示，这就是内连接select * from xxx inner join xxxc; 这是一个简单的内连接查询；但是该连接没有去重，xxx表的每一个数据都对应了xxxc表中的多个记录；可以使用on作为条件select * from xxx inner join xxxc on xxx.cls_id = xxxc.name;但是此时还有个问题，就是两个表的相同键都存在，因为我们显示了两个表的所有；正确的方法应该为select xxx.*,xxxc.name from xxx inner join xxxc on xxx.cls_id = xxxc.name;为了方便，我们可以将表通过as起别名； 外连接，外连接分为左连接和又连接：左连接：以join左边的表为基准去其他表去找记录，如果左边的表的指定字段在右边的表没有字段则显示null，通常内连接只有两个表都有该字段才会显示一条合并后的记录；右连接原理类似、连接的返回值通常是一个新表，是一个新的结果，可以通过having 加条件进行筛选；（where 通常用于对原表进行条件查询，having通常用于对一个结果或者新表进行条件查找；） 什么是自关联使用场景：省市三级联动、select * from areas as privince inner join areas as ticy on cith.pid = provice.aid having provice.atitle = ‘shandong’这就是自关联的使用场景、就是自己内连接自己的表； 6.子查询 查询语句先执行子查询（子查询稍微有点消耗性能）：select * from xxx where height = ( select max(height) from xxx ) ;这是一个包含子查询的拆查询语句；将来会先执行子查询语句； 7.数据库的设计： 范式（NF）：数据库的范式遵循的几种规范，分为八种，一般前三种就行了第一范式(1NF)：表中每一个字段的信息不可再拆分：第二范式(2NF)：一个表中必须有一个主键，且其他非主键必须依赖于我们的主键：第三范式(3NF)：非主键必须直接依赖于主键、不能存在传递依赖，即不能存在非主键列a依赖于非主键b，非主键b依赖于主键的情况 E-R模型： 一对多 多对一 多对多 sql的高级语法数据库的视图 视图试图是从一个或几个基本表(或视图)导出来的表。它与基本表不同，是一个虚表。数据库中只存放视图的定义，而不存放视图对应的数据，这些数据仍存放在原来的基本表中。所以一旦基本表中的数据发生变化，从视图中查询出来的数据也就随之改变了。从这个意义上说，视图就像是一个窗口，透过它可以看到数据库中自己感兴趣的数据及其变化。 视图的创建方法create view vvv_p as select * from good where cate_name = ‘台式机’; 数据表视图的好处：提高了重用性就像一个函数、对数据重构却不影响程序的运行、提高了安全性能，对不同的用户开放、让数据更加清晰； 数据库中的事务 事务的好处：可以防止出现不可避免的意外情况下数据可以恢复到最开始的状态；即要么都成功要么都失败 所谓事务就是一个操作序列，这些操作要么都执行、要么都不执行，它是一个不可分割的工作单位； 事务的四大特性：ACID即 A：原子性 C一致性 I隔久性： D持久性； 开启事务的方法：start transaction/begin 提交事务：commit 回滚事务rollback；回滚后回到事务开始状态；不发生修改； 注意：mysql客户端是默认开启事务的； 数据库中的索引索引 ==》索引是一种特殊的文件比如（innodb数据表上的索引是表空间的一个组成部分）他们包含着对数据表里的所有记录的引用指针；索引能加快数据库的查询速度；索引的目的在于提高效率；create index 索引 on 表明里的字段（字段的最大长度）;create index tt on xxxss(num(50));| Query_ID | Duration | Query |+———-+————+——————————————————————–+| 1 | 0.00055875 | desc xxxss || 2 | 0.00679775 | select * from xxxss where num = ‘hahahahahhahahhahahha—–49999’ || 3 | 0.03975900 | create index tt on xxxss(num(50)) || 4 | 0.00052425 | select * from xxxss where num = ‘hahahahahhahahhahahha—–49999’ |+———-+————+——————————————————————–+通过第二次和第四次的比较，通过索引查询效率大大提高； show index from xxxss显示索引的方法； 注意：创建太多的索引将会影响更新和插入的速度，因为它需要更新文件的索引；所有只有进程查询的表才建议创建索引； 数据库中的索引 了解sql账户管理：（保证将来数据的安全） 通过desc查看数据库用户列表（改表在数据库mysql下）select user,host from user; 创建账户和授权grant 权限列表 on 数据库 to 用户名@访问主机 indetified by 密码grant select on xxxss.* to ‘zhansan’@’localhost’ identified by ‘123456789’ ;注意select此时是权限； 建议不要使用远程登录、非常危险： 删除数据库用户的方法：drop user zhansan@localhost;MYSQL的主从：从一个数据库服务器到其他服务器上、在复制数据时、一个服务器充当主服务器、mysql服务器之间的主从同步是义域二进制日志机制的，主服务器使用二进制日志来记录数据库的变动情况；从服务器通过读取和执行改日志文件来保持和主服务器的一致；完成主从服务器之间的同步建议看csdn作用：用于数据库的备份；且随时备份；读写分离（写入数据让主服务器响应，读数据让从服务器响应） 数据库与python的交互mysql知识补充 切记分组之后的查询字段的函数是对每一组进行操作（分组后的查询是对每一组的查询；）select cate_name,avg(price) from good group by cate_name; 外键插入的方法：怎么给一张表添加外键（两种种方法）通过reference 加其他表的主键比如xxx(id)\\CONSTRAINT是约束的意思外键一般尽量少使用：会降低数据库的性能；cs_id int(30) references classes(id),（包含references 和指定表的字段的字段就是外键；）FOREIGN KEY (cs_id) REFERENCES classes(id)CONSTRAINT FK_ID_CS FOREIGN KEY (cs_id) REFERENCES classes(id) 如何取消外键：alter table 表名 drop foreign key 外键名称： pymysql使用 window系统下pip3 install pymysql 创建链接数据库connect_t = connect(多值字典参数) cursor = connect_t.cursor()创建邮标cursor去操作数据库 cursor.execute(‘select * from xxx;’)操作数据库 cursor.close() connect_t.close() 依次关闭游标和链接 注意：处理查询操作必须都要提交我们的链接，connect.commit() 123456789101112131415from pymysql import *def main(): connect_t = connect(host='localhost',port=3306, user='root',password='961948438',database='python',charset='utf8') cursor = connect_t.cursor() cursor.execute('select * from xxx;') print('======') print(cursor.fetchmany(10)) cursor.close() connect_t.close() passif __name__ == '__main__': main() 注意：sql的查询语句不需要利用链接（不是游标cursor）去调用commit提交： 但是其他的增删改操作需要利用链接对象去调用commit方法去确认语句，如果此时不想确认sql操作可以调用 链接对象下的rollback（）方法，但此时递增的数据库表字段可能已经发生了递增； 了解sql注入 什么是sql注意：在程序事先定义好的 查询语句中添加额外的SQL语句 ，在管理员不知情的情况下实现非法操作，以此来实现 欺骗数据库服务器执行非授权的任意查询 ，从而进一步得到相应的数据信息。SQL注入通俗说就是： 通过SQL语句找到破绽，进行非法的数据读取。python可以通过execute（sql语句，[参数]）方法让execute自行拼接，而不是通过sql = ’select * from xxx %s‘ % inputname 手动拼接；","categories":[{"name":"Database","slug":"Database","permalink":"http://www.innerjquery.club/categories/Database/"}],"tags":[{"name":"DB-mysql","slug":"DB-mysql","permalink":"http://www.innerjquery.club/tags/DB-mysql/"}]},{"title":"ERROR!","slug":"test","date":"2020-06-30T11:12:42.000Z","updated":"2021-03-13T03:32:37.087Z","comments":true,"path":"2020/06/30/test/","link":"","permalink":"http://www.innerjquery.club/2020/06/30/test/","excerpt":"","text":"失误！","categories":[],"tags":[]},{"title":"django彻底解决跨域","slug":"django彻底解决跨域","date":"2020-06-24T16:24:48.000Z","updated":"2021-03-27T11:24:03.452Z","comments":true,"path":"2020/06/25/django彻底解决跨域/","link":"","permalink":"http://www.innerjquery.club/2020/06/25/django%E5%BD%BB%E5%BA%95%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F/","excerpt":"","text":"详情查看如下：https://blog.csdn.net/zhu6201976/article/details/84677213 补充在跨域请求下可以访问cookie但是无法设置cookies 参考链接：https://blog.csdn.net/kevinfan2011/article/details/90111854 浏览器接受到设置cookies的响应之后无法做出处理，这时候需要前后端都做出处理： 同时在此访问同网站时无法携带cookie的问题 1.前端配置axios.defaults.withCredentials=true 2.后端配置响应的cookies支持： response[‘Access-Control-Allow-Origin’] = ‘http://localhost:3000' response[‘Access-Control-Allow-Credentials’] = True 熟悉django中session（session对象.set_expiry(过期time)）和cookies对象下的属性和方法利用oauth完成我们的认证信息注意有可能我们的django框架拿不到contenttype=”application/json”的请求数据 此时我们需要利用序列化工具json.dumps(request.body)方法； 当然了如果内容类型为urlencode就可以直接获取到 组件的更新机制当前组件发生变化只会影响当前组件和子组件极其后代组件的更新调用render函数使用纯组件纯组件内部对比使用的是浅层对比，非浅层可能检测不到 如果又非浅层数据修改的需求就需要使用assign或者使用扩展运算符；引用类型应该创建一个新数据； js也是一样，变量存储的数据在内存中的地址，没有小数据池，render方法返回的产物是虚拟dom，是为了新旧虚拟dom进行diff算法比较；虚拟dom存在可以使得我们的程序脱离浏览器，只要能够运行js的环境我们程序就能运行； 为跨平台提供了条件；react为面向虚拟dom开发； Router路由分发器是一个容器组件，通常要它来包裹整个应用； 路由器有两种,一种是hashrouter，和browserrouter(使用h5里面的history Api来实现的) 路由的执行过程： 点击link路由入口组件，修改了浏览器地址栏中的url react路由监听到地址栏中的url的变化。 react路由内部遍历所有的route组件，使用路由规则和路径名进行匹配； 当路由规则path能够匹配到地址栏中的pathname就展route组件的内容； 默认路由：默认路由的的路径就是/（模糊匹配的存在可能导致多个组件被渲染） 比如 /first 时，默认路由和/first对应组件都会被匹配成功： 模糊匹配规则只要pathname以path开头就会匹配成功，不一定要完全一样， 比如/a/b的pathname（url中的或者link的to属性的值）和/a的path(route中的path属性的值)就能匹配成功 精确匹配就是pathname和path要一摸一样就是精确匹配给我们的路由添加exact属性，切记不要随意添加exact属性，可能会影响子路由； 通常情况下给我们的默认路由添加精确匹配属性是非常推荐的，其他情况下不建议添加我们的exact属性 路由的匹配模式，模糊匹配（默认匹配模式）和精确匹配；django框架如何根据已有的数据库表生成模型类react的重定向组件redirect的用法： &lt;Route exact path=’/‘ render={()=&gt;}&gt; antd组件中的留白组件WingBlank的取舍：如何手动分发一个原生事件：window.dispatchEvent(new Event(‘resize’));在脚手架工具中使用sass工具、安装yarn add node-sass即可经常遇到的额文字和图标基线不一致的问题：可以通过flex布局解决 display: flex;align-items: center; h5中2的地理位置api，通过 navigator.gelocation.getcurrentpostion((position)=&gt;console.log(position)) position表示当前的位置信息 他会返回一个地理包含地理坐标和时间错的对象，我们从坐标中获取到我们的信息； latitude和longitude分别表示经纬度 定位的方式有wifi、gps、mac等，具体使用什么定位视设备而定 实际开发过程中使用的是百度地图api、高德地图api 具体使用方法在百度api中查看 注意：在脚手架中相关的方法window.BMapGL.Map/Point是挂载在window上的，我们必须通过window来获取 闪烁问题","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_django","slug":"python-django","permalink":"http://www.innerjquery.club/tags/python-django/"}]},{"title":"spider爬取财经所有股票信息","slug":"python爬虫小安列","date":"2020-05-24T12:24:41.000Z","updated":"2021-03-24T12:35:42.327Z","comments":true,"path":"2020/05/24/python爬虫小安列/","link":"","permalink":"http://www.innerjquery.club/2020/05/24/python%E7%88%AC%E8%99%AB%E5%B0%8F%E5%AE%89%E5%88%97/","excerpt":"","text":"一、爬取所有股票信息1.依赖selenium、xpath12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from logging import exceptionfrom selenium import webdriverimport timeimport io,syssys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='gb18030')class Domain(object): def __init__(self): self.chrome_driver = 'C:\\\\Users\\\\dd\\Desktop\\\\chromedriver.exe' self.driver = webdriver.Chrome(self.chrome_driver) @staticmethod def sleep_time(num): time.sleep(num) def login(self): self.driver.set_window_size(1920,1680) self.driver.get('http://vip.stock.finance.sina.com.cn/mkt/#stock_hs_up') time.sleep(0.5) self.totalpate = self.driver.find_element_by_xpath('//div[@id=\"list_pages_top2\"]/a[last()-1]') headtr =self.driver.find_element_by_xpath('//*[@id=\"tbl_wrap\"]//thead//tr') headcontent = [] headcontent.append(headtr.find_element_by_xpath('.//th[1]/a').text) headcontent.append(headtr.find_element_by_xpath('.//th[2]').text) tdalist = headtr.find_elements_by_xpath('.//td/a') for tda in tdalist: headcontent.append(tda.text) headcontent.append('\\n') with open(\"ggupiao.csv\",mode='a',encoding='utf-8') as f: f.write(\",\".join(headcontent)) while True: alltrlist =self.driver.find_elements_by_xpath('//*[@id=\"tbl_wrap\"]//tbody//tr') for tr in alltrlist: print(f'to scrapy {alltrlist.index(tr)}') listcontent = [] try: listcontent.append(tr.find_element_by_xpath('.//th[1]/a').text) except Exception: listcontent.append('暂未获取到代码') tdalist = tr.find_elements_by_xpath('.//td') try: listcontent.append(tr.find_element_by_xpath('.//th[2]/a/a').text) except Exception: listcontent.append('暂未获取到名称') tdalist = tr.find_elements_by_xpath('.//td') for tda in tdalist: listcontent.append(tda.text) listcontent.append('\\n') with open(\"ggupiao.csv\",mode='a',encoding='utf-8') as f: f.write(\",\".join(listcontent)) try: self.driver.find_element_by_xpath('//div[@id=\"list_pages_top2\"]/a[text()=\"下一页\"]').click() except Exception: print('找不到元素') return def run(self): self.login()if __name__ == \"__main__\": browser = Domain() browser.run()","categories":[{"name":"spider","slug":"spider","permalink":"http://www.innerjquery.club/categories/spider/"}],"tags":[{"name":"python 爬虫","slug":"python-爬虫","permalink":"http://www.innerjquery.club/tags/python-%E7%88%AC%E8%99%AB/"}]},{"title":"python的多任务进程","slug":"multopprocesssing模块","date":"2020-03-23T12:30:34.000Z","updated":"2021-03-24T12:34:39.391Z","comments":true,"path":"2020/03/23/multopprocesssing模块/","link":"","permalink":"http://www.innerjquery.club/2020/03/23/multopprocesssing%E6%A8%A1%E5%9D%97/","excerpt":"","text":"进程、线程、协程的概念 进程的概念：正在进行的一个过程或者说一个任务，而负责执行任务的则是CPU，进程本身是一个抽象的概念,即进程就是一个过程、一个任务。CPU描述的是一个程序的执行过程.进程之间是如何做到并发的：CPU在各个任务之间来回的进行切换，并在切换的过程当中保存当前进程的执行状态（保存蛋糕的执行过程）。进程与程序的区别：程序相当于菜谱，而进程相当于做菜的整个过程。需要强调的是：同一个程序执行两次(双击),那也是两个进程，比如打开暴风影音，虽然都是同一个软件，但是一个可以播放a，一个可以播放b.核的概念：https://zhidao.baidu.com/question/541410131.html处理器，就是说有几个处理器。。。也就说一个CPU里面会有几个处理器，这样就可以同时处理几个要求了。 线程的概念：一个进程里面至少有一个控制线程，进程的概念只是一种抽象的概念，真正在CPU上面调度的是进程里面的线程,就好比真正在地铁这个进程里面工作的实际上是地铁里面的线程,北京地铁里面至少要有一个线程，线程是真正干活的，线程用的是进程里面包含的一堆资源,线程仅仅是一个调度单位，不包含资源。协程的概念：协程 ，又称为微线程，它是实现多任务的另一种方式，只不过是比线程更小的执行单元。因为它自带CPU的上下文，这样只要在合适的时机，我们可以把一个协程切换到另一个协程。 通俗的理解： 在一个线程中的某个函数中，我们可以在任何地方保存当前函数的一些临时变量等信息，然后切换到另外一个函数中执行，注意不是通过调用函数的方式做到的 ，并且切换的次数以及什么时候再切换到原来的函数都由开发者自己确定。协程与线程的差异：在实现多任务时, 线程切换__从系统层面__远不止保存和恢复CPU上下文这么简单。操作系统为了程序运行的高效性，每个线程都有自己缓存Cache等等数据，操作系统还会帮你做这些数据的恢复操作，所以线程的切换非常耗性能。但是__协程的切换只是单纯地操作CPU的上下文__，所以一秒钟切换个上百万次系统都抗的住。 在python中使用Process进程类1. 进程创建的两种方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;!-- 开启进程的第一种方式: --&gt;from multiprocessing import Processimport timedef task(name): print(f'{name} is running') time.sleep(2) print(f'{name} is gone')if __name__ == '__main__': # 在windows环境下, 开启进程必须在 __name__ == '__main__' 下面 p = Process(target=task,args=('常鑫',)) # 创建一个进程对象 p.start() &lt;!-- 只是向操作系统发出一个开辟子进程的信号,然后就执行下一行了. --&gt; &lt;!-- 这个信号操作系统接收到之后,会从内存中开辟一个子进程空间,然后在将主进程所有数据copy加载到子进程,然后在调用cpu去执行. 开辟子进程开销是很大的. --&gt; print('==主开始') time.sleep(3) &lt;!-- 所以永远会先执行主进程的代码. --&gt;&lt;!-- 开启进程的第二种方式: --&gt;from multiprocessing import Processimport timeclass MyProcess(Process): def __init__(self,name): super().__init__() self.name = name def run1(self): print(f'{self.name} is running') time.sleep(2) print(f'{self.name} is gone')if __name__ == '__main__': p = MyProcess('常鑫') p.start() print('===主')&lt;!-- 简单应用: --&gt;from multiprocessing import Processimport timedef task(name): print(f'{name} is running') time.sleep(1) print(f'{name} is gone')def task1(name): print(f'{name} is running') time.sleep(2) print(f'{name} is gone')def task2(name): print(f'{name} is running') time.sleep(3) print(f'{name} is gone')if __name__ == '__main__': # 在windows环境下, 开启进程必须在 __name__ == '__main__' 下面 # p1 = Process(target=task,args=('常鑫',)) # 创建一个进程对象 # p2 = Process(target=task,args=('李远点业',)) # 创建一个进程对象 # 一个进程串行的执行三个任务 start_time = time.time() task('常鑫') task1('李远点业') task2('海狗') print(f'结束时间{time.time() - start_time}') 三个进程 并发或者并行的执行三个任务 start_time = time.time() p1 = Process(target=task, args=('常鑫',)) # 创建一个进程对象 p2 = Process(target=task1, args=('李远点业',)) # 创建一个进程对象 p1.start() p2.start() task2('海狗') print(f'结束时间{time.time()-start_time}') 2. 获取进程pid1234567891011121314151617181920212223import osimport timeprint(f'子进程:{os.getpid()}')print(f'主(父)进程:{os.getppid()}')time.sleep(50)from multiprocessing import Processimport timeimport osdef task(name): print(f'子进程:{os.getpid()}') print(f'主进程:{os.getppid()}')if __name__ == '__main__': p = Process(target=task,args=('常鑫',)) # 创建一个进程对象 p.start() # print('==主开始') print(f'====主{os.getpid()}') 3. 验证进程之间的空间隔离1234567891011121314151617181920212223242526272829303132#encoding=utf-8from multiprocessing import Processimport osimport timename = 'sa'def task(): global name name = 'assb' print(f'子进程{name}')if __name__ == '__main__': p = Process(target=task) # 创建一个进程对象 p.start() # print('==主开始') time.sleep(3) print(f'主:{name}')lst = ['丽丽',]def task(): lst.append('怼姐') print(f'子进程{lst}')if __name__ == '__main__': p = Process(target=task) # 创建一个进程对象 p.start() # print('==主开始') time.sleep(3) print(f'主:{lst}') 4. join方法让主进程等待子进程结束之后,在执行主进程 join让主进程等待子进程结束之后,在执行主进程. join 多个连接的join方法是2一起通知主进程的，只针对主进程,如果join下面多次join 他是不阻塞的.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158from multiprocessing import Processimport timedef task(name): print(f'{name} is running') time.sleep(2) print(f'{name} is gone')if __name__ == '__main__': p = Process(target=task,args=('ad',)) # 创建一个进程对象 p.start() p.join() print('==instart')多个子进程使用joinfrom multiprocessing import Processimport timedef task(name,sec): print(f'{name}is running') time.sleep(sec) print(f'{name} is gone')if __name__ == '__main__': start_time = time.time() p1 = Process(target=task,args=('常鑫',1)) p2 = Process(target=task,args=('李业',2)) p3 = Process(target=task,args=('海狗',3)) p1.start() p2.start() p3.start() print(f'==主{time.time()-start_time}') # 0.02 这只是主进程结束的时间,与其他进程毫无关系验证1from multiprocessing import Processimport timedef task(name,sec): print(f'{name}is running') time.sleep(sec) print(f'{name} is gone')if __name__ == '__main__': start_time = time.time() p1 = Process(target=task,args=('常鑫',1)) p2 = Process(target=task,args=('李业',2)) p3 = Process(target=task,args=('海狗',3)) p1.start() p2.start() p3.start() # join 只针对主进程,如果join下面多次join 他是不阻塞的. p1.join() p2.join() p3.join() print(f'==主{time.time()-start_time}')验证2from multiprocessing import Processimport timedef task(name,sec): print(f'{name}is running') time.sleep(sec) print(f'{name} is gone')if __name__ == '__main__': start_time = time.time() p1 = Process(target=task,args=('常鑫',3)) p2 = Process(target=task,args=('李业',2)) p3 = Process(target=task,args=('海狗',1)) p1.start() p2.start() p3.start() # join就是阻塞 p1.join() # 等2s print(f'==主1:{time.time()-start_time}') p2.join() print(f'===主2:{time.time()-start_time}') p3.join() print(f'==主3:{time.time()-start_time}') # 优化上面的代码from multiprocessing import Processimport timedef task(sec): print(f'is running') time.sleep(sec) print(f' is gone')if __name__ == '__main__': start_time = time.time() p1 = Process(target=task,args=(1,)) p2 = Process(target=task,args=(2,)) p3 = Process(target=task,args=(3,)) p1.start() p2.start() p3.start() # join 只针对主进程,如果join下面多次join 他是不阻塞的. p1.join() p2.join() p3.join() 错误示范: for i in range(1,4): p = Process(target=task,args=(i,)) p.start() p.join() ''' p1 = Process(target=task,args=(1,)) p1.start() p1.join() p2 = Process(target=task,args=(2,)) p2.start() p2.join() p3 = Process(target=task,args=(3,)) p3.start() p3.join() ''' 正确示范: l1 = [] for i in range(1, 4): p = Process(target=task,args=(i,)) l1.append(p) p.start() for i in l1: i.join() print(f'==主{time.time()-start_time}') join就是阻塞,主进程有join,主进程下面的代码一律不执行,直到进程执行完毕之后,在执行. 5. 进程的其他参数123456789101112131415161718192021222324from multiprocessing import Processimport timedef task(name): print(f'{name} is running') time.sleep(2) print(f'{name} is gone')if __name__ == '__main__': # 在windows环境下, 开启进程必须在 __name__ == '__main__' 下面 # p = Process(target=task,args=('常鑫',)) # 创建一个进程对象 p = Process(target=task,args=('常鑫',),name='alex') # 创建一个进程对象 p.start() # time.sleep(1) # p.terminate() # 杀死子进程 *** # p.join() # *** # time.sleep(0.5) # print(p.is_alive()) # *** # print(p.name) p.name = 'sb' print(p.name) print('==主开始') 6. 守护进程1234567891011121314151617181920212223 # 守护进程: # 古时候 太监守护这个皇帝,如果皇帝驾崩了,太监直接也就死了. # 子进程守护着主进程,只要主进程结束,子进程跟着就结束,from multiprocessing import Processimport timedef task(name): print(f'{name} is running') time.sleep(2) print(f'{name} is gone')if __name__ == '__main__': # 在windows环境下, 开启进程必须在 __name__ == '__main__' 下面 p = Process(target=task,args=('常鑫',)) # 创建一个进程对象 p.daemon = True # 将p子进程设置成守护进程,只要主进程结束,守护进程马上结束. p.start() # p.daemon = True # 一定要在子进程开启之前设置 time.sleep(1) print('===主') 7. 僵尸进程孤儿进程 基于unix环境(linux,macOS) 主进程需要等待子进程结束之后,主进程才结束 主进程时刻监测子进程的运行状态,当子进程结束之后,一段时间之内,将子进程进行回收. 为什么主进程不在子进程结束后马上对其回收呢? 主进程与子进程是异步关系.主进程无法马上捕获子进程什么时候结束. 如果子进程结束之后马上再内存中释放资源,主进程就没有办法监测子进程的状态了. unix针对于上面的问题,提供了一个机制. 所有的子进程结束之后,立马会释放掉文件的操作链接,内存的大部分数据,但是会保留一些内容: 进程号,结束时间,运行状态,等待主进程监测,回收. 僵尸进程: 所有的子进程结束之后,在被主进程回收之前,都会进入僵尸进程状态. 僵尸进程有无危害??? 如果父进程不对僵尸进程进行回收(wait/waitpid),产生大量的僵尸进程,这样就会占用内存,占用进程pid号. 孤儿进程: 父进程由于某种原因结束了,但是你的子进程还在运行中,这样你的这些子进程就成了孤儿进程.你的父进程如果结束了,你的所有的孤儿进程就会被init进程的回收,init就变成了你的父进程,对你进行回收. 僵尸进程如何解决??? 父进程产生了大量子进程,但是不回收,这样就会形成大量的僵尸进程,解决方式就是直接杀死父进程,将所有的僵尸进程变成孤儿进程进程,由init进行回收. 8. 僵尸进程孤儿进程 lock与join的区别. 共同点: 都可以把并发变成串行, 保证了顺序. 不同点: join人为设定顺序,lock让其争抢顺序,保证了公平性. 互斥锁,锁:进程锁主要是用来解决进程直接抢占资源等操作，比如读取同一文件、抢占队列数据 和抢占打印机等等类似操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127# 三个同事 同时用一个打印机打印内容.# 三个进程模拟三个同事, 输出平台模拟打印机.# 版本一:# from multiprocessing import Process# import time# import random# import os## def task1():# print(f'{os.getpid()}开始打印了')# time.sleep(random.randint(1,3))# print(f'{os.getpid()}打印结束了')## def task2():# print(f'{os.getpid()}开始打印了')# time.sleep(random.randint(1,3))# print(f'{os.getpid()}打印结束了')## def task3():# print(f'{os.getpid()}开始打印了')# time.sleep(random.randint(1,3))# print(f'{os.getpid()}打印结束了')## if __name__ == '__main__':## p1 = Process(target=task1)# p2 = Process(target=task2)# p3 = Process(target=task3)## p1.start()# p2.start()# p3.start()# 现在是所有的进程都并发的抢占打印机,# 并发是以效率优先的,但是目前我们的需求: 顺序优先.# 多个进程共强一个资源时, 要保证顺序优先: 串行,一个一个来.# 版本二:# from multiprocessing import Process# import time# import random# import os## def task1(p):# print(f'{p}开始打印了')# time.sleep(random.randint(1,3))# print(f'{p}打印结束了')## def task2(p):# print(f'{p}开始打印了')# time.sleep(random.randint(1,3))# print(f'{p}打印结束了')## def task3(p):# print(f'{p}开始打印了')# time.sleep(random.randint(1,3))# print(f'{p}打印结束了')## if __name__ == '__main__':## p1 = Process(target=task1,args=('p1',))# p2 = Process(target=task2,args=('p2',))# p3 = Process(target=task3,args=('p3',))## p2.start()# p2.join()# p1.start()# p1.join()# p3.start()# p3.join()# 我们利用join 解决串行的问题,保证了顺序优先,但是这个谁先谁后是固定的.# 这样不合理. 你在争抢同一个资源的时候,应该是先到先得,保证公平.# 版本3:from multiprocessing import Processfrom multiprocessing import Lockimport timeimport randomimport osdef task1(p,lock): ''' 一把锁不能连续锁两次 lock.acquire() lock.acquire() lock.release() lock.release() ''' lock.acquire() print(f'{p}开始打印了') time.sleep(random.randint(1,3)) print(f'{p}打印结束了') lock.release()def task2(p,lock): lock.acquire() print(f'{p}开始打印了') time.sleep(random.randint(1,3)) print(f'{p}打印结束了') lock.release()def task3(p,lock): lock.acquire() print(f'{p}开始打印了') time.sleep(random.randint(1,3)) print(f'{p}打印结束了') lock.release()if __name__ == '__main__': mutex = Lock() p1 = Process(target=task1,args=('p1',mutex)) p2 = Process(target=task2,args=('p2',mutex)) p3 = Process(target=task3,args=('p3',mutex)) p2.start() p1.start() p3.start() 9. 进程之间通信（基于文件、队列、管道） 进程在内存级别是隔离的,但是文件在磁盘上, 基于文件通信. 利用抢票系统讲解. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# 抢票系统.# 1. 先可以查票.查询余票数. 并发# 2. 进行购买,向服务端发送请求,服务端接收请求,在后端将票数-1,返回到前端. 串行.# from multiprocessing import Process# import json# import time# import os# import random### def search():# time.sleep(random.randint(1,3)) # 模拟网络延迟(查询环节)# with open('ticket.json',encoding='utf-8') as f1:# dic = json.load(f1)# print(f'{os.getpid()} 查看了票数,剩余{dic[\"count\"]}')### def paid():# with open('ticket.json', encoding='utf-8') as f1:# dic = json.load(f1)# if dic['count'] &gt; 0:# dic['count'] -= 1# time.sleep(random.randint(1,3)) # 模拟网络延迟(购买环节)# with open('ticket.json', encoding='utf-8',mode='w') as f1:# json.dump(dic,f1)# print(f'{os.getpid()} 购买成功')## def task():# search()# paid()### if __name__ == '__main__':## for i in range(6):# p = Process(target=task)# p.start()# 当多个进程共强一个数据时,如果要保证数据的安全,必须要串行.# 要想让购买环节进行串行,我们必须要加锁处理.## from multiprocessing import Process# from multiprocessing import Lock# import json# import time# import os# import random### def search():# time.sleep(random.randint(1,3)) # 模拟网络延迟(查询环节)# with open('ticket.json',encoding='utf-8') as f1:# dic = json.load(f1)# print(f'{os.getpid()} 查看了票数,剩余{dic[\"count\"]}')### def paid():# with open('ticket.json', encoding='utf-8') as f1:## dic = json.load(f1)# if dic['count'] &gt; 0:# dic['count'] -= 1# time.sleep(random.randint(1,3)) # 模拟网络延迟(购买环节)# with open('ticket.json', encoding='utf-8',mode='w') as f1:# json.dump(dic,f1)# print(f'{os.getpid()} 购买成功')### def task(lock):# search()# lock.acquire()# paid()# lock.release()## if __name__ == '__main__':# mutex = Lock()# for i in range(6):# p = Process(target=task,args=(mutex,))# p.start()# 当很多进程共强一个资源(数据)时, 你要保证顺序(数据的安全),一定要串行.# 互斥锁: 可以公平性的保证顺序以及数据的安全.# 基于文件的进程之间的通信: # 效率低. # 自己加锁麻烦而且很容易出现死锁. 基于队列通信. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 队列: 把队列理解成一个容器,这个容器可以承载一些数据,# 队列的特性: 先进先出永远保持这个数据. FIFO 羽毛球筒.# from multiprocessing import Queue# q = Queue()# def func():# print('in func')# q.put(1)# q.put('alex')# q.put([1,2,3])# q.put(func)### print(q.get())# print(q.get())# print(q.get())# f = q.get()# f()# from multiprocessing import Queue# q = Queue(3)## q.put(1)# q.put('alex')# q.put([1,2,3])# # q.put(5555) # 当队列满了时,在进程put数据就会阻塞.# # q.get()## print(q.get())# print(q.get())# print(q.get())# print(q.get()) # 当数据取完时,在进程get数据也会出现阻塞,直到某一个进程put数据.from multiprocessing import Queueq = Queue(3) # maxsizeq.put(1)q.put('alex')q.put([1,2,3])# q.put(5555,block=False)#print(q.get())print(q.get())print(q.get())print(q.get(timeout=3)) # 阻塞3秒,3秒之后还阻塞直接报错.# print(q.get(block=False))# block=False 只要遇到阻塞就会报错. 基于管道的通信.","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_multopprocesssing模块","slug":"python-multopprocesssing模块","permalink":"http://www.innerjquery.club/tags/python-multopprocesssing%E6%A8%A1%E5%9D%97/"}]},{"title":"axios的配置与拦截器","slug":"axios的配置与拦截器","date":"2020-03-18T04:19:53.000Z","updated":"2021-03-24T12:33:34.867Z","comments":true,"path":"2020/03/18/axios的配置与拦截器/","link":"","permalink":"http://www.innerjquery.club/2020/03/18/axios%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/","excerpt":"","text":"一、简单用法 发起get请求 1234567891011121314151617181920212223242526272829303132333435363738axios.get('/user?ID=12345') .then(function (response) { // handle success console.log(response); }) .catch(function (error) { // handle error console.log(error); }) .then(function () { // always executed });// Optionally the request above could also be done asaxios.get('/user', { params: { ID: 12345 } }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }) .then(function () { // always executed }); // Want to use async/await? Add the `async` keyword to your outer function/method.async function getUser() { try { const response = await axios.get('/user?ID=12345'); console.log(response); } catch (error) { console.error(error); }} 通过配置配置参数发起get请求或者响应 1234567891011121314151617axios({ method: 'post', url: '/user/12345', data: { firstName: 'Fred', lastName: 'Flintstone' }});// GET request for remote imageaxios({ method:'get', url:'http://bit.ly/2mTM3nY', responseType:'stream'}) .then(function (response) { response.data.pipe(fs.createWriteStream('ada_lovelace.jpg')) }); 发起delete请求、head请求、put请求等等axios#request(config)axios#get(url[, config])axios#delete(url[, config])axios#head(url[, config])axios#options(url[, config])axios#post(url[, data[, config]])axios#put(url[, data[, config]])axios#patch(url[, data[, config]])axios#getUri([config])配置参数的选项有 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153{// `url` is the server URL that will be used for the requesturl: '/user',// `method` is the request method to be used when making the requestmethod: 'get', // default// `baseURL` will be prepended to `url` unless `url` is absolute.// It can be convenient to set `baseURL` for an instance of axios to pass relative URLs// to methods of that instance.baseURL: 'https://some-domain.com/api/',// `transformRequest` allows changes to the request data before it is sent to the server// This is only applicable for request methods 'PUT', 'POST', and 'PATCH'// The last function in the array must return a string or an instance of Buffer, ArrayBuffer,// FormData or Stream// You may modify the headers object.transformRequest: [function (data, headers) { // Do whatever you want to transform the data return data;}],// `transformResponse` allows changes to the response data to be made before// it is passed to then/catchtransformResponse: [function (data) { // Do whatever you want to transform the data return data;}],// `headers` are custom headers to be sentheaders: {'X-Requested-With': 'XMLHttpRequest'},// `params` are the URL parameters to be sent with the request// Must be a plain object or a URLSearchParams objectparams: { ID: 12345},// `paramsSerializer` is an optional function in charge of serializing `params`// (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/)paramsSerializer: function (params) { return Qs.stringify(params, {arrayFormat: 'brackets'})},// `data` is the data to be sent as the request body// Only applicable for request methods 'PUT', 'POST', and 'PATCH'// When no `transformRequest` is set, must be of one of the following types:// - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams// - Browser only: FormData, File, Blob// - Node only: Stream, Bufferdata: { firstName: 'Fred'},// `timeout` specifies the number of milliseconds before the request times out.// If the request takes longer than `timeout`, the request will be aborted.timeout: 1000, // default is `0` (no timeout)// `withCredentials` indicates whether or not cross-site Access-Control requests// should be made using credentialswithCredentials: false, // default// `adapter` allows custom handling of requests which makes testing easier.// Return a promise and supply a valid response (see lib/adapters/README.md).adapter: function (config) { /* ... */},// `auth` indicates that HTTP Basic auth should be used, and supplies credentials.// This will set an `Authorization` header, overwriting any existing// `Authorization` custom headers you have set using `headers`.auth: { username: 'janedoe', password: 's00pers3cret'},// `responseType` indicates the type of data that the server will respond with// options are 'arraybuffer', 'blob', 'document', 'json', 'text', 'stream'responseType: 'json', // default// `responseEncoding` indicates encoding to use for decoding responses// Note: Ignored for `responseType` of 'stream' or client-side requestsresponseEncoding: 'utf8', // default// `xsrfCookieName` is the name of the cookie to use as a value for xsrf tokenxsrfCookieName: 'XSRF-TOKEN', // default// `xsrfHeaderName` is the name of the http header that carries the xsrf token valuexsrfHeaderName: 'X-XSRF-TOKEN', // default// `onUploadProgress` allows handling of progress events for uploadsonUploadProgress: function (progressEvent) { // Do whatever you want with the native progress event},// `onDownloadProgress` allows handling of progress events for downloadsonDownloadProgress: function (progressEvent) { // Do whatever you want with the native progress event},// `maxContentLength` defines the max size of the http response content in bytes allowedmaxContentLength: 2000,// `validateStatus` defines whether to resolve or reject the promise for a given// HTTP response status code. If `validateStatus` returns `true` (or is set to `null`// or `undefined`), the promise will be resolved; otherwise, the promise will be// rejected.validateStatus: function (status) { return status &gt;= 200 &amp;&amp; status &lt; 300; // default},// `maxRedirects` defines the maximum number of redirects to follow in node.js.// If set to 0, no redirects will be followed.maxRedirects: 5, // default// `socketPath` defines a UNIX Socket to be used in node.js.// e.g. '/var/run/docker.sock' to send requests to the docker daemon.// Only either `socketPath` or `proxy` can be specified.// If both are specified, `socketPath` is used.socketPath: null, // default// `httpAgent` and `httpsAgent` define a custom agent to be used when performing http// and https requests, respectively, in node.js. This allows options to be added like// `keepAlive` that are not enabled by default.httpAgent: new http.Agent({ keepAlive: true }),httpsAgent: new https.Agent({ keepAlive: true }),// 'proxy' defines the hostname and port of the proxy server.// You can also define your proxy using the conventional `http_proxy` and// `https_proxy` environment variables. If you are using environment variables// for your proxy configuration, you can also define a `no_proxy` environment// variable as a comma-separated list of domains that should not be proxied.// Use `false` to disable proxies, ignoring environment variables.// `auth` indicates that HTTP Basic auth should be used to connect to the proxy, and// supplies credentials.// This will set an `Proxy-Authorization` header, overwriting any existing// `Proxy-Authorization` custom headers you have set using `headers`.proxy: { host: '127.0.0.1', port: 9000, auth: { username: 'mikeymike', password: 'rapunz3l' }},// `cancelToken` specifies a cancel token that can be used to cancel the request// (see Cancellation section below for details)cancelToken: new CancelToken(function (cancel) {})} 响应通常包含如下信息 12345678910111213141516171819202122{ // `data` is the response that was provided by the server data: {}, // `status` is the HTTP status code from the server response status: 200, // `statusText` is the HTTP status message from the server response statusText: 'OK', // `headers` the headers that the server responded with // All header names are lower cased headers: {}, // `config` is the config that was provided to `axios` for the request config: {}, // `request` is the request that generated this response // It is the last ClientRequest instance in node.js (in redirects) // and an XMLHttpRequest instance the browser request: {}} 配置全局默认信息： 123axios.defaults.baseURL = 'https://api.example.com';axios.defaults.headers.common['Authorization'] = AUTH_TOKEN;axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; 二、axios的请求和响应拦截器1.config 指的是将来被传入的配置选项 1234567891011121314151617 // Add a request interceptoraxios.interceptors.request.use(function (config) { // Do something before request is sent return config; }, function (error) { // Do something with request error return Promise.reject(error); });// Add a response interceptoraxios.interceptors.response.use(function (response) { // Do something with response data return response; }, function (error) { // Do something with response error return Promise.reject(error); });","categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"}],"tags":[{"name":"axios","slug":"axios","permalink":"http://www.innerjquery.club/tags/axios/"}]},{"title":"python的time模块","slug":"python的time模块","date":"2020-02-10T08:46:55.000Z","updated":"2021-03-24T12:35:33.183Z","comments":true,"path":"2020/02/10/python的time模块/","link":"","permalink":"http://www.innerjquery.club/2020/02/10/python%E7%9A%84time%E6%A8%A1%E5%9D%97/","excerpt":"","text":"Python time模块的时间转换：1.time()函数time( )函数用于返回当前时间的时间戳(从1970年1月1日00时00分00秒到现在的浮点秒数)time()函数的语法如下： time.time()1、此语法中第一个 time 表示 time 模块，该函数不需要传递参数2、返回值：返回当前时间的时间戳 1234import timeprint(\"当前时间的时间的时间戳：%f\" % time.time())当前时间的时间的时间戳：1536375255.196752 2.localtime()函数time.localtime( )函数的作用是格式化时间戳为本地时间(struct_time类型）。如果secs参数未传入，就以当前时间为转换标准localtime() 方法的语法：time.localtime([ secs ])1、参数secs – 指转换为 time.struct_time 类型的对象的秒数2、返回值：该函数无任何返回值 1234import timeprint(time.localtime())time.struct_time(tm_year=2018, tm_mon=9, tm_mday=8, tm_hour=10, tm_min=59, tm_sec=39, tm_wday=5, tm_yday=251, tm_isdst=0) 3.gmtime()函数gmtime( ) 函数用于将一个时间戳转换为UTC时区(0时区)的 struct_time。可选参数secs 表示从1970-1-1 到现在的秒数，无参数时默认为本地时间函数返回 time.struct_time 类型的对象 (struct_time 是在 time 模块中定义的表示时间的对象)gmtime([secs]) 的语法如下：time.gmtime([secs])1、参数secs – 指转换为 time.struct_time 类型的对象的秒数2、返回值：该函数无任何返回值 1234 import time time.gmtime()time.struct_time(tm_year=2018, tm_mon=9, tm_mday=8, tm_hour=8, tm_min=22, tm_sec=14, tm_wday=5, tm_yday=251, tm_isdst=0) 4.mktime()函数mktime( )函数用于执行与 gmtime()、localtime() 相反的操作，接收 struct_time 对象作为参数，返回用秒数表示时间的浮点数。如果输入的值不是合法时间，就会触发OverflowError或ValueError以下是 mktime()方法的语法： time.mktime(t)1、参数t – 这是 struct_time (结构化时间)或全满 9 个元素的元组。2、返回值：该方法返回一个浮点数，为了兼容time()函数。 12345import timet = ( 2018,9,8,16,34,30,5,251,0)time.mktime(t) 1536395670.0 time.mktime(time.localtime())1536395774.0 5.asctime([t])函数接收一个时间元组并返回一个可读的形式为”Tue Dec 11 18:07:14 2008”（2008年12月11日 周二18时07分14秒）的24个字符的字符串asctime() 方法的语法：time.asctime([t]))1、参数 t – 完整的9位元组元素或 struct_time 表示，由 gmtime() 和 localtime() 函数返回的时间的元组。2、返回值：此方法返回以下形式的24个字符的字符串： ‘Tue Feb 17 23:21:05 2009’. 1234import timet = ( 2021,3,10,16,34,30,5,251,0)time.asctime(t)'Wed Mar 10 17:03:25 2021' 6.ctime([ secs ]))函数时间戳转换为time.asctime()的形式。语法如下：time.ctime([ sec ])1、参数sec – 这是将被转换成字符串表示的秒数。2、返回值：此方法不返回任何值。 123import timetime.ctime()'Wed Mar 10 17:05:44 2021' 7.sleep(secs)函数sleep()函数用于推迟调用线程的运行，可通过参数secs指定进程挂起的时间sleep()方法的语法：time.sleep(t)1、参数t – 这是要暂停执行的秒数。2、返回值：此方法不返回任何值。 123456import time def sleep_time(times): print(time.ctime()) time.sleep(times) print(time.ctime())sleep_time(100) 8.clock函数 不建议使用，已经废弃 9.strftime(format[, t])函数strftime() 方法用于接收时间元组，并返回以可读字符串表示的当地时间。格式由format参数决定。strftime()只能接受struct_time类型的参数strftime()方法的语法：time.strftime(format [,t] ) 123456import timet = (2022, 9, 25, 17, 50, 38, 6, 48, 0)t = time.mktime(t)print(time.strftime('%b %d %Y %H:%M:%S', time.gmtime(t)))print(\"\\n\\n\",time.strftime('%b %d %Y %H:%M:%S'))print(\"\\n\\n\",time.strftime('%H:%M:%S')) 10.strPtime(string [, format])函数strptime( )函数用于根据format的格式把一个时间字符串解析为时间元组。语法如下：strptime (string [,format] ) 123import timestruct_time = time.strptime(\"8 Sep 18\", \"%d %b %y\")print('returned tuple: ', struct_time)","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_time模块","slug":"python-time模块","permalink":"http://www.innerjquery.club/tags/python-time%E6%A8%A1%E5%9D%97/"}]},{"title":"python_logging模块","slug":"python-logging模块","date":"2020-01-12T02:33:03.000Z","updated":"2021-03-24T12:35:24.457Z","comments":true,"path":"2020/01/12/python-logging模块/","link":"","permalink":"http://www.innerjquery.club/2020/01/12/python-logging%E6%A8%A1%E5%9D%97/","excerpt":"","text":"logging – 日志logging日志低配版12345678'''import logginglogging.debug('我是调试')logging.info('我是信息')logging.warning('我是警告')logging.error('我是错误')logging.critical('我是危险')默认是从warning开始记录 logging日志常用版123456789101112131415161718192021222324252627282930313233343536373839404142import logginglogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(filename)s [line:%(lineno)d] %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S', filename='test.log', filemode='w')dic = {\"key\":123}logging.debug(dic)num = 100logging.info(f\"用户当前余额:{num - 50}\")try: num = int(input(\"请输入数字:\"))except Exception as e: logging.warning(\"int将字符串转换报错了\")print(\"12334\")logging.error('我是错误')logging.critical('我是危险')'''import logginglogger = logging.getLogger() '''创建一个logger'''fh = logging.FileHandler('test.log',mode=\"a\",encoding='utf-8') # 文件ch = logging.StreamHandler() # 屏幕formatter = logging.Formatter('%(asctime)s - %(name)s - %(filename)s - [line:%(lineno)d] - %(levelname)s - %(message)s')logger.setLevel(logging.DEBUG) # 将屏幕和文件都是用以上格式fh.setFormatter(formatter) # 设置记录级别ch.setFormatter(formatter) # 使用自定义的格式化内容logger.addHandler(fh) #logger对象可以添加多个fh和ch对象logger.addHandler(ch)logger.debug('logger debug message')logger.info('logger info message')logger.warning('logger warning message')logger.error('logger error message')logger.critical('logger critical message') logging日志高配版123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172\"\"\"logging配置\"\"\"import osimport logging.config\"\"\"定义三种日志输出格式 开始\"\"\"standard_format = '[%(asctime)s][%(threadName)s:%(thread)d][task_id:%(name)s][%(filename)s:%(lineno)d]' \\ '[%(levelname)s][%(message)s]' #其中name为getlogger指定的名字simple_format = '在 %(asctime)s %(message)s'id_simple_format = '[%(levelname)s][%(asctime)s] %(message)s'\"\"\"log文件的全路径\"\"\"logfile_path = 'all2.log'\"\"\"log配置字典\"\"\"LOGGING_DIC = { 'version': 1, 'disable_existing_loggers': False, 'formatters': { 'standard': { 'format': standard_format }, 'simple': { 'format': simple_format }, }, 'filters': {}, 'handlers': { #打印到终端的日志 'stream': { 'level': 'DEBUG', 'class': 'logging.StreamHandler', # 打印到屏幕 'formatter': 'simple' }, #打印到文件的日志,收集info及以上的日志 'file': { 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', # 保存到文件 'formatter': 'standard', 'filename': None, # 日志文件 'maxBytes': 1024*1024*1024, # 日志大小 5M 'backupCount': 5, 'encoding': 'utf-8', # 日志文件的编码，再也不用担心中文log乱码了 }, }, 'loggers': { #logging.getLogger(__name__)拿到的logger配置 '': { 'handlers': ['stream', 'file'], # 这里把上面定义的两个handler都加上，即log数据既写入文件又打印到屏幕 'level': 'DEBUG', 'propagate': True, # 向上（更高level的logger）传递 }, },}def get_logger(): path = r'F:\\s24\\day21\\liye.log' LOGGING_DIC['handlers']['file']['filename'] = path logging.config.dictConfig(LOGGING_DIC) # 导入上面定义的logging配置 logger = logging.getLogger(__name__) # 生成一个log实例 return loggerdef save(): logger = get_logger() logger.info(f'{} 存入300元') # 记录该文件的运行状态save()","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_logging模块","slug":"python-logging模块","permalink":"http://www.innerjquery.club/tags/python-logging%E6%A8%A1%E5%9D%97/"}]},{"title":"UDP_TCP_protocol","slug":"UDP_TCP_protocol","date":"2019-12-30T11:12:42.000Z","updated":"2021-03-24T12:36:35.067Z","comments":true,"path":"2019/12/30/UDP_TCP_protocol/","link":"","permalink":"http://www.innerjquery.club/2019/12/30/UDP_TCP_protocol/","excerpt":"","text":"一. 内容大纲 C/S B/S架构 网络通信原理 osi七层协议 简单串联五层协议以及作用 对五层协议详细的补充说明 UDP TCP 协议 TCP协议的三次握手和四次挥手 socket套接字 基于TCP协议的socket简单的网络通信(待定) 二. 具体内容1. C/S B/S架构 C: client端 B: browse 浏览器 S: server端 C/S架构: 基于客户端与服务端之间的通信 ​QQ, 游戏,皮皮虾, 快手,抖音. ​优点: 个性化设置,响应速度快, 缺点: 开发成本,维护成本高,占用空间,用户固定. B/S架构: 基于浏览器与服务端之间的通信 谷歌浏览器,360浏览器,火狐浏览器等等. 优点: 开发维护成本低,占用空间相对低,用户不固定. ​缺点: 功能单一,没有个性化设置,响应速度相对慢一些. 2. 网络通信原理 80年代,固定电话联系,(还没有推广普通话) 1.两台电话之间一堆物理连接介质连接. 2.拨号,锁定对方电话的位置. 由于当时没有统一普通话,所以你如果和河南,山西,广西,福建等朋友进行友好的沟通交流,你必须学当地的方言. 推广普通话,统一交流方式. 两台电话之间一堆物理连接介质连接. 拨号,锁定对方电话的位置. 统一交流方式. 全球范围内交流: 两台电话之间一堆物理连接介质连接. 拨号,锁定对方电话的位置. 统一交流方式.(英语) 话题转回互联网通信: 我现在想和美国的一个girl联系.你如何利用计算机联系??? 两台计算机要有一堆物理连接介质连接. 找到对方计算机软件位置. 遵循一揽子互联网通信协议. 3. osi七层协议 简单串联五层协议以及作用 物理层 物理层指的就是网线,光纤,双绞线等等物理连接介质 物理层发送的是比特流: 01010101010101010101只是发送比特流有什么问题??? 数据应该有规律的分组,分组是数据链路层做的事情. 数据链路层 数据链路层对比特流进行分组. 最开始从事互联网企业的就是美国的几家公司,各家有各家自定的分组标准.后来统一了标准: 对数据分组的标准. 以太网协议: 对比特流进行合理的分组. 一组数据01010101 叫做一帧,数据报. head | data(晚上约么) head是固定的长度:18个字节 源地址: 6个字节 目标地址: 6个字节 数据类型: 6个字节 data: 最少是46个字节,最大1500字节. 一帧数据: 最少64个字节,最大1518个字节. 一帧数据|一帧数据…… 每个电脑上都有一个网卡,往卡上都记录一个独一无二的地址. mac地址: 就是你的计算机上网卡上标注的地址. 12位16进制数组成 :前六位是厂商编号,后六位是流水线号. 源mac地址 目标mac地址 数据类型 | data ‘1C-1B-0D-A4-E6-44’ 计算机的通信方式: 同一个局域网内,通过广播的形式通信. 消息一经广播发出,村里所有的人(局域网所有的计算机都能接收到消息,分析消息,是否是找我的,不是就丢弃), 计算机只能在局域网内进行广播: 范围大了 广播风暴,效率极低. 以太网协议：对比特流进行分组，一组数据也叫做一帧，或者一个数据报head | data(“你好！”)head是固定长度的18个字节源地址： 6个字节目标地址：6个字节数据类型：6个字节data最少是46个字节，最大时1518个字节一帧数据最少是64个字节，最大是1518个字节，每一个电脑上都有一个网卡，网卡上记录中一个独一无二的地址这个地址就是mac地址：mac地址就是我们计算机上网络标注的地址，由12位16进制的数组成，前六位是厂商编号，后六位是流水线号；比如：”1C-1B-0D-A4-E6-44”计算机的通讯方式： 同一个局域网内，通过广播的形式通信局域网所有的计算机都能接收消息，分析消息，判断是否找本机的同一局域网内：mac地址 +我们的广播就可以通讯了 还有两个没有解决: 不同局域网如何通信? 软件与软件的通信,而不是计算机之间的通信. 网络层 IP协议: 确定局域网(子网)的位置. 找到具体软件的位置,上一层的事情 传输层: TCP端口协议: 确定软件在计算机的位置 应用层: 自己定义的协议. 广播(局域网内) + mac地址(计算机位置) + ip(局域网的位置) + 端口(软件在计算机的位置) 有了以上四个参数:你就可以确定世界上任何一个计算机的软件的位置. 对五层协议详细的补充说明 数据链路层补充: 同一个局域网通过广播的形式发送数据. 交换机的mac地址学习功能: 一个交换机的5个接口: 5个计算机. 1: FF-FF-FF-FF-FF-FF 2: FF-FF-FF-FF-FF-FF广播(局域网内) + mac地址(计算机位置) + ip(局域网的位置) + 端口(软件在计算机的位置) 有了以上四个参数:你就可以确定世界上任何一个计算机的软件的位置. 3: FF-FF-FF-FF-FF-FF 4: FF-FF-FF-FF-FF-FF 5: FF-FF-FF-FF-FF-FF 接口1: 源mac 1C-1B-0D-A4-E6-44 目标1C-1C-0D-A4-E5-44 |数据 以广播的形式发出 2,3,4,5口都会接收到消息,5口是最终的目标地址,交换机就会将5口与mac地址对应上. 1: 1C-1B-0D-A4-E6-44 2: FF-FF-FF-FF-FF-FF 3: FF-FF-FF-FF-FF-FF 4: FF-FF-FF-FF-FF-FF 5: 1C-1C-0D-A4-E5-44 当五个口都对应上具体的mac地址,2口再次发消息,就不会广播了,就会以单播发送. 我们的前提是什么? 你必须知道对方的mac地址你才可以以广播的形式发消息.实际上,网络通信中,你只要知道对方的IP与自己的IP即可. 网络层: IP协议: ip地址:四段分十进制 192.168.0.12 取值范围 0255.0255.0255.0255 子网掩码: C类子网掩码: 255.255.255.0 ip地址 + 子网掩码 按位与运算 计算出是否在统一局域网(子网,网段). 计算172.16.10.1 与 172.16.10.128 172.16.10.1：10101100.00010000.00001010.00000001 255.255.255.0: 11111111.11111111.11111111.00000000 从属于的局域网: 172.16.10.0 172.16.10.128：10101100.00010000.00001010.10000000 255.255.255.0: 11111111.11111111.11111111.00000000 从属于的局域网: 172.16.10.0 172.16.10.1 ~172.16.10.255 C类子网掩码 一个网段最多可以承载多个IP地址? 255 -3个ip地址 比如：192.168.254.1：被占用 192.168.254.255广播地址被占用，192.168.254.1被占用 172.16.10.0 被占用. 172.16.10.255 广播地址 被占用. 172.16.10.1 被占用. 253台计算机. 如果你要想给另一个计算机发数据, 你一定要知道对方的ip地址. ARP协议:通过对方的ip地址获取到对方的mac地址. 源码mac 目标mac 源IP 目标IP 数据 1C-1B-0D-A4-E6-44 FF:FF:FF:FF:FF:FF 172.16.10.13 172.16.10.156 数据 第一次发消息: 发送到交换机 —&gt; 路由器 广播的形式发出去 目标计算机收到消息:就要回消息: 源码mac 目标mac 源IP 目标IP 数据 1B-1B-0D-A4-E6-54 1C-1B-0D-A4-E6-44 172.16.10.156 172.16.10.13 数据总结:前提:知道目标mac: 计算机A 发送一个消息给 计算机B 源码mac 目标mac 源IP 目标IP 数据 单播的形式发送到交换机,交换机会检测自己的对照表有没有目标mac,如果有,单播传.如果没有,交由上一层: 路由器: 路由器收到消息: 对消息进行分析: 要确定目标计算机与本计算机是否在同一网段, 如果在同一网段,直接发送给对应的交换机,交换机在单播发给目标mac. 如果不是在同一网段: ? 前提:不知道目标mac: 计算机A 发送一个消息给 计算机B 源码mac 目标mac不知道 源IP 目标IP 数据 单播的形式发送到交换机,交换机交由上一层路由器:路由器收到消息: 对消息进行分析: 要确定目标计算机与本计算机是否在同一网段, 如果在同一网段通过 IP以及ARP协议获取到对方的mac地址,然后在通信. 如果不是在同一网段: ? 传输层: 端口协议: UDP协议,TCP协议 65535端口 1~1024操作系统专门使用的端口 举例: 3306 数据库 自己开发软件都是8080以后的端口号 4. UDP TCP 协议 TCP（Transmission Control Protocol）可靠的、面向连接的协议（eg:打电话）、流式协议, 传输效率低全双工通信（发送缓存&amp;接收缓存）、面向字节流。使用TCP的应用：Web浏览器；文件传输程序。 UDP（User Datagram Protocol）不可靠的、无连接的服务，传输效率高（发送前时延小），一对一、一对多、多对一、多对多、面向报文(数据包)，尽最大努力服务，无拥塞控制。使用UDP的应用：域名系统 (DNS)；视频流；IP语音(VoIP)。 5. TCP协议的三次握手和四次挥手 注意：三次握手的过程中间两次可以合并，而四次挥手时中间两层不能合并的原因 可能服务器端还有正在向客户端发送的数据，为了保证数据的完整性服务器回先发送完 这些数据；所以这两次挥手的过程不能合并： syn洪水攻击:制造大量的假的无效的IP请求服务器.致使正常的IP访问不了服务器. 6. socket套接字7. 基于TCP协议的socket简单的网络通信(待定)","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_udp_tcp原理","slug":"python-udp-tcp原理","permalink":"http://www.innerjquery.club/tags/python-udp-tcp%E5%8E%9F%E7%90%86/"}]},{"title":"socket原理","slug":"socket原理","date":"2019-12-23T03:15:09.000Z","updated":"2021-03-24T12:36:19.222Z","comments":true,"path":"2019/12/23/socket原理/","link":"","permalink":"http://www.innerjquery.club/2019/12/23/socket%E5%8E%9F%E7%90%86/","excerpt":"","text":"一、Socket原理讲解https://blog.csdn.net/pashanhu6402/article/details/96428887 1、什么是TCP/IP、UDP？2、Socket在tcp/ip五层协议/iso七层协议的哪里？3、Socket是什么呢？4、如何使用使用它们吗？二、python套接字socket用法https://blog.csdn.net/qq_29350991/article/details/110232175 1、套接字的简介2、Socket的类型3、Socket函数4、Socket的编程思想","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_socket模块","slug":"python-socket模块","permalink":"http://www.innerjquery.club/tags/python-socket%E6%A8%A1%E5%9D%97/"}]},{"title":"redis和redis模块","slug":"redis和redis模块","date":"2019-12-13T03:41:22.000Z","updated":"2021-03-24T12:36:07.858Z","comments":true,"path":"2019/12/13/redis和redis模块/","link":"","permalink":"http://www.innerjquery.club/2019/12/13/redis%E5%92%8Credis%E6%A8%A1%E5%9D%97/","excerpt":"","text":"redis介绍 mysql、oracle、sql server都是关系型数据库,都有通用的操作语言sqlredis、mongodb是主要的两个非关系型数据库， 非关系型数据库nosql是一类新出现的数据库（not only sql），其特点有如下： 不支持sql语法，存储解构采用键值对的形式储存 没有通用的语言，每一个nosql都有自己都有的api和语法： nosql和sql的比较，再复杂场景下建议使用关系型数据库，sql对事务支持的非常完善，nosql基本不支持事务所谓事务：（一组sql操作要么都成功要么都失败） redis特性：支持书库的持久化，不仅仅支持简单的键值对类型数据，支持数据的备份，redis的性能极高，redis的所有操作都是基于原子性的，redis还支持发布订阅通过key过期等等操作： 应用场景：用来做缓存，redis中的数据都是存放到内存中的，可以再某些特定的场景下替代一个传统的数据库，比如社交的应用，再一些大型的系统，实现一些特定的功能，session共享、购物车等等 redis在linux上的安装 下载，解压，编译:$ wget http://download.redis.io/releases/redis-5.0.4.tar.gz$ tar xzf redis-5.0.4.tar.gz$ cd redis-5.0.4$ make二进制文件是编译完成后在src目录下. 运行如下:$ src/redis-server==》redis在window下安装进入redisgithub官网就下载最新版msci即可进行redis的相关配置操作： redis服务端在window下的启动： C:\\Program Files\\Redis 进入redis安装目录 redis-server.exe redis.windows.conf 运行redis即可 客户端通过redis-cli命令直接链接服务器端 字符串命令 默认redis有16个数据库：，且默认链接到第一个数据库，select index（索引）链接指定数据库 redis存储的数据结构键的类型是字符串、值得类型分为五种：字符串，哈希，集合，有序集合数据库得操作行为：保存、修改、删除、获取， 注意redis是基于二进制安全得，这意味着类字符串类型可以接收任意类型：get 键 命令获取值，set 键 值 设置键值mset 键 值 键 值 命令可以一次性设置多个键值，setex 键 时间 值 命令可以设置有时间限制得值，append 键 值 可以往键里面追加值 键命令 keys * 一次性查看所有键 exists 键 判断键是否存在，存在返回1，不存在返回0 type key 查看key对应得value类型 del 键，用于删除多个键 expire 键 时间 用于设置键对应得时间，单位为秒 ttl 键，查看键还剩下得有效时间（未设置返回-1，过期返回-2） hash命令： 用于存储对象，对象得结构为属性、值： hset key 属性 属性值值，创建一个hash存储对象： hmset key 属性 属性值 创建多个对象 hkeys u 查看hash键得所有属性 hget 键 属性 获取一个has键得属性 hmset 键 属性1、属性2 hvals 键 获取hash键得所有属性得属性值 hdel 键 属性1，属性2 一次删除一个或者多个hash键得属性得值 list命令 lpush 键 值1，值2，值3 从左侧往一个列表插入数据 lrange 键 开始下标 结束下标 查看指定下表区间得列表得值（o表示开始下表，-1表示结束下标） rpush 键 值1，值2 ，值3从右侧往一个列表插入数据 linsert 键 before/after 现有值 新值 在指定得元素前面或者后面插入一个元素： lset 键 下标 值 重置指定列表类型键得下标得值 lrem 键 数量m 值 将类型为列表得键的前m次出现为某只的元素移除掉注意：如果m=0表示移除所有，&gt;大于0表示从右往左移除,小于表示从左往右移除 set无序集合命令 sadd 键 值1，值2，值3 smembers 键 查看集合类型的键的所有元素 srem 键 值 删除集合类型的键的某个值，可以删除多个 zset有序集合命令 zadd 键 权重 值 权重 值 zrange 键 起始下标 结束下标 查看有序集合类型键的指定权重之间的值 zadd rs 2 zhansan 5 lisi 8 wangwu 4 feiq zrangebyscore 键 开始权重 结束权重 返回指定权重之间的数据 zrem 键 值 删除 删除类型为有序集合的键的某个值 zremrangebyscore 键 开始权重 结束权重 删除指定权重之间的数据 redis 和python的交互使用 注意：以下rr是reids链接类的实例化对象 依赖于第三方包redis pip install redis 导入模块 from redis import * 中的所有属性和方法 通过StrictRedis（缺省参数域名，缺省参数端口，缺省参数第几个数据库）类的实例化对象链接我们的数据库 rr.set(‘name’,’sadfsafsad’) set方法相当于字符串命令中的set命令，第一个参数为字符串类型的键，第二个参数为字符串值 注意：该返还值为布尔值，表示是否设置成功： res = rr.get(‘name’) 用于获取字符串类型的键的值 rr.delete（多值元组参数键） 该方法的返回值表示删除了几个字符串类型的键 rr.keys（）方法获取到数据库中的所有的键，返回值为一个列表 redis中存储session的相关配置工作：在数据库的配置文件夹下做出如下配置信息：SESSION_ENGINE=’redis_sessions.session’SESSION_REDIS_HOST = ‘localhost’SESSION_REDIS_PORT = 6379SESSION_REDIS_PASSWORD = ‘’SESSION_REDIS_DB = 2SESSION_REDIS_PREFIX = ‘session’ 这样当我们设置了session之后，会在我们redis数据库里面生成一个字符串类型的键： redis集群 集群：是一组相互独立的通过高速网络互联的计算机共同对外服务器构成一个服务器整体 redis集群分为软件层面（一台电脑开启多个redis服务）和硬件层面：（多台电脑每台开启一个或多个redis服务） 软件层面：（一台电脑开启多个·redis服务器；）","categories":[{"name":"Database","slug":"Database","permalink":"http://www.innerjquery.club/categories/Database/"}],"tags":[{"name":"DB-redis","slug":"DB-redis","permalink":"http://www.innerjquery.club/tags/DB-redis/"}]},{"title":"django实现文件上传的几种方式","slug":"django实现文件上传的几种方式","date":"2019-11-18T15:37:31.000Z","updated":"2021-03-24T12:33:54.858Z","comments":true,"path":"2019/11/18/django实现文件上传的几种方式/","link":"","permalink":"http://www.innerjquery.club/2019/11/18/django%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"django实现文件上传的几种方式方式一、通过Django的Form方式上传文件 前台html创建Form，根据格式要求完善form内标签属性；提交后台后，后台获取前台传来的数据进行处理：文件路径保存至数据库，文件内容保存至本地文件夹中；后台处理完成后刷新前台页面。 静态html页面设置：写一个form表单，三个关键标签：text、file、submit，分别存新的文件名、文件内容、提交按钮，由于是文件上传因此form中enctype需要设置成multipart/form-data。 12345&lt;form action=\"/upload.html\" method=\"post\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"text\" name=\"fileName\"&gt; &lt;input type=\"file\" name=\"fileContent\"&gt; &lt;input type=\"submit\" value=\"提交\"&gt;&lt;/form&gt; 3、views后台设置： 123456789101112131415161718192021222324252627 from django.shortcuts import render,redirectimport os def Upload(request): if request.method==\"GET\": return render(request,\"upload.html\") elif request.method==\"POST\": # 获取普通input标签值，即文件名 filname=request.POST.get('fileName') # 获取file类型的input标签值，即文件内容 file=request.FILES.get('fileContent') # 获取文件后缀名 postfix=file.name.split('.')[1] # 设置本地文件路径 file_path=os.path.join('static',filname+'.'+postfix) # 将上传的文件写入本地目录 f=open(file_path,\"wb\") for chunk in file.chunks(): f.write(chunk) f.close() return redirect(\"upload.html\") 配置文件 123456from Upload import views urlpatterns = [ path('upload.html',views.Upload),] 原理： 当Get请求时，即浏览器打开该网页时，显示上传页面； 当POST请求时，即点击“提交”按钮时： 获取界面传过来的新的文件名及文件内容。 分块读取文件内容，并写入到本地目录。 页面上动态显示刚刚上传的图片，需做如下改造： 123456789101112131415161718192021222324252627新建数据库表，用来存储图片路径class image(models.Model): # 路径 file_Path=models.CharField(max_length=32)在上传成功时将文件路径保存至数据库，即在views的视图方法的POST中的保存文件后面添加代码： models.image.objects.create(file_Path=file_path)页面刷新时展现图片，即在视图方法的GET中读取数据库中添加的图片路径，并将其返给html页面： if request.method==\"GET\": # 获取所有图片 imgs=models.image.objects.all() return render(request,\"upload.html\",{\"imgs\":imgs}) html页面中增加: &lt;div class=\"imgs\"&gt; { % for obj in imgs % } &lt;img src=\"{{ obj.file_Path }}\"&gt; { % endfor % } &lt;/div&gt; 由于Django对静态文件浏览的限制，需要在配置中添加： STATIC_URL = '/static/' STATICFILES_DIRS = [ os.path.join(BASE_DIR,\"static\"), ] 方式二、通过ajax 前端处理： 12&lt;input type=\"file\" name=\"img\" id=\"img1\"&gt;&lt;p&gt;&lt;input type=\"button\" value=\"上传图片\" id=\"upload1\"&gt;&lt;/p&gt; 利用formdata表单数据对象添加数据： 1234567891011121314document.querySelector('#upload1').addEventListener('click',function(e){ e.preventDefault() imgele = document.querySelector('#img1') img = imgele.files[0] // console.log(img.name) var formdata = new FormData(); formdata.append('myfiles',img) console.log(formdata) axios.post('http://localhost:8000/app/img/upload',formdata).then(function(result){ console.log(result) }).catch(function(error){ console.log(error) }) }) FormData对象的作用(formdata本质就是一个js对象)a、模拟HTML表单，相当于将HTML表单映射为表单对象，自动将表单对象中的数据拼接成请求参数的格式b、异步上传二进制文件（比如图片、视频和音频）FormData对象与ajax有关FormData对象不能用于get请求formData.get(key)formData.set(key,value)formData.delete(key)formData.append(key,value)var formData=new FormData()formData.append(key,value) django后端处理： 123456789def imgss(request):print('*' * 50)# print(request.POST.get('myfiles'))img = request.FILES['myfiles']print('*' * 50)with open(\"upload/imgs/\"+img.name,'ab') as fp: for chunk in img.chunks(): fp.write(chunk)return HttpResponse(\"is ok\")","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_hashlib模块","slug":"python-hashlib模块","permalink":"http://www.innerjquery.club/tags/python-hashlib%E6%A8%A1%E5%9D%97/"}]},{"title":"python_collections模块","slug":"python-collections模块","date":"2019-04-12T04:09:32.000Z","updated":"2021-03-24T12:35:09.665Z","comments":true,"path":"2019/04/12/python-collections模块/","link":"","permalink":"http://www.innerjquery.club/2019/04/12/python-collections%E6%A8%A1%E5%9D%97/","excerpt":"","text":"collctions模块给我们提供了一些python的特殊的数据类型1.namedtuple: 命令元组生成可以使用名字来访问元素内容的tuple2.deque: 双端队列，可以快速的从另外一侧追加和推出对象3.Counter: 计数器，主要用来计数4.OrderedDict: 有序字典5.defaultdict: 带有默认值的字典123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from collections import namedtuple,dequePoint = namedtuple('tu',[\"a\",\"b\",\"c\"]) # 第一个参数是元组的名字,第二参数是元组中元素的[名字,名字]p = Point({\"keu\":(1,2,3,4)}, 20,10)print(p)tu = (1,2,32,34,4)print(tu)lst = deque([1,2,3,4,5,6,7])lst.append(8)lst.appendleft(0)lst.pop()lst.popleft()print(lst[4])队列:先进先出栈:先进后出 -- 栈顶lst = [1,2,3,4]lst.append(5)lst.pop(0)'''5.defaultdict: 带有默认值的字典'''from collections import defaultdictdic = defaultdict(list)dic[\"k1\"].append(12)print(dic)li = [11,22,33,44,55,77,88,99,90]result = {\"key1\":[],\"key2\":[]}result = {}for row in li: if row &gt; 66: if 'key1' not in result: result['key1'] = [] result['key1'].append(row) else: if 'key2' not in result: result['key2'] = [] result['key2'].append(row)print(result)from collections import defaultdictdic = defaultdict(set)li = [11,22,33,44,55,77,88,99,90]for i in li: if i &gt; 66: dic[\"k1\"].add(i) else: dic[\"k2\"].add(i)print(dic)from collections import Counters = \"1112233344aaa\"s = [1,1,2,2,3,3]s = (1,2,3,3,4,5,6,7,78)print(dict(Counter(s))) # ***'''统计元素出现的次数'''","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_collections模块","slug":"python-collections模块","permalink":"http://www.innerjquery.club/tags/python-collections%E6%A8%A1%E5%9D%97/"}]},{"title":"django中间件的两种实现方式","slug":"django中间件的两种实现方式","date":"2019-03-19T04:53:46.000Z","updated":"2021-03-24T12:34:04.700Z","comments":true,"path":"2019/03/19/django中间件的两种实现方式/","link":"","permalink":"http://www.innerjquery.club/2019/03/19/django%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/","excerpt":"","text":"中间件的两种实现方式 什么是中间件：Django中的中间件是一个轻量级、底层的插件系统，可以介入Django的请求和响应处理过程，修改Django的输入或输出。中间件的设计为开发者提供了一种无侵入式的开发方式，增加了Django框架的健壮性。我们可以使用中间件，在Django处理视图的不同阶段对输入或输出进行干预。 如何定义我们的中间件： 1. 通过闭包函数定义我们的中间件 12345678910111213def simple_middleware(get_response): # 此处编写的代码仅在Django第一次配置和初始化的时候执行一次。 def middleware(request): # 此处编写的代码会在每个请求处理视图前被调用。 response = get_response(request) # 此处编写的代码会在每个请求处理视图之后被调用。 return response return middleware 根据代码：需要定义一个中间件的工厂函数 simple_middleware，然后返回一个可以被调用的中间件 middleware 中间件工厂函数 simple_middleware 需要接收一个可以调用的 get_response 对象 返回的中间件也是一个可以被调用的对象，并且像视图一样需要接收一个request对象参数，返回一个response对象。 例如，在users应用模块中新建一个middleware.py文件 123456789def my_middleware(get_response): print('init 被调用') def middleware(request): print('before request 被调用') response = get_response(request) print('after response 被调用') return response return middleware 定义好中间件后，需要在settings.py 文件中添加注册中间件 12345678910MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'users.middleware.my_middleware', # 添加中间件] 1. 通过闭包函数定义我们的中间件 12345678910111213lass SimpleMiddleware: def __init__(self, get_response): self.get_response = get_response # One-time configuration and initialization. def __call__(self, request): # 视图函数请求之前做一些事情 response = self.get_response(request) # 视图函数响应之后做一些事情 return response","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_django_middleware","slug":"python-django-middleware","permalink":"http://www.innerjquery.club/tags/python-django-middleware/"}]},{"title":"python的多任务协程","slug":"协程","date":"2019-03-14T04:53:33.000Z","updated":"2021-03-24T12:33:21.164Z","comments":true,"path":"2019/03/14/协程/","link":"","permalink":"http://www.innerjquery.club/2019/03/14/%E5%8D%8F%E7%A8%8B/","excerpt":"","text":"一、协程：一个线程并发的处理任务. 协程的本质就是：单个线程并发的处理多个任务,程序自己保持快速的切换让cpu以为我们的线程没有堵塞io，进而不切换走 任务处理的方式： 串行: 一个线程执行一个任务,执行完毕之后,执行下一个任务. 并行: 多个cpu执行多个任务, 4个cpu 执行4个任务. 并发: 一个cpu执行多个任务,看起来像是同时运行. 并发真正的核心: 切换并且保持状态. 多线程的并发: 3个线程处理10个任务,如果线程1处理的这个任务,遇到阻塞,cpu被操作系统切换到另一个线程, 一个线程能否并发的处理任务??? 一个线程处理三个任务. 单个cpu: 10个任务,让你给我并发的执行这个10个任务: 方式一:开启多进程并发执行, 操作系统切换+保持状态. 方式二:开启多线程并发执行,操作系统切换+保持状态. 方式三:开启协程并发的执行, 自己的程序 把控着cpu 在3个任务之间来回切换+保持状态.对3详细解释: 协程他切换速度非常快,蒙蔽操作系统的眼睛,让操作系统认为cpu一直在运行你这一个线程(协程.) 协程方式最好,为什么? 开销小.] 运行速度快. 协程会长期霸占cpu只执行我程序里面的所有任务. 并发的本质:就是切换+保持状态. 协程处理IO密集型, 计算密集型,还是串行好. 什么是协程? 单个线程并发的处理多个任务. 程序控制协程的切换+保持状态. 协程的特点: 必须在只有一个单线程里实现并发 修改共享数据不需加锁 用户程序里自己保存多个控制流的上下文栈(保持状态) 附加：一个协程遇到IO操作自动切换到其它协程 工作中:一般在工作中我们都是进程+线程+协程的方式来实现并发，以达到最好的并发效果，如果是4核的cpu，一般起5个进程，每个进程中20个线程（5倍cpu数量），每个线程可以起500个协程，大规模爬取页面的时候，等待网络延迟的时间的时候，我们就可以用协程去实现并发。 并发数量 = 5 * 20 * 500 = 50000个并发，这是一般一个4cpu的机器最大的并发数。nginx在负载均衡的时候最大承载量就是5w个单线程里的这20个任务的代码通常会既有计算操作又有阻塞操作，我们完全可以在执行任务1时遇到阻塞，就利用阻塞的时间去执行任务2。。。。如此，才能提高效率，这就用到了Gevent模块。 二、greenlet模块实现任务切换和状态保持 greenlet遇到IO不会主动切换，它只会等待任务的执行完成 greenlet不是真的协程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 切换# def func1():# print('in func1')## def func2():# print('in func2')# func1()# print('end')## func2()# 切换 + 保持状态# def gen():# while 1:# yield 1## def func():# obj = gen()# for i in range(10):# next(obj)# func()# 上面的例子遇到IO不能自动切换# import time# def gen():# while 1:# yield 1# time.sleep(0.5)## def func():# obj = gen()# for i in range(10):# next(obj)# func()## 切换 +保持状态(遇到IO不会主动切换)# from greenlet import greenlet# import time# def eat(name):# print('%s eat 1' %name) # 2# # g2.switch('taibai') # 3# time.sleep(3)# print('%s eat 2' %name) # 6# g2.switch() # 7## def play(name):# print('%s play 1' %name) # 4# g1.switch() # 5# print('%s play 2' %name) # 8## g1=greenlet(eat)# g2=greenlet(play)## g1.switch('taibai') # 1 切换到eat任务 三、gevent第三方模块实现任务切换和状态保持https://blog.csdn.net/qq_43573663/article/details/113446029?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161450235916780274184792%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=161450235916780274184792&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-113446029.first_rank_v2_pc_rank_v29&amp;utm_term=python%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF 使用gevent实现协程 geven模拟的阻塞,不是真正的阻塞 gevent是一个基于协程的Python网络库,基于greenlet实现协程。当我们在进行频繁的网络交互访问时，网络IO会大大影响程序的性能(下面会看到)，但这些IO我们不必要等待，多任务时完全可以先执行其他任务等待IO结束，在处理返回结果。gevent就是基于这种思想设计实现。 monkey.patch_all()方法修改python标准库。gevent神奇之处在于它会自动检测网络IO，并进行子程序切换。由于切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，这一过程在启动时通过monkey.patch完成。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849mport time# 协程# 模拟的阻塞,不是真正的阻塞# import gevent# from threading import current_thread# def eat(name):# print('%s eat 1' %name)# print(current_thread().name)# # gevent.sleep(2)# time.sleep(2)# print('%s eat 2' %name)## def play(name):# print('%s play 1' %name)# print(current_thread().name)# # gevent.sleep(1)# time.sleep(1)# print('%s play 2' %name)### g1 = gevent.spawn(eat,'egon')# g2 = gevent.spawn(play,name='egon')# print(f'主{current_thread().name}')# g1.join()# g2.join()# 最终版本:import geventfrom gevent import monkeymonkey.patch_all() # 打补丁: 将下面的所有的任务的阻塞都打上标记def eat(name): print('%s eat 1' %name) time.sleep(2) print('%s eat 2' %name)def play(name): print('%s play 1' %name) time.sleep(1) print('%s play 2' %name)g1 = gevent.spawn(eat,'egon')g2 = gevent.spawn(play,name='egon')# g1.join()# g2.join()gevent.joinall([g1,g2])","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_gevent协程模块","slug":"python-gevent协程模块","permalink":"http://www.innerjquery.club/tags/python-gevent%E5%8D%8F%E7%A8%8B%E6%A8%A1%E5%9D%97/"}]},{"title":"python的多任务线程","slug":"threading模块","date":"2019-03-13T15:39:46.000Z","updated":"2021-03-24T12:36:28.107Z","comments":true,"path":"2019/03/13/threading模块/","link":"","permalink":"http://www.innerjquery.club/2019/03/13/threading%E6%A8%A1%E5%9D%97/","excerpt":"","text":"1. 线程的理论知识 什么是线程一条流水线的工作流程.进程: 在内存中开启一个进程空间,然后将主进程的所有的资源数据复制一份,然后调用cpu去执行这些代码.之前的描述不够具体:开启一个进程:在内存中开启一个进程空间,然后将主进程的所有的资源数据复制一份,然后调用线程去执行代码进程是资源单位, 线程是执行单位.以后你描述开启一个进程:开启一个进程:进程会在内存中开辟一个进程空间,将主进程的资料数据全部复制一份,线程会执行里面的代码. 线程vs进程 开启进程的开销非常大,比开启线程的开销大很多 开启线程的速度非常快要快几十倍到上百倍 线程线程之间可以共享数据,进程与进程之间需借助队列等方法实现通信. 线程的应用并发: 一个cpu 看起来像是同时执行多个任务.单个进程开启三个线程.并发的执行任务.开启三个进程并发的执行任务.文本编辑器:1. 输入文字.2. 在屏幕上显示.3. 保存在磁盘中.开启多线程就非常好了:数据共享, 开销小,速度快.主线程子线程没有地位之分,但是,一个进程谁在干活?一个主线程在干活,当干完活了,你得等待其他线程干完活之后,才能结束本进程. 2. 开启线程的两种方式 1234567891011121314151617181920212223242526272829303132333435# 多进程:from threading import Thread# from multiprocessing import Process# import os## def work():# print('hello')## if __name__ == '__main__':# #在主进程下开启线程# t=Process(target=work)# t.start()# print('主线程/主进程')# 多线程# from threading import Thread# import time## def task(name):# print(f'{name} is running')# time.sleep(1)# print(f'{name} is gone')#### if __name__ == '__main__':## t1 = Thread(target=task,args=('海狗',))# t1.start()# print('===主线程') # 线程是没有主次之分的. 3. 线程vs进程的代码对比 开启速度对比 对比pid 同一个进程内线程共享内部数据 12345678910111213141516171819202122232425262728293031323334# 多进程:from threading import Thread# from multiprocessing import Process# import os## def work():# print('hello')## if __name__ == '__main__':# #在主进程下开启线程# t=Process(target=work)# t.start()# print('主线程/主进程')# 多线程# from threading import Thread# import time## def task(name):# print(f'{name} is running')# time.sleep(1)# print(f'{name} is gone')#### if __name__ == '__main__':## t1 = Thread(target=task,args=('海狗',))# t1.start()# print('===主线程') # 线程是没有主次之分的. 1234567891011121314151617181920212223242526272829303132333435# from multiprocessing import Process# import time# import os# def task(name):# print(f'子进程: {os.getpid()}')# print(f'主进程: {os.getppid()}')### if __name__ == '__main__':## p1 = Process(target=task,args=('常鑫',)) # 创建一个进程对象# p2 = Process(target=task,args=('常鑫',)) # 创建一个进程对象# p1.start()# p2.start()# print(f'==主{os.getpid()}')# 线程:from threading import Threadimport osdef task(): print(os.getpid())if __name__ == '__main__': t1 = Thread(target=task) t2 = Thread(target=task) t1.start() t2.start() print(f'===主线程{os.getpid()}') 12345678910111213141516from threading import Threadimport osx = 3def task(): global x x = 100if __name__ == '__main__': t1 = Thread(target=task) t1.start() t1.join() print(f'===主线程{x}')# 同一进程内的资源数据对于这个进程的多个线程来说是共享的. 4. 线程的相关其他方法(了解) currentThread方法用于获取当前线程对象 enumerate方法用于枚举当前进程的所有线程对象 activeCount方法用法返回当前正在运行的线程数量 线程对象下的isAlive()方法用于判断线程是否还或者 线程对象下的getName()方法用于返回当前线程的名字 线程对象下的setName(‘子线程-1’)方法或者name属性用于设置当前线程名 os.getpid()方法返回进程id且一个进程的所有线程是在同一进程id下的 1234567891011121314151617181920212223242526272829303132from threading import Threadfrom threading import currentThreadfrom threading import enumeratefrom threading import activeCountimport osimport timex = 3def task(): # print(currentThread()) time.sleep(1) print('666')print(123)if __name__ == '__main__': t1 = Thread(target=task,name='线程1') t2 = Thread(target=task,name='线程2') # name 设置线程名 t1.start() t2.start() # time.sleep(2) # print(t1.isAlive()) # 判断线程是否活着 # print(t1.getName()) # 获取线程名 # t1.setName('子线程-1') # print(t1.name) # 获取线程名 *** # threading方法 # print(currentThread()) # 获取当前线程的对象 # print(enumerate()) # 返回一个列表,包含所有的线程对象 print(activeCount()) # *** print(f'===主线程{os.getpid()}') 5. 守护线程(考点) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173# join: 阻塞 告知主线程要等待我子线程执行完毕之后再执行主线程# from threading import Thread# import time## def task(name):# print(f'{name} is running')# time.sleep(1)# print(f'{name} is gone')#### if __name__ == '__main__':# start_time = time.time()# t1 = Thread(target=task,args=('海狗',))# t2 = Thread(target=task,args=('海狗1',))# t3 = Thread(target=task,args=('海狗2',))## t1.start()# t1.join()# t2.start()# t2.join()# t3.start()# t3.join()## print(f'===主线程{time.time() - start_time}') # 线程是没有主次之分的.# 守护线程# 回忆一下守护进程# from multiprocessing import Process# import time### def foo():# print(123)# time.sleep(1)# print(\"end123\")### def bar():# print(456)# time.sleep(2)# print(\"end456\")## if __name__ == '__main__':## p1 = Process(target=foo,)# p2 = Process(target=bar,)## p1.daemon = True# p1.start()# p2.start()# print('====主')# 守护线程# from threading import Thread# import time### def sayhi(name):# print('你滚!')# time.sleep(2)# print('%s say hello' %name)## if __name__ == '__main__':# t = Thread(target=sayhi,args=('egon',))# # t.setDaemon(True) #必须在t.start()之前设置# t.daemon = True# t.start() # 线程的开启速度要跟进程开很多## print('主线程')# from threading import Thread# import time## def foo():# print(123) # 1# time.sleep(1)# print(\"end123\") # 4## def bar():# print(456) # 2# time.sleep(3)# print(\"end456\") # 5### t1=Thread(target=foo)# t2=Thread(target=bar)## t1.daemon=True# t1.start()# t2.start()# print(\"main-------\") # 3# 主线程什么时候结束???# 守护线程 等待非守护子线程以及主线程结束之后,结束.# from threading import Thread# import time## def foo():# print(123) # 1# time.sleep(3)# print(\"end123\") # 4## def bar():# print(456) # 2# time.sleep(1)# print(\"end456\") # 5### t1=Thread(target=foo)# t2=Thread(target=bar)## t1.daemon=True# t1.start()# t2.start()# print(\"main-------\") # 3'''123456main-------end123end456123456mainend456main456end456456123mainend456'''# from threading import Thread# import time## def foo():# print(123)# time.sleep(3)# print(\"end123\")## def bar():# print(456)# time.sleep(1)# print(\"end456\")### t1=Thread(target=foo)# t2=Thread(target=bar)## t1.daemon=True# t1.start()# t2.start()# print(\"main-------\") 6. 互斥锁(考点) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# from threading import Thread# import time# import random# x = 100## def task():# time.sleep(random.randint(1,2))# global x# temp = x# time.sleep(random.randint(1, 3))# temp = temp - 1# x = temp### if __name__ == '__main__':# l1 = []# for i in range(100):# t = Thread(target=task)# l1.append(t)# t.start()## for i in l1:# i.join()# print(f'主线程{x}')# 多个任务公抢一个数据,保证数据的安全的目的,要让其串行from threading import Threadfrom threading import Lockimport timeimport randomx = 100def task(lock): lock.acquire() # time.sleep(random.randint(1,2)) global x temp = x time.sleep(0.01) temp = temp - 1 x = temp lock.release()if __name__ == '__main__': mutex = Lock() l1 = [] for i in range(100): t = Thread(target=task,args=(mutex,)) l1.append(t) t.start() time.sleep(3) print(f'主线程{x}') 7. 死锁现象与递归锁 死锁现象产生的原因：1线程拿着a锁想要b锁，2线程拿着b锁想要a锁，两个线程都在等着对象解锁，导致都无法拿到想要的锁而出现死锁在以后的任务中锁越多，出现死锁的可能越大 递归锁可以解决死锁现象，其内部做了如下处理,使用同一把锁递归锁有一个计数的功能, 原数字为0,上一次锁,计数+1,释放一次锁,计数-1,只要递归锁上面的数字不为零,其他线程就不能抢锁. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# from threading import Thread# from threading import Lock# import time## lock_A = Lock()# lock_B = Lock()### class MyThread(Thread):## def run(self):# self.f1()# self.f2()### def f1(self):## lock_A.acquire()# print(f'{self.name}拿到了A锁')## lock_B.acquire()# print(f'{self.name}拿到了B锁')## lock_B.release()## lock_A.release()## def f2(self):## lock_B.acquire()# print(f'{self.name}拿到了B锁')## time.sleep(0.1)# lock_A.acquire()# print(f'{self.name}拿到了A锁')## lock_A.release()## lock_B.release()#### if __name__ == '__main__':## for i in range(3):# t = MyThread()# t.start()from threading import Threadfrom threading import RLockimport timelock_A = lock_B = RLock()# 递归锁有一个计数的功能, 原数字为0,上一次锁,计数+1,释放一次锁,计数-1,# 只要递归锁上面的数字不为零,其他线程就不能抢锁.class MyThread(Thread): def run(self): self.f1() self.f2() def f1(self): lock_A.acquire() print(f'{self.name}拿到了A锁') lock_B.acquire() print(f'{self.name}拿到了B锁') lock_B.release() lock_A.release() def f2(self): lock_B.acquire() print(f'{self.name}拿到了B锁') time.sleep(0.1) lock_A.acquire() print(f'{self.name}拿到了A锁') lock_A.release() lock_B.release()if __name__ == '__main__': for i in range(3): t = MyThread() t.start() 8. 信号量 也是一种锁, 控制并发数量123456789101112131415161718from threading import Thread, Semaphore, current_threadimport timeimport randomsem = Semaphore(5)def task(): sem.acquire() print(f'{current_thread().name} 厕所ing') time.sleep(random.randint(1,3)) sem.release()if __name__ == '__main__': for i in range(20): t = Thread(target=task,) t.start() 9. IO计算密集型验证 对于IO密集型: 单个进程的多线程的并发效率高. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879from threading import Threadfrom multiprocessing import Processimport timeimport random# # 计算密集型: 单个进程的多线程并发 vs 多个进程的并发并行## def task():# count = 0# for i in range(10000000):# count += 1### if __name__ == '__main__':## # 多进程的并发,并行# # start_time = time.time()# # l1 = []# # for i in range(4):# # p = Process(target=task,)# # l1.append(p)# # p.start()# ## # for p in l1:# # p.join()# ## # print(f'执行效率:{time.time()- start_time}') # 3.1402080059051514## # 多线程的并发# # start_time = time.time()# # l1 = []# # for i in range(4):# # p = Thread(target=task,)# # l1.append(p)# # p.start()# ## # for p in l1:# # p.join()# ## # print(f'执行效率:{time.time()- start_time}') # 4.5913777351379395# 总结: 计算密集型: 多进程的并发并行效率高.# IO密集型: 单个进程的多线程并发 vs 多个进程的并发并行def task(): count = 0 time.sleep(random.randint(1,3)) count += 1# if __name__ == '__main__':# 多进程的并发,并行# start_time = time.time()# l1 = []# for i in range(50):# p = Process(target=task,)# l1.append(p)# p.start()## for p in l1:# p.join()## print(f'执行效率:{time.time()- start_time}') # 8.000000000# 多线程的并发# start_time = time.time()# l1 = []# for i in range(50):# p = Thread(target=task,)# l1.append(p)# p.start()## for p in l1:# p.join()## print(f'执行效率:{time.time()- start_time}') # 3.0294392108917236# 对于IO密集型: 单个进程的多线程的并发效率高. 10. GIL全局解释器锁 前言：GIL的知识大多都是在面试的时候才会用到，但是抱着学习(或者说更好的与面试官扯皮)的心态，怎么也要了解的深入一些 GIL全局解释器锁说明：GIL全局解释器锁是CPython解释器独有的锁，目的就是牺牲效率保证数据安全。一直有CPython的并发不太行的说法，是真的呢？还是一些大V危言耸听？吸引眼球还是确有其事？接下来就跟你详细剖析一些GIL全局解释器锁 通过命令执行python文件的流程：操作系统在内存中开辟一个进程空间，将你的Python解析器以及py文件加载进去，解释器运行py文件。我们可以把Python解释器看做一个函数，你的py代码就是一堆代码，相当于一个实参，然后将这个实参传入函数中(Python解释器)执行。此时我们所说的Python解释器就是CPython解释器。 你的Python解释器细分为三部分: 先将你的代码通过编译器编译成C的字节码 然后给到虚拟机将字节码输出为机器码 最后配合操作系统把你的这个机器码扔给CPU去执行你的py文件中有一个主线程(红色箭头代表的就是主线程)，主线程配合操作系统执行了整个过程。我们知道一个进程可以开启多个线程执行任务，那就意味着：理论上来说，一个进程的多个线程可以利用多核并行(不是并发)的处理任务。三个线程给Python三个CPU去并行的执行，最大限度提高效率。but！ 这个只是理论上来说，实际上Python的单个进程的多线程是无法应用多核的，因为写Cpython源码的大佬程序员给进入解释器的线程加了一把锁，也就是我们常说的GIL锁。 为什么CPython解析器要加这把锁呢？ 因为在Python刚刚研发出来的时候是单核的时代，而且CPU价格非常的昂贵，Python起初作为一种脚本语言，面临的需求单核解决足以 如果不加这把GIL锁，那么同一时刻进入CPython解释器线程数量不固定，我们要保证CPython解释器的数据资源安全，就需要在源码内部主动加入大量的互斥锁(Lock)来保证数据安全性，这样非常麻烦并且会降低CPython源码的开发速度 那现在为什么不将这把锁去掉呢？CPython解释器内部的管理以及业务逻辑全部是围绕单线程实现的，并且从⻳叔创建CPython到现在，CPython源码已经更新迭代⻢上到4版本了，源码内容体量庞⼤，如果你要去掉，这个⼯程量⽆异于重新构建python，是⽐登天还难。 Cpython解释器是官⽅推荐的解释器，处理速度快，功能强⼤ JPython就是编译成Java识别的字节码，没有GIL锁 Pypy属于动态编译型，规则和漏洞很多，现在还在测试阶段（未来可能会成为主流）没有GIL锁只有Cpython解释器有GIL锁，其他类型的解释器以及其他语⾔都没有 由此可以看出，CPython并发不太行是确有其事的，但是也不能因此否定Python，虽然说Python的单个进程的多线程不能利用多核并行处理脚本，但是并不是说Python不能并行，是单个进程下的多线程不能并行，如果你要开启多个进程是可以利用多核的。那么继续发问了，多个进程不是开销⾮常⼤么？这不是影响性能么？其实这个只是相对的，⼗⼏个进程对于我们现在⽤的平常的电脑是不成问题的，何况企业级服务器呢？ 其实，即使说单个进程的多个线程不能并行。也不会影响很多的。不能并行那就并发吧，这就要针对计算密集型还是IO密集型分情况讨论了 IO密集型： 操作系统可以操控着CPU遇到IO就将CPU强⾏的切执⾏另⼀个任务，⽽这个任务遇到IO阻塞了，⻢上⼜会切换，所以IO密集型利⽤单个进程的多线程并发是最好的解决⽅式（后⾯还会有协程也⾮常好⽤）。多个任务都是纯计算都没有IO阻塞，那么此时应该利⽤多进程并⾏的处理任务。 总结： GIL全局解释器锁只存在Cpython解释器中，他是给进⼊解释器的线程上锁： 优点：便于Cpython解释器的内部资源管理，保证了Cpython解释器的数据安全。 缺点：单个进程的多线程不能利⽤多核。 注意：GIL全局解释器锁并不是让Cpython不能利⽤多核，多进程是可以利⽤多核的，况且IO密集型的任务，单个进程的多线程并发处理⾜以。 IO密集型：单个进程的多线程并发处理 计算密集型：多个进程并⾏处理 GIL全局解释器锁与互斥锁的关系(补充)Python已经有⼀个GIL来保证同⼀时间只能有⼀个线程来执⾏了，为什么这⾥还需要Lock? ⾸先我们需要达成共识：锁的⽬的是为了保护共享的数据，同⼀时间只能有⼀个线程来修改共享的数据然后，我们可以得出结论：保护不同的数据就应该加不同的锁。 最后，问题就很明朗了，GIL 与Lock是两把锁，保护的数据不⼀样，前者是解释器级别的(当然保护的就是解释器级别的数据，⽐如垃圾回收的数据)，后者是保护⽤户⾃⼰开发的应⽤程序的数据，很明显GIL不负责这件事，只能⽤户⾃定义加锁处理，即Lock。 过程分析：所有线程抢的是GIL锁，或者说所有线程抢的是执行权限线程1抢到GIL锁，拿到执行权限，开始执行，然后加了一把Lock，还没有执行完毕，即线程1还未释放Lock，有可能线程2抢到GIL锁，开始执行，执行过程中发现Lock还没有被线程1释放，于是线程2进入阻塞，被夺走执行权限，有可能线程1拿到GIL，然后正常执行到释放Lock。。。这就导致了串行运行的效果 既然是串行，那我们执行 t1.start() t1.join t2.start() t2.join() 这也是串行执行啊，为何还要加Lock呢，需知join是等待t1所有的代码执行完，相当于锁住了t1的所有代 码，而Lock只是锁住一部分操作共享数据的代码。！！！ join是等待所有的代码执行完之后，而加锁只是锁上了一部分操作共享数据的代码，更加灵活，看不同的场景用来应用join还是lock 因为Python解释器帮你自动定期进行内存回收，你可以理解为python解释器里有一个独立的线程，每过一段时间它起wake up做一次全局轮询看看哪些内存数据是可以被清空的，此时你自己的程序 里的线程和py解释器自己的线程是并发运行的，假设你的线程删除了一个变量，py解释器的垃圾回收线程在清空这个变量的过程中的clearing时刻，可能一个其它线程正好又重新给这个还没来及得清空的内存空间赋值了，结果就有可能新赋值的数据被删除了，为了解决类似的问题，python解释器简单粗暴的加了锁，即当一个线程运行时，其它人都不能动，这样就解决了上述的问题， 这可以说是Python早期版本的遗留问题。 11. 线程池,进程池 线程池: 一个容器,这个容器限制住你开启线程的数量,比如4个,第一次肯定只能并发的处理4个任务,只要有任务完成,线程马上就会接下一个任务.以时间换空间 1234567891011121314151617181920212223242526272829303132from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutorimport osimport timeimport random# print(os.cpu_count())def task(n): print(f'{os.getpid()} 接客') time.sleep(random.randint(1,3))if __name__ == '__main__': # 开启进程池 (并行(并行+并发)) # p = ProcessPoolExecutor() # 默认不写,进程池里面的进程数与cpu个数相等 # # # p.submit(task,1) # # p.submit(task,1) # # p.submit(task,1) # # p.submit(task,1) # # p.submit(task,1) # # p.submit(task,1) # # p.submit(task,1) # for i in range(20): # p.submit(task,i) # # 开启线程池 (并发) t = ThreadPoolExecutor() # 默认不写, cpu个数*5 线程数 # t = ThreadPoolExecutor(100) # 100个线程 for i in range(20): t.submit(task,i) 12. 阻塞,非阻塞,同步,异步 阻塞,非阻塞,同步,异步进程运行的三个状态: 运行,就绪,阻塞. 执行的角度: 阻塞: 程序运行时,遇到了IO,程序挂起,cpu被切走. 非阻塞: 程序没有遇到IO,程序遇到IO但是我通过某种手段,让cpu强行运行我的程序. 提交任务的角度: 同步: 提交一个任务,自任务开始运行直到此任务结束(可能有IO),返回一个返回值之后,我在提交下一个任务. 异步: 一次提交多个任务,然后我就直接执行下一行代码. 返回结果如何回收?给三个老师发布任务: 同步: 先告知第一个老师完成写书的任务,我从原地等待,等他两天之后完成了,告诉完事了,我在发布下一个任务…… 异步:直接将三个任务告知三个老师,我就忙我的我,直到三个老师完成之后,告知我. 同步调用,异步调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# 1. 异步调用# 异步调用返回值如何接收? 未解决. from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor import time import random import os def task(i): print(f'{os.getpid()}开始任务') time.sleep(random.randint(1,3)) print(f'{os.getpid()}任务结束') return i if __name__ == '__main__': # 异步调用 pool = ProcessPoolExecutor() for i in range(10): pool.submit(task,i) pool.shutdown(wait=True) # shutdown: 让我的主进程等待进程池中所有的子进程都结束任务之后,在执行. 有点类似与join. # shutdown: 在上一个进程池没有完成所有的任务之前,不允许添加新的任务. # 一个任务是通过一个函数实现的,任务完成了他的返回值就是函数的返回值. print('===主') # 2. 同步调用 from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor import time import random import os def task(i): print(f'{os.getpid()}开始任务') time.sleep(random.randint(1,3)) print(f'{os.getpid()}任务结束') return i if __name__ == '__main__': # 同步调用 pool = ProcessPoolExecutor() for i in range(10): obj = pool.submit(task,i) # obj是一个动态对象,返回的当前的对象的状态,有可能运行中,可能(就绪阻塞),还可能是结束了. # obj.result() 必须等到这个任务完成后,返回了结果之后,在执行下一个任务. print(f'任务结果:{obj.result()}') pool.shutdown(wait=True) # shutdown: 让我的主进程等待进程池中所有的子进程都结束任务之后,在执行. 有点类似与join. # shutdown: 在上一个进程池没有完成所有的任务之前,不允许添加新的任务. # 一个任务是通过一个函数实现的,任务完成了他的返回值就是函数的返回值. print('===主') # 3 异步如何取结果??? # 方式一: 异步调用,统一回收结果. # from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor # import time # import random # import os # # def task(i): # print(f'{os.getpid()}开始任务') # time.sleep(random.randint(1,3)) # print(f'{os.getpid()}任务结束') # return i # # if __name__ == '__main__': # # # 异步调用 # pool = ProcessPoolExecutor() # l1 = [] # for i in range(10): # obj = pool.submit(task,i) # l1.append(obj) # # pool.shutdown(wait=True) # print(l1) # for i in l1: # print(i.result()) # print('===主') # 统一回收结果: 我不能马上收到任何一个已经完成的任务的返回值,我只能等到所有的任务全部结束统一回收. # 第二种方式:from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutorimport timeimport randomimport osdef task(i): print(f'{os.getpid()}开始任务') time.sleep(random.randint(1,3)) print(f'{os.getpid()}任务结束') return iif __name__ == '__main__': # 异步调用 pool = ProcessPoolExecutor() l1 = [] for i in range(10): obj = pool.submit(task,i) l1.append(obj) pool.shutdown(wait=True) print(l1) for i in l1: print(i.result()) print('===主') # 打印一下结果就行了 异步调用+回调函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207 # 浏览器工作原理, 向服务端发送一个请求,服务端验证你的请求,如果正确,给你的浏览器返回一个文件,# 浏览器接收到文件,将文件里面的代码渲染成你看到的漂亮美丽的模样.# 什么叫爬虫?# 1. 利用代码模拟一个浏览器,进行浏览器的工作流程得到一堆源代码.# 2. 对源代码进行数据清洗得到我想要数据.# import requests# ret = requests.get('http://www.baidu.com')# if ret.status_code == 200:# print(ret.text)\"\"\"# 版本一:# from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor# import time# import random# import os# import requests### def task(url):# '''模拟的就是爬取多个源代码 一定有IO操作'''# ret = requests.get(url)# if ret.status_code == 200:# return ret.text## def parse(content):# '''模拟对数据进行分析 一般没有IO'''# return len(content)### if __name__ == '__main__':# '''串行 耗费时间长,不可取# ret = task('http://www.baidu.com')# print(parse(ret))## ret = task('http://www.JD.com')# print(parse(ret))## ret = task('http://www.taobao.com')# print(parse(ret))## ret = task('https://www.cnblogs.com/jin-xin/articles/7459977.html')# print(parse(ret))## '''# # 开启线程池,并发并行的执行# url_list = [# 'http://www.baidu.com',# 'http://www.JD.com',# 'http://www.JD.com',# 'http://www.JD.com',# 'http://www.taobao.com',# 'https://www.cnblogs.com/jin-xin/articles/7459977.html',# 'https://www.luffycity.com/',# 'https://www.cnblogs.com/jin-xin/articles/9811379.html',# 'https://www.cnblogs.com/jin-xin/articles/11245654.html',# 'https://www.sina.com.cn/',# ]# pool = ThreadPoolExecutor(4)# obj_list = []# for url in url_list:# obj = pool.submit(task,url)# obj_list.append(obj)## pool.shutdown(wait=True)# for res in obj_list:# print(parse(res.result()))# # '''# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())# parse(res.result())'''# print('===主')'''# 版本一:# 1. 异步发出10个任务,并发的执行,但是统一的接收所有的任务的返回值.(效率低,不能实时的获取结果)# 2. 分析结果流程是串行,影响效率.# for res in obj_list:# print(parse(res.result()))'''# 版本二: 针对版本一的缺点2,改进,让串行编程并发或者并行.# from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor# import time# import random# import os# import requests### def task(url):# '''模拟的就是爬取多个源代码 一定有IO操作'''# ret = requests.get(url)# if ret.status_code == 200:# return parse(ret.text)### def parse(content):# '''模拟对数据进行分析 一般没有IO'''# return len(content)### if __name__ == '__main__':## # 开启线程池,并发并行的执行# url_list = [# 'http://www.baidu.com',# 'http://www.JD.com',# 'http://www.JD.com',# 'http://www.JD.com',# 'http://www.taobao.com',# 'https://www.cnblogs.com/jin-xin/articles/7459977.html',# 'https://www.luffycity.com/',# 'https://www.cnblogs.com/jin-xin/articles/9811379.html',# 'https://www.cnblogs.com/jin-xin/articles/11245654.html',# 'https://www.sina.com.cn/',## ]# pool = ThreadPoolExecutor(4)# obj_list = []# for url in url_list:# obj = pool.submit(task, url)# obj_list.append(obj)# '''# # 1 在开一个线程进程池,并发并行的处理. 再开一个线程进程池,开销大.# # 2 将原来的任务扩大,# 版本一:# 线程池设置4个线程, 异步发起10个任务,每个任务是通过网页获取源码, 并发执行,# 最后统一用列表回收10个任务, 串行着分析源码.# 版本二:# 线程池设置4个线程, 异步发起10个任务,每个任务是通过网页获取源码+数据分析, 并发执行,# 最后将所有的结果展示出来.# 耦合性增强了.# 并发执行任务,此任务最好是IO阻塞,才能发挥最大的效果# '''# pool.shutdown(wait=True)# for res in obj_list: # [obj1, obj2,obj3....obj10]# print(res.result())#\"\"\"# 版本三:# 基于 异步调用回收所有任务的结果我要做到实时回收结果,# 并发执行任务每个任务只是处理IO阻塞的,不能增加新得功能.# 异步调用 + 回调函数from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutorimport timeimport randomimport osimport requestsdef task(url): '''模拟的就是爬取多个源代码 一定有IO操作''' ret = requests.get(url) if ret.status_code == 200: return ret.textdef parse(obj): '''模拟对数据进行分析 一般没有IO''' print(len(obj.result()))if __name__ == '__main__': # 开启线程池,并发并行的执行 url_list = [ 'http://www.baidu.com', 'http://www.JD.com', 'http://www.JD.com', 'http://www.JD.com', 'http://www.taobao.com', 'https://www.cnblogs.com/jin-xin/articles/7459977.html', 'https://www.luffycity.com/', 'https://www.cnblogs.com/jin-xin/articles/9811379.html', 'https://www.cnblogs.com/jin-xin/articles/11245654.html', 'https://www.sina.com.cn/', ] pool = ThreadPoolExecutor(4) for url in url_list: obj = pool.submit(task, url) obj.add_done_callback(parse) ''' 线程池设置4个线程, 异步发起10个任务,每个任务是通过网页获取源码, 并发执行, 当一个任务完成之后,将parse这个分析代码的任务交由剩余的空闲的线程去执行,你这个线程继续去处理其他任务. 如果进程池+回调: 回调函数由主进程去执行. 如果线程池+回调: 回到函数由空闲的线程去执行. '''# 异步 回调是一回事儿?# 异步站在发布任务的角度,# 站在接收结果的角度: 回调函数 按顺序接收每个任务的结果,进行下一步处理.# 异步 + 回调:# 异步处理的IO类型.# 回调处理非IO 13. 线程队列queue模块 线程queue多线程抢占资源: 只能让其串行. 互斥锁. 队列. 12345678910111213141516171819202122232425262728293031323334 import queue# 第一种 先进先出# q = queue.Queue(3)# q.put(1)# q.put(2)# q.put(3)# # q.put(4)# print(q.get())# print(q.get())# print(q.get())# # print(q.get(block=False))# q.get(timeout=2) # 阻塞2s 还没有值直接报错# 第二种 后进先出 LiFo 堆栈# q = queue.LifoQueue(4)# q.put(1)# q.put(2)# q.put('alex')# q.put('太白')# print(q.get())# print(q.get())# print(q.get())# print(q.get())# 第三种优先级队列q = queue.PriorityQueue(4)q.put((5, '元宝'))q.put((-2,'狗狗'))q.put((0, '李业'))# q.put((0, '刚哥'))print(q.get())print(q.get())print(q.get()) 线程event事件 开启两个线程,一个线程运行到中间的某个阶段,触发另个线程执行.两个线程增加了耦合性. 线程事件的实例对象本质就是一个布尔值的标志位; event = Event() 创建一个线程事件对象 event.is_set() 获取线程事件对象的标志位的布尔值，默认是false event.set() 设置线程事件对象的标志位的值为true event.wait() 只阻塞n秒,n秒之后如果还没有进行set 直接进行下一步操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990 # 版本一:# 如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作# from threading import Thread# from threading import current_thread# import time## flag = False# def check():# print(f'{current_thread().name} 监测服务器是否开启...')# time.sleep(3)# global flag# flag = True# print('服务器已经开启...')## def connect():# while 1:# print(f'{current_thread().name} 等待连接...')# time.sleep(0.5)# if flag:# print(f'{current_thread().name} 连接成功...')# break## t1 = Thread(target=check,)# t2 = Thread(target=connect,)# t1.start()# t2.start()# 版本二: 事件event# from threading import Thread# from threading import current_thread# from threading import Event# import time## event = Event()# def check():# print(f'{current_thread().name} 监测服务器是否开启...')# time.sleep(3)# print(event.is_set())# event.set()# print(event.is_set())# print('服务器已经开启...')## def connect():## print(f'{current_thread().name} 等待连接...')# # event.wait() # 阻塞 直到 event.set() 方法之后# event.wait(1) # 只阻塞1秒,1秒之后如果还没有进行set 直接进行下一步操作.# print(f'{current_thread().name} 连接成功...')## t1 = Thread(target=check,)# t2 = Thread(target=connect,)# t1.start()# t2.start()# 一个线程监测服务器是否开始,# 另个一线程判断如果开始了,则显示连接成功,此线程只尝试连接3次,1s 一次,如果超过3次,还没有连接成功,则显示连接失败.# from threading import Thread# from threading import current_thread# from threading import Event# import time## event = Event()# def check():# print(f'{current_thread().name} 监测服务器是否开启...')# time.sleep(4)# event.set()# print('服务器已经开启...')## def connect():# count = 1# while not event.is_set():# if count == 4:# print('连接次数过多,已断开')# break# event.wait(1)# print(f'{current_thread().name} 尝试连接{count}次')# count += 1# else:# print(f'{current_thread().name} 连接成功...')## t1 = Thread(target=check,)# t2 = Thread(target=connect,)# t1.start()# t2.start()","categories":[{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"}],"tags":[{"name":"python_threading模块","slug":"python-threading模块","permalink":"http://www.innerjquery.club/tags/python-threading%E6%A8%A1%E5%9D%97/"}]}],"categories":[{"name":"js","slug":"js","permalink":"http://www.innerjquery.club/categories/js/"},{"name":"spider","slug":"spider","permalink":"http://www.innerjquery.club/categories/spider/"},{"name":"web 前端杂项","slug":"web-前端杂项","permalink":"http://www.innerjquery.club/categories/web-%E5%89%8D%E7%AB%AF%E6%9D%82%E9%A1%B9/"},{"name":"python","slug":"python","permalink":"http://www.innerjquery.club/categories/python/"},{"name":"Database","slug":"Database","permalink":"http://www.innerjquery.club/categories/Database/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://www.innerjquery.club/tags/vue/"},{"name":"python 爬虫","slug":"python-爬虫","permalink":"http://www.innerjquery.club/tags/python-%E7%88%AC%E8%99%AB/"},{"name":"react-virtualized_component","slug":"react-virtualized-component","permalink":"http://www.innerjquery.club/tags/react-virtualized-component/"},{"name":"issue","slug":"issue","permalink":"http://www.innerjquery.club/tags/issue/"},{"name":"js 原生","slug":"js-原生","permalink":"http://www.innerjquery.club/tags/js-%E5%8E%9F%E7%94%9F/"},{"name":"vue 前端面试题","slug":"vue-前端面试题","permalink":"http://www.innerjquery.club/tags/vue-%E5%89%8D%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"python_其他第三方模块","slug":"python-其他第三方模块","permalink":"http://www.innerjquery.club/tags/python-%E5%85%B6%E4%BB%96%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97/"},{"name":"react_context","slug":"react-context","permalink":"http://www.innerjquery.club/tags/react-context/"},{"name":"wx api","slug":"wx-api","permalink":"http://www.innerjquery.club/tags/wx-api/"},{"name":"vs code","slug":"vs-code","permalink":"http://www.innerjquery.club/tags/vs-code/"},{"name":"vue ui","slug":"vue-ui","permalink":"http://www.innerjquery.club/tags/vue-ui/"},{"name":"js_axios","slug":"js-axios","permalink":"http://www.innerjquery.club/tags/js-axios/"},{"name":"DB-mongo","slug":"DB-mongo","permalink":"http://www.innerjquery.club/tags/DB-mongo/"},{"name":"python_hashlib模块","slug":"python-hashlib模块","permalink":"http://www.innerjquery.club/tags/python-hashlib%E6%A8%A1%E5%9D%97/"},{"name":"DB-mysql","slug":"DB-mysql","permalink":"http://www.innerjquery.club/tags/DB-mysql/"},{"name":"python_django","slug":"python-django","permalink":"http://www.innerjquery.club/tags/python-django/"},{"name":"python_multopprocesssing模块","slug":"python-multopprocesssing模块","permalink":"http://www.innerjquery.club/tags/python-multopprocesssing%E6%A8%A1%E5%9D%97/"},{"name":"axios","slug":"axios","permalink":"http://www.innerjquery.club/tags/axios/"},{"name":"python_time模块","slug":"python-time模块","permalink":"http://www.innerjquery.club/tags/python-time%E6%A8%A1%E5%9D%97/"},{"name":"python_logging模块","slug":"python-logging模块","permalink":"http://www.innerjquery.club/tags/python-logging%E6%A8%A1%E5%9D%97/"},{"name":"python_udp_tcp原理","slug":"python-udp-tcp原理","permalink":"http://www.innerjquery.club/tags/python-udp-tcp%E5%8E%9F%E7%90%86/"},{"name":"python_socket模块","slug":"python-socket模块","permalink":"http://www.innerjquery.club/tags/python-socket%E6%A8%A1%E5%9D%97/"},{"name":"DB-redis","slug":"DB-redis","permalink":"http://www.innerjquery.club/tags/DB-redis/"},{"name":"python_collections模块","slug":"python-collections模块","permalink":"http://www.innerjquery.club/tags/python-collections%E6%A8%A1%E5%9D%97/"},{"name":"python_django_middleware","slug":"python-django-middleware","permalink":"http://www.innerjquery.club/tags/python-django-middleware/"},{"name":"python_gevent协程模块","slug":"python-gevent协程模块","permalink":"http://www.innerjquery.club/tags/python-gevent%E5%8D%8F%E7%A8%8B%E6%A8%A1%E5%9D%97/"},{"name":"python_threading模块","slug":"python-threading模块","permalink":"http://www.innerjquery.club/tags/python-threading%E6%A8%A1%E5%9D%97/"}]}